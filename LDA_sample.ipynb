{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 11 words):\n",
      "Topic 0:\n",
      " 4.24836273916\n",
      " 10.9940049657\n",
      " 2.93073243479\n",
      " 17.5312296012\n",
      " 4.9656599241\n",
      " 2.28202279826\n",
      " 12.3791330609\n",
      " 1.70762915807\n",
      " 4.53354242286\n",
      " 14.0388408945\n",
      " 12.2795276872\n",
      "Topic 1:\n",
      " 9.48618202868\n",
      " 9.00112275964\n",
      " 5.42156337187\n",
      " 9.79756009919\n",
      " 10.5584896311\n",
      " 14.8385325843\n",
      " 11.7591616338\n",
      " 4.08371530515\n",
      " 1.56831183324\n",
      " 3.81156608184\n",
      " 5.97742047833\n",
      "Topic 2:\n",
      " 12.2654552322\n",
      " 9.00487227465\n",
      " 3.64770419334\n",
      " 12.6712102996\n",
      " 9.47585044478\n",
      " 4.87944461741\n",
      " 6.86170530522\n",
      " 4.20865553678\n",
      " 1.8981457439\n",
      " 6.14959302369\n",
      " 14.7430518345\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Load and parse the data\n",
    "data = sc.textFile(\"../spark/data/mllib/sample_lda_data.txt\")\n",
    "parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "# Index documents with unique IDs\n",
    "corpus = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n",
    "# Cluster the documents into three topics using LDA\n",
    "ldaModel = LDA.train(corpus, k=3)\n",
    "\n",
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize()) + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(3):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))\n",
    "\t\t\n",
    "# Save and load model\n",
    "ldaModel.save(sc, \"myModelPath\")\n",
    "sameModel = LDAModel.load(sc, \"myModelPath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
