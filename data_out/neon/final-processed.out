
copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


gener function run unit test pytest


itertool
numpi
pytest

neon backend backend

pytest addopt parser

option full rang paramet test gener
pytest test gener

parser addopt action store help test
parser addopt devic help devic


pytest fixtur
devic request
request config getopt devic

pytest fixtur scope session

path nervana
path

backend request datatyp float32
backend backend request param
datatyp datatyp
devic request config getopt devic
batch size
seed
request param
enabl winograd enabl winograd enabl winograd


pytest fixtur scope
backend request

fixtur setup backend run test also regist teardown
clean backend test done thi scope
test given test file

thi fixtur parameter backend everi test

backend request

cleanup call test done
cleanup
request getfuncargvalu backend

request addfin cleanup

test fixtur access backend
backend nervana object


pytest fixtur scope
backend request

fixtur setup backend run test also regist teardown
clean backend test done thi scope
test given test file

thi fixtur parameter backend everi test

backend request

cleanup call test done
cleanup
request getfuncargvalu backend

request addfin cleanup

test fixtur access backend
backend nervana object


pytest fixtur scope
backend cpu64 request

fixtur return backend dtype
test like gradient check whihch need higher
precis

backend request datatyp float64

cleanup call test done
cleanup
request getfuncargvalu backend cpu64

request addfin cleanup

test fixtur access backend
backend nervana object


idfunc val

print human readabl format parameter test

dtype val
dtype dtype split numpi strip
val dtype

itertool product float16 float32
pytest fixtur scope idfunc
backend test request

fixtur return backend

backend backend request param
datatyp request param
batch size
devic request config getopt devic
seed

cleanup call test done
cleanup
request getfuncargvalu backend test

request addfin cleanup

test fixtur access backend
backend nervana object

python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



setuptool setup find packag command
subprocess

defin version inform
version
fullvers version
write version


pipe subprocess popen pars head
stdout subprocess pipe
serr pipe commun
pipe returncod
fullvers strip decod



write version

copyright 2015 nervana system
licens apach licens version
licens
file complianc
licens
obtain copi licens

http apach licens licens

unless requir applic agre write
softwar
distribut licens distribut
basi
without warranti condit kind either express
impli
licens specif languag govern permiss

limit licens

n version n short version
fname path join path dirnam file neon version
open fname

write project version inform fullvers version

close


setup name neon
version version
descript nervana deep learn framework
descript open readm read
author nervana system
author email info nervanasi
http nervanasi
licens licens approv apach softwar licens
script neon nvi
packag find packag exclud test
neon backend kernel sass sass
backend kernel cubin cubin
loader
classifi develop statu alpha
environ consol
environ consol curs
environ environ
intend audienc user desktop
intend audienc develop
intend audienc scienc research
licens approv apach softwar licens
oper system posix
oper system mac os mac os
program languag python
topic scientif engin
artifici intellig
topic scientif engin inform analysi
topic system distribut comput

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


nervana deep learn librari



neon version version version noqa
import error

error version inform found ensur built
softwar from level issu make

copi deepcopi
inspect
log

setup preliminari stream base logger
log basic config level log error
logger log get logger name

arg func

return dictionari name valu input

arg vararg keyword default inspect getargspec func

default revers default default
arg revers arg

default arg
default

dict arg default


nervana object

base avail class

arg
name option

attribut
backend hardwar backend use backend
name option name assign given


counter

init name
name
name classnm counter
name name
desc
counter

classmethod
pdict
pdict


counter

properti
classnm

conveni method get name

name

properti
modulenm

conveni method get full path

name

descript skip kwarg
skip
skip skip

skip deepcopi skip
skip append

config
default arg init
default
skip


arg need dict read
read altern
descript
descript dictionari
dict
dict default
isinst dict nervana object
config dict descript

config dict

logger warn describ argument format

desc modulenm config config
desc desc
desc

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


import requir build document

bokeh plot figur
bokeh palett brewer
bokeh model range1d
bokeh emb compon
jinja2 templat
import error



label epoch axi

axi label depend epoch axi

epoch epoch axi minibatch


cost cost plot height plot width epoch axi

gener figur line element cost


figur plot height plot height
plot width plot width
titl cost
axi label label epoch axi
axi label cross entropi error

spectral palett support distinct color
color requir cost
color requir insuffici color predefin palett
color brewer spectral cost
color requir
manual adjust pallett better contrast
color brewer spectral
color requir
color brewer spectral

name cost
line legend name color color line width



hist hist plot height plot width rang epoch axi

gener figur imag plot hist bin axi
time axi

name hdata bin offset hist
rang
rang
figur plot height plot height
plot width plot width
titl name
axi label label epoch axi
rang rang
rang offset offset bin
imag imag hdata offset palett spectral11



imag rang rang plot size
figur rang rang rang rang
plot width plot size plot height plot size
toolbar locat
imag rgba
axi visibl
border



deconv fig layer name layer plot size
key dict
key dict
dict dict

name deconv enumer layer




shape
rang range1d start
rang range1d start
imag rang rang plot size
deconv imag deconv rang rang plot size

titl fmap format layer name
key titl
key titl

dict key deconv
dict key

key key dict


deconv summari page filenam cost deconv
dict dict

cost cost plot
dict cost cost cost epoch axi

key dict
key dict
layer layer deconv
key key dict deconv fig layer layer
key layer key
key layer key
dict updat dict

script compon dict

templat
doctyp html
html lang
head
meta charset
titl page titl titl
style left style
link stylesheet
href http pydata bokeh releas bokeh
text
script text javascript
http pydata bokeh releas bokeh script
script
head
bodi
cost plot style width pad 10px
cost


layer sort layer
outer layer style pad 20px
layer style background color c6 fff1 pad 10px
layer layer
key layer key
style pad 10px
featur
key layer
key layer







bodi
html


open filenam htmlfile
htmlfile write render page titl deconv visual script script
cost cost key key
key key
sort layer sort key

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

h5pi
numpi


creat minibatch minibatch minibatch marker epoch axi

helper build axi captur minibatch

argument
minibatch mani total minibatch
minibatch marker cumul minibatch complet given epoch
epoch axi whether render epoch minibatch integ step axi

epoch axi
zero minibatch
last
enumer minibatch marker
minibatch last
last arang minibatch minibatch
last

arang minibatch




creat epoch point epoch freq minibatch marker epoch axi

helper build axi point captur epoch

argument
point mani point need correspond axi point
epoch freq point epoch everi epoch
minibatch marker cumul minibatch complet given epoch
epoch axi whether render epoch minibatch integ step axi


epoch axi
zero point
last
enumer minibatch marker
minibatch last
epoch freq
epoch freq minibatch minibatch
last

minibatch marker epoch freq epoch freq




cost filenam epoch axi

read cost hdf5 file gener axi cost line

return
tupl name


h5pi file filenam

config cost time marker config cost time marker
total epoch config attr total epoch
total minibatch config attr total minibatch
minibatch marker time marker minibatch

name ydata cost iteritem
ydata
ydata attr time marker epoch freq
epoch freq ydata attr epoch freq
total epoch epoch freq
creat epoch epoch freq minibatch marker epoch axi

ydata attr time marker minibatch
total minibatch
creat minibatch total minibatch minibatch marker epoch axi


type error unsupport format cost

append name




hist filenam epoch axi

h5pi file filenam
hist
hist config hist config
bin offset time marker hist attr
bin offset time marker
total epoch config attr total epoch
total minibatch config attr total minibatch

hname hdata hist iteritem
total epoch time marker epoch freq total minibatch
bin
append hname hdata bin offset




convert bokehrgba downsampl

convert imag dimension rgba valu encod integ
requir bokeh function current avail bokeh
issu rais http github bokeh bokeh issu 1699
modifi version suggest solut

argument
ndarray shape dtype uint8 imag
height imag
width imag

return
ndarray imag rgba valu

dtype uint8
not implement error

ndim
not implement error

downsampl render perform flip sinc plot origin bottom left
transpos
downsampl downsampl
shape

alpha channel imag recast pixel u8u8u8u8
bokeh dstack one uint8
imag bokeh reshap view uint32

imag


deconv filenam

read deconv visual hdf5 file

return
list each inner repres layer consist
tupl deconv


h5pi file filenam
deconv key

deconv
deconv

layer key
layer
rang layer shape

avoid store entir dataset img cach need look
batch layer batch
store batch format batch
cach store attr

convert rgba cast uint32 dtype bokeh
plot convert bokehrgba store uint8 cach
plot deconv convert bokehrgba layer

layer append plot deconv plot

append layer layer


copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon callback callback callback

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

collect dequ
h5pi
inspect
log
numpi

signal

time
timeit timer
weakref

neon nervana object
neon nervana data iter ticker
neon util persist load save load
neon layer convolut
logger log get logger name


callback nervana object


contain store iter callback

attribut
callback order callback object


init model
train
output file
freq
progress
save path
serial
histori
model file

metric

creat callback contain callback

argument
model model model
output file option path save callback
freq option often epoch evalu
progress control whether progress
callback creat default
save path file path save model snapshot
serial serial model everi epoch
histori checkpoint file retain
model file option file load weight serial model
nervana data iter option dataset upon evalu loss
metric
metric metric option metric evalu

deprec arg remov kwarg also remov
well code
epoch complet remov sinc often pass argpars arg
train
logger warn deprec warn callback longer
accept train paramet thi argument
remov soon updat code

callback init name
callback
epoch marker
output file output file
output file
hasattr callback
callback
name sould give uniqu filenam
callback h5pi file name driver core back store

path isfil output file
logger warn overwrit output file output file
remov output file
callback h5pi file output file

model weakref model

model file model file

callback train cost callback

progress
callback progress bar callback

freq

evalu frequenc specifi provid
logger except
valu error

loss callback freq
callback insert
metric
metric callback metric freq
callback insert

save path save path
save path
serial interv serial serial
serial model callback save path serial interv histori
callback

callback train logger callback
callback run timer callback



callback close



serial
descript

descript
serial callabck configur
cdict
cdict epoch marker epoch marker
cdict output file output file

cdict callback
callback callback
cdict callback append callback descript
cdict

classmethod
load callback cdict model
cdict
cdict load cdict
callback model output file cdict output file
callback epoch marker cdict epoch marker
callback callback
cdict callback
load
callback callback append config
callback

deconv callback train valid dataset

conveni creat deconvolut callback use
visual

argument
train nervana data iter train dataset
valid nervana data iter valid dataset

callback deconv callback train valid
dataset dataset

save best state callback path

conveni creat save best state callback

argument
path save best model state

callback save best state callback path

watch ticker callback valid

conveni creat watch ticker callback

argument
valid dataset valid
ticker dataset train desir

callback append watch ticker callback model valid

earli stop callback stop func

conveni creat earli stop callback

argument
stop func determin stop

callback earli stop callback stop func

hist callback plot mini filter
callback append hist callback plot mini plot mini filter filter

callback callback insert

user suppli callback sinc callback serial share
order matter behavior append callback
suffici insert posit control

argument
callback callback callback regist
insert option posit insert callback
default mean append

insert
callback append callback

callback insert insert callback

train epoch

call regist callback train function

iter wrap around avoid partial minibatch
callback produc minibatch need prealloc buffer
config callback creat group config
total minibatch model ndata epoch
config attr total minibatch total minibatch
config attr total epoch epoch

time marker callback creat group time marker
time marker creat dataset minibatch epoch
model file
model load model file

setup interrupt handler
signal signal signal sigint sigint

callback
train callback model epoch

train

call regist callback train function

reset signal handler
signal signal signal sigint signal

callback
train callback model

callback close

epoch epoch

call regist callback epoch function

argument
epoch index epoch begin

callback
fire callback model epoch epoch freq
epoch callback model epoch

epoch epoch

call regist callback epoch function

argument
epoch index epoch end

callback
fire callback model epoch epoch freq
epoch callback model epoch

epoch marker epoch minibatch
callback time marker minibatch epoch epoch marker
callback time marker attr epoch complet epoch
callback time marker attr minibatch complet epoch marker
callback flush

minibatch epoch minibatch

call regist callback minibatch function

argument
epoch index current epoch
minibatch index minibatch begin

callback
fire callback model minibatch minibatch freq
minibatch callback model epoch minibatch

minibatch epoch minibatch

call regist callback minibatch function

argument
epoch index current epoch
minibatch index minibatch end

callback
fire callback model minibatch minibatch freq
minibatch callback model epoch minibatch

keep track epoch sinc vari
epoch minibatch minibatch

sigint epoch minibatch

callback handl sigint event

argument
epoch index current epoch
minibatch index minibatch end

restor orign handler
signal signal signal sigint signal

save model
save path
save model serial keep state save path
keyboard interrupt checkpoint file save format save path

keyboard interrupt


callback nervana object


interfac defin common callback function

implement callback subclass callback overrid necessari
train epoch minibatch function

callback function provid time queue deriv callback
class must manag state


init epoch freq minibatch freq
epoch freq epoch freq
minibatch freq minibatch freq
costnm

descript
key inspect getargspec init
key remov

skip
key
isinst getattr nervana data iter
iter input serial serpart
skip append
pdict callback descript skip skip
datap skip
pdict config datap data name getattr datap name
pdict

train callback model epoch

call train

argument
callback hdf5 dataset share callback
model model model



train callback model

call train

argument
callback hdf5 dataset share callback
model model model



epoch callback model epoch

call epoch

argument
callback hdf5 dataset share callback
model model model
epoch index epoch begin



epoch callback model epoch

call epoch

argument
callback hdf5 dataset share callback
model model model
epoch index epoch end



minibatch callback model epoch minibatch

call minibatch

argument
callback hdf5 dataset share callback
model model model
epoch index current epoch
minibatch index minibatch beginin



minibatch callback model epoch minibatch

call minibatch

argument
callback hdf5 dataset share callback
model model model
epoch index current epoch
minibatch index minibatch end



fire callback model time freq

helper determin callback work given
interv

argument
callback hdf5 dataset share callback
model model model
time current time arbitrari unit
freq fire frequenc multipl unit use
time time never fire

time freq




cach epoch loss callback model epoch label

helper check exist loss given label certain
epoch index depend loss callback previous comput loss
store callback doe actual comput

argument
callback hdf5 dataset share callback
model model model
epoch epoch index check
label label find cach loss callback

return
dict contain loss cost valu time inform display inform


costnm
costnm loss costnam display resolv cost
model cost
costnm model cost costfunc name costnm
cost cost label
time time label
cost callback

freq callback cost attr epoch freq
epoch freq
dict cost callback cost epoch freq
time callback time epoch freq
costnm costnm


serial model callback callback


callback serial state model

argument
save path save model dataset
epoch freq option often epoch serial
model specifi
run everi epoch
histori option checkpoint file retain newest
file count retain filenam
check point file
save path epoch


init save path epoch freq histori
serial model callback init epoch freq epoch freq
save path save path
histori histori
checkpoint file dequ

epoch callback model epoch
histori
save histori epoch model

save model serial keep state save path

save histori epoch model
histori save last checkpoint
equal histori file form
save path epoch ad filenam

checkpoint file histori
remov oldest checkpoint file count save
checkpoint file popleft

remov
logger info remov checkpoint
os error
logger warn could checkpoint file

path split path splitext save path
save path path split epoch path split
current file dequ
checkpoint file append save path
save model serial keep state save path

maintain symlink point latest model

path islink save path
remov save path
symlink path split save path save path
os error
logger warn could creat latest model symlink
save path save path


run timer callback callback

callback track total train time

init
run timer callback init

train callback model epoch
time callback creat group time train
time creat dataset start time dtype float64
time creat dataset time dtype float64
time start time time time
time start time attr unit second

train callback model
callback time train time time time
callback time train time attr unit second


train cost callback callback

callback comput averag train cost period train

init
train cost callback init epoch freq


train callback model epoch
prealloc space minibatch whole
point callback config attr total minibatch
callback creat dataset cost train point

make sure window size less equal total minibatch
point
cost histori dequ maxlen

clue reader minibatch time marker
callback cost train attr time marker minibatch

minibatch callback model epoch minibatch
cost histori append model cost cost
mean cost cost histori cost histori
mbstart callback time marker minibatch epoch epoch
callback cost train mbstart minibatch mean cost


loss callback callback


callback calcul loss given dataset period train

argument
nervana data iter dataset evalu
epoch freq option often epoch info
default everi epoch


init epoch freq
loss callback init epoch freq epoch freq

loss zero dtype float32

train callback model epoch
callback creat dataset cost loss epoch epoch freq
callback creat dataset time loss epoch epoch freq
callback cost loss attr time marker epoch freq
callback cost loss attr epoch freq epoch freq

epoch callback model epoch
start loss timer
nprocess
loss
reset

model fprop infer
ndata nprocess
model cost cost
nstep shape isinst
shape
costbuf model cost output nstep
nprocess
loss loss costbuf axi nstep
mean cost loss nprocess
callback time loss epoch epoch freq timer start loss
callback cost loss epoch epoch freq mean cost


metric callback callback

callback calcul metric given dataset period
train

argument
nervana data iter dataset evalu
metric metric metric evalu
epoch freq option often epoch info
default everi epoch

init metric epoch freq
metric callback init epoch freq epoch freq

metric metric
metric metric metric name
metric desc join metric metric name

train callback model epoch
callback creat group metric
metric metric name
group name metric
callback creat dataset group name epoch epoch freq
callback group name attr time marker epoch freq
callback group name attr epoch freq epoch freq

epoch callback model epoch
epoch epoch freq
reset
stat model metric metric
logger info metric desc join stat flatten

enumer metric metric name
callback metric epoch epoch freq stat


multi label stat callback callback


callback calcul statist multi label classif task

use precis recal metric calcul precis recal
valu classif task

argument
nervana data iter dataset evalu
label name order must
row target
metric metric instanti perform metric like
precis recal
epoch freq option often epoch info
default everi epoch


init label metric epoch freq
multi label stat callback init epoch freq epoch freq

metric metric
label label
metric desc join metric metric name

epoch callback model epoch
epoch epoch freq
reset

run stat zero like metric output dtype float32

calcul metric valu
nbatch

model fprop infer

metric
run stat metric output
nbatch

run stat nbatch

print statist label
label enumer label
metric text
metric enumer metric metric name
metric text metric run stat

metric text label
stdout write metric text encod
stdout flush


hist callback callback

collect histogram weight layer configur comput
histogram minibatch epoch plot mini
flag histogram store hdf5 output file visual
nvi tool

init plot mini filter
hist callback init epoch freq minibatch freq
plot mini plot mini
filter filter

train callback model epoch
minibatch callback config attr total minibatch

hist callback creat group hist
hist attr bin hist bin
hist attr offset hist offset
hist attr time marker minibatch plot mini epoch
hist attr time step minibatch plot mini epoch

minibatch callback model epoch minibatch
plot mini
prev epoch minibatch
epoch
prev epoch minibatch callback time marker minibatch epoch

timestamp prev epoch minibatch minibatch
save hist callback model timestamp

epoch callback model epoch
plot mini
save hist callback model epoch

save hist callback model timestamp
enumer model layer layer
item filter
hasattr item
name name item
getattr item
getattr item hist name

hist callback hist
point hist attr time step
hdata hmap dump hist
hdata hdata
hname hmap
hist dset hist dataset hname shape point dtype hdata dtype
hist dset timestamp hdata hmap hname reshap


progress epoch minibatch nbatch cost time
blockchar u2588

gener progress

argument
label train valid test
epoch current epoch display
minibatch current minibatch display
nbatch total minibatch use display rel progress
cost current cost valu
time time elaps epoch
blockchar option charact display step
progress default u2588
solid block

width
width minibatch nbatch width
epoch batch cost width
format epoch blockchar width minibatch nbatch cost time


progress bar callback callback

callback provid live updat consol base progress


init epoch freq
minibatch freq updat thresh
progress bar callback init epoch freq epoch freq
minibatch freq minibatch freq
updat thresh updat thresh
last strlen

epoch callback model epoch
start epoch last updat timer
nbatch model nbatch

minibatch callback model epoch minibatch
timer
complet minibatch
last updat updat thresh complet nbatch
last updat
mbstart callback time marker minibatch epoch epoch
train cost callback cost train mbstart minibatch

progress progress train epoch complet nbatch
train cost start epoch
clear last line
stdout write last strlen
line
stdout write progress encod
last strlen progress
stdout flush

epoch callback model epoch
cach epoch loss callback model epoch loss

progress costnm cost time
stdout write progress encod
stdout flush
stdout write


train logger callback callback


callback log train progress

argument
epoch freq option often epoch train info
default everi epoch
minibatch freq option often minibatch
train info
epoch boundari default


init epoch freq minibatch freq
train logger callback init epoch freq epoch freq
minibatch freq minibatch freq
epoch freq epoch freq
minibatch freq minibatch freq

train callback model epoch
logger info model model

minibatch callback model epoch minibatch
mbstart callback time marker minibatch epoch epoch
train cost callback cost train mbstart minibatch
logger info epoch minibatch complet train cost epoch minibatch train cost

epoch callback model epoch
cach epoch loss callback model epoch loss
epoch complet train cost epoch model total cost
eval cost cost
logger info


save best state callback callback


callback save best model state

argument
path repeatedli write best model paramet seen
filesystem path specifi


init path
save best state callback init epoch freq
best path path
best cost

epoch callback model epoch
cach epoch loss callback model epoch loss

cost best cost best cost
todo gener seral
save model serial keep state best path
best cost cost


earli stop callback callback


callback stop train threshold trigger

argument
stop func function take receiv tupl state
current state valid error time
return tupl state bool return updat
state indic whether stop train


init stop func
earli stop callback init epoch freq
stop func stop func
stop state state need stop func

epoch callback model epoch
cach epoch loss callback model epoch loss

stop state finish stop func stop state cost
finish
model finish
logger warn earli stop trigger mean cost cost


deconv callback callback

callback store project activ back pixel space
guid backpropag springenberg2014 detail meant
use visual purpos nvi

argument
train nervana data iter train dataset
option maximum featur map visual
layer default
dataset option initi portion valid dataset
find maximum activ
default

note

springenberg2014 http arxiv 1412 6806

init train valid dataset
deconv callback init epoch freq
train train
valid valid

dataset dataset
name guid bprop

progress updat curr total unit time blockchar u2588
clear redraw progress
width
width curr total width
visual width
progress format blockchar width curr total unit time
stdout write progress encod
stdout flush

train callback model
todo gener complex topolog
layer model layer layer
cach dict
dict
layer shape
visual featur map layer
logger info format name

enumer layer
isinst convolut
convparam


callback creat group deconv format
creat dataset batch dtype uint16
creat dataset dtype int16
creat dataset dtype uint8
creat dataset activ dtype float32
activ

valid reset
start time time
sampl batch dataset
valid nbatch
batch enumer valid

batch sampl batch


img store layer act callback model batch

store imag callback batch img store

progress updat find img batch
sampl batch batch
time time start

stdout write

loop everi layer visual
start time time
rang layer
layer layer

isinst layer layer convolut
layer layer shape
size
visual layer callback model size layer
progress updat comput name
layer layer
time time start

stdout write

scale

convert valid valu rang

argument
ndarray imag

return
ndarray imag valid valu









store imag callback batch img store batch
img img store
img
batch img store
store callback creat group deconv batch batch

store uint8 format plot
hwc8 store creat dataset uint8 img
dtype uint8 compress
transpos reshap img
hwc8 scale

keep imag format fprop visual
need beyond runtim avoid write file
cach batch

keep lookup file posit
order store need img batch flat prealloc
batch dict
enumer img store
store attr
batch

layer act callback model batch
img store

enumer model layer layer
fprop infer

isinst convolut


shape
argmax zero dtype int32
maxact arang dtype int32

callback deconv format

act output reshap
act flat output reshap

argmax argmax act axi
maxact maxact argmax
act host act flat maxact
argmax host argmax


rang

argmax argmax host
argmax
curr act host

curr activ
activ curr
batch batch
argmax
img store

img store

visual layer callback model size layer
model
callback deconv format layer
layer model layer layer

loop visual everi featur

rang
batch batch

prepar fake minibatch activ imag
batch zero cach batch shape
cach off batch
batch cach batch cach off
batch batch

prep model state fprop
model fprop batch infer

activ correct featur locat

activ zero size
activ activ
activ activ reshap size
activ activ

loop previou layer perform deconv
enumer layer layer
isinst convolut

zero current layer activ
activ maximum activ

output shape deconv input shape conv
convparam

bprop conv layer nglayer activ grad
activ

zero input lower layer
layer act layer layer input
layer act greater layer act
activ multipli layer act activ

layer shape
activ activ reshap
activ transpos activ
scale activ


watch ticker callback callback


callback examin singl input output pair valid
thi work ticker dataset make much sens
imag video someth

argument
model model model
valid data iter valid dataset process
epoch freq option often epoch examin pair
default everi epoch


init model valid epoch freq
watch ticker callback init epoch freq epoch freq
model model
valid valid

isinst valid ticker
valu error valid must ticker

epoch callback model epoch

batch index enumer valid
model fprop infer

wider tensor wrap around
printopt formatt format
linewidth

assum sequenc minibatch length
pull mask buffer host devic
column nonzero
take maximum total timestep
divid batch size time step sequenc minibatch
index purpos
column nonzero

print name pretti version mask
name item input output target


name

onli first sequenc minibatch
there bia sequenc randomli gener
printabl item
printabl column

onli minibatch diagnost tool


copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

log
numpi

neon nervana object
neon backend autodiff
neon backend backend tensor
neon util persist load


logger log get logger name


interpret shape xshape

helper interpret tensor layout preced layer handl recurr
recurr local layer

isinst xshape
xshape

xshape
xshape

prod xshape


layer nervana object


level gener neural network layer layer
type inherit

argument
name name identifi layer log
parallel type parallel prefer layer possibl
valu unknown disabl data onli applic
distribut backend backend detail


init name parallel unknown
layer init name
output

input
own output
own delta
delta
parallel parallel
revert
layer
actual
actual



format layer printabl

format classnm name


nest level

util display layer info given indent level

argument
level option indent level


level

configur

set shape base paramet layer given input tupl
input layer

argument
tupl layer tensor dataset provid shape
inform layer

return
tupl shape output

isinst layer
prev layer
shape shape
parallel unknown
parallel parallel

prev layer
isinst tupl
shape input shape tupl directli
isinst tensor
shape shape shape

shape shape thi dataset

alloc share output

alloc output buffer store activ fprop
realloc alreadi exist
onli alloc space layer own output bia activ work place
output
output alloc alloc pool share output provid

argument
share output tensor option alloc tensor activ
comput


output

own output
output iobuf shape share share output
parallel parallel

delta delta buffer

alloc layer contain buffer backpropag error
onli delta layer delta
onli alloc space layer own delta bia activ work place
delta

argument
delta buffer alloc tensor provid layer contain


layer layer parallel parallel
own delta

own delta prev layer
prev layer branch node color nois
delta prev layer delta

delta iobuf shape share delta buffer
parallel parallel
delta buffer revers

delta

layer
layer layer

fprop input infer

appli forward transform input

argument
input tensor input

return
tensor output

not implement error

fprop infer input

appli forward transform input

skip comput need infer

call bprop subsequ valid

argument
input tensor input

return
tensor output

not implement error

bprop error

appli backward transform input

argument
error tensor delta back propag adjac higher layer

return
tensor delta propag adjac lower layer

not implement error

termin

use recurs get node layer contain



serial

state paramet layer

return
whatev model want receiv order restor state




load weight pdict load state
pdict
load state
state pdict

param attr
dict parallel parallel data model
distribut parallel model

pdict


state pdict


batch size
actual


actual

descript kwarg

layer paramet paramet need optim
weight serial

argument

layer descript kwarg


branch node layer

layer allow branch use send output multipl layer pathway
each pathway entir output layer preced branch node

instanc

name

branch node need uniqu name
identifi thi method check
branch node made alreadi
creat name return


name instanc
instanc name

layer name name

init name
init

name branch node instanc
branch node instanc name
branch node init name
own output

fprop input infer


pass output preced layer without modif

output input
output input
output

configur

set shape base paramet layer given input tupl
input layer

argument
tupl layer tensor provid shape
inform layer

return
tupl shape output

hasattr shape
previous configur
branch node configur
shape shape


delta delta buffer
delta
delta iobuf shape share delta buffer
delta buffer revers

bprop error alpha beta

branch node skip bprop sinc delta share




skip node layer

layer allow


init name
skip node init name
own delta

fprop input infer beta

pass output preced layer without modif

output output beta input
output

configur

set shape base paramet layer given input tupl
input layer

argument
tupl layer tensor provid shape
inform layer

return
tupl shape output

skip node configur
shape shape


bprop error alpha beta

skip node back

delta delta beta alpha error
delta


pool layer


pool layer implement

argument
fshape tupl dimension shape
pool window
option pool oper default
stride dict option stride appli pool window
appli dimens dict
appli dimens distinctli default

pad dict option pad appli edg
input appli dimens dict
appli dimens distinctli default

name option layer name default pool layer


init fshape stride pad
name
pool init name
poolparam

paramat

keep arg around dict descript

fshape fshape
stride stride
pad pad
own delta
isinst fshape
fshape fshape fshape
isinst fshape tupl
fkey fshape
fshape fkey fshape
fshape
fshape dict
isinst stride
stride stride stride
isinst pad
pad pad pad
fshape stride pad
poolparam updat
nglayer


pool layer input output
name
shape shape shape
shape shape shape

configur
pool configur
nglayer
isinst shape tupl
ikey shape
shapedict ikey shape
shapedict
poolparam updat shapedict
poolparam
poolparam shapedict
poolparam shapedict
nglayer pool layer dtype poolparam
nglayer dim o
shape shape


delta delta buffer
pool delta delta buffer

argmax output shape dtype uint8

argmax

fprop input infer beta
input input
fprop pool nglayer input output argmax beta beta
output

bprop error alpha beta
bprop pool nglayer error delta argmax alpha beta
delta


paramet layer layer


intermedi use common function layer weight

intend use directli

argument
init initi option initi
initi layer weight
name option layer name default paramet layer


init init name
parallel unknown
paramet layer init name parallel

init init


weight shape
batch
batch shape
state
own delta

classmethod
pdict
init pdict pdict init
cname pdict init
icl load cname
init icl pdict init config
pdict init init
pdict

alloc share output
paramet layer alloc share output

init weight shape
batch shape
batch batch shape dtype float32
param attr

init shape

alloc layer paramet buffer initi
suppli initi

argument
shape tupl shape alloc layer paramet
buffer

shape param attr
like
state

isinst init tensor isinst init ndarray
init shape shape initi weight shape match
init

init fill



layer paramet gradient state optim

state

serial keep state
descript weight keep state keep state

descript weight keep state

layer paramet paramet need optim
weight serial

argument
keep state control whether paramet return
weight serial default

serial dict paramet layer descript
weight
serial dict
keep state
serial dict state state
serial dict

pdict

layer paramet weight alloc space paramet initi


argument
pdict dict ndarray dictionari ndarray layer paramet
support ndarray deprec remov

pdict dict
pdict
hasattr
setattr

attr getattr
isinst attr tensor
attr alreadi alloc
valu
attr pdict
pdict ndarray
setattr pdict param attr

setattr pdict


like

state pdict
state pdict
state serial leav
optim initi
state

need done step mgpu backend
state state
state zero like
rang pdict state

rang pdict state
state pdict state


convolut paramet layer


convolut layer implement

argument
fshape tupl three dimension shape convolut window
stride dict option stride appli convolut
window appli dimens dict
appli dimens distinctli default

pad dict option pad appli edg
input appli dimens dict
appli dimens distinctli default

init initi option initi
initi layer weight
name option layer name default convolut layer


init fshape stride pad init bsum
name parallel data
convolut init init name parallel
nglayer
bsum bsum determinist
convparam

bsum bsum paramat

keep around arg dict descript
fshape fshape
stride stride
pad pad
bsum bsum

isinst fshape tupl isinst fshape
fkey fshape
fshape fkey fshape
isinst stride
stride stride stride
isinst pad
pad pad pad
fshape stride pad
convparam updat


spatial shape
spatial join spatial
padstr join spatial
padstr spatial

tupl tupl convparam padstr
tupl tupl convparam padstr

tupl name shape shape tupl tupl
convolut layer
spatial input spatial output
padstr pad padstr stride

tupl

configur
convolut configur
nglayer
isinst shape tupl
ikey shape
shapedict ikey shape
shapedict
convparam updat shapedict
nglayer conv layer dtype convparam
nglayer dim o
shape
weight shape
weight shape nglayer dim f2
convparam bsum
batch shape nglayer


fprop input infer beta
input input
fprop conv nglayer input output beta beta
bsum batch
output

bprop error alpha beta
delta
bprop conv nglayer error delta
alpha alpha beta beta
updat conv nglayer input error
delta


deconvolut paramet layer


deconvolut layer implement

argument
fshape tupl three dimension shape convolut window
stride dict option stride appli convolut
window appli dimens dict
appli dimens distinctli default

pad dict option pad appli edg
input appli dimens dict
appli dimens distinctli default

init initi option initi
initi layer weight
name option layer name default deconvolut layer


init fshape stride pad init bsum
name
deconvolut init init name
nglayer
bsum bsum determinist
deconvparam

bsum bsum

keep around arg dict descript
fshape fshape
stride stride
pad pad
bsum bsum

isinst fshape tupl
fshape nifm
fshape fshape fshape fshape
isinst stride
stride stride stride
isinst pad
pad pad pad
fshape stride pad
deconvparam updat


deconvolut layer input output
name
shape shape shape
shape shape shape

configur
deconvolut configur
nglayer
isinst shape tupl
shapedict shape
shape
shape

deconvparam updat shapedict
nglayer deconv layer dtype deconvparam
shape nglayer nglayer nglayer
weight shape
weight shape nglayer dim f2
deconvparam bsum
batch shape nglayer


fprop input infer

fprop deconv equival bprop conv
bprop conv take error delta grad
deconv bprop conv take input output grad

input input
bprop conv layer nglayer input grad output
bsum batch
output

bprop error alpha beta

bprop deconv equival fprop conv
fprop conv take input output
deconv fprop conv take error input delta output

delta
fprop conv nglayer error delta alpha alpha beta beta
updat conv nglayer error input
delta


linear paramet layer


fulli connect layer implement product input
weight

argument
nout tupl desir size shape layer output
init initi option initi
initi layer weight
name option layer name default linear layer


init nout init bsum name
linear init init name disabl
nout nout
input
bsum bsum


linear layer input output
name nout

configur
linear configur
nstep interpret shape shape
shape nout nstep
weight shape
weight shape nout
bsum
batch shape nout


fprop input infer beta

input input
actual actual
compound input output beta beta
bsum batch

actual actual
step nstep actual actual

compound
input step
output step
beta beta
bsum batch

output

bprop error alpha beta
delta
compound error delta alpha alpha beta beta
compound error input
delta


bia paramet layer


bia layer implement add learn bia input produc
output shape

argument
init initi option initi
initi layer bia
name option layer name default bia layer


init init name
bia init init name

own output
own delta


shape
layer bia layer size
name shape shape shape

layer bia layer size name bia size
layer

configur
bia configur
shape shape
bia size shape
weight shape
weight shape bia size


fprop input infer
output input input
output
output reshap bia size

output

bprop error
delta
delta error reshap shape
delta axi
error


activ layer


layer appli specifi transform input
produc output shape

gener use implemen nonlinear layer post activ

argument
transform transform transform fprop bprop
function appli
name option layer name default activ layer


init transform name
activ init name
transform transform
own output
own delta


activ layer
name transform name

classmethod
pdict
transform pdict
cname pdict transform
tcl load cname
mani activ arg
config pdict transform
pdict transform config
transf tcl pdict transform config
pdict transform transf
pdict

configur
activ configur
shape shape
nout interpret shape shape


fprop input infer
output input input
output transform input
output

bprop error
delta transform bprop output error
delta


data transform layer


layer appli specifi transform input fprop

onli support first layer network

argument
transform transform transform fprop appli
name option layer name default data transform layer


init transform name
data transform init name
transform transform
own output


data transform layer
name transform name

classmethod
pdict
pdict transform
icl load pdict transform
transform icl pdict transform config
pdict transform transform
pdict

configur
data transform configur
shape shape
nout interpret shape shape


fprop input infer
output input input
output transform input
output

bprop arg



color nois layer


implement colorspac nois perturb describ
krizhevski imag net classif deep convolut neural network

colorpca colorstd valu rel robust across differ imageset
valu provid krizhevski cuda convnet2 given imag
numpi ndarray imgdata imag imag
dimens channel requir valu
comput

imgdata imgdata reshap
colorstd colorpca linalg imgdata
colorstd sqrt colorstd

imgdata matrix first second third
blue green pixel valu dataset respect

argument
colorpca option element contain eigenvector compon
pixel covari matrix
colorstd option element contain sqrt eigenvalu
pixel covari matrix
nois coeff option standard deviat gaussian nois use
perturb color channel default
name option layer name default color nois layer


init colorpca colorstd nois coeff name color nois layer
color nois init name
use point reshap view input
nois
assum colorpca compon column eigvector
colorpca
colorpca 39731118 70119634 59200296
81698062 02354167 5761844
41795513 71257945 56351045
colorpca colorpca reshap astyp float32

colorstd
colorstd 72083305 09388853 78006099
colorstd colorstd reshap astyp float32

colorpca colorpca colorstd nois coeff
nois coeff nois coeff
nois norm nois coeff


color nois layer featur map name

configur
color nois configur
shape shape

shape


attribut error color nois use layer provid


alloc share output
color nois alloc share output
nois
thi expand matrix broadcast along dimens
bmat tile colorpca reshap

fprop input infer
output input
infer
output
popul nois nois coeff absorb bmat
fill normal nois
compound bmat nois output
alpha nois norm beta nois norm
output

bprop arg



compound layer

base macro layer

init bia batch norm activ name
compound layer init
batch norm bia
attribut error batchnorm bia cannot combin
activ activ
batch norm batch norm
bia bia
name name

classmethod
pdict
init bia activ
pdict pdict
cname pdict
icl load cname
config pdict
pdict config
pdict icl pdict config
pdict

init name
name
name name

postfilt layer
init name
bia
name name bia
append bia init bia name name
batch norm
name name bnorm
append batch norm name name
activ
name name activ classnm
append activ transform activ name name


affin compound layer


linear layer learn bia activ implement
compos separ linear bia batchnorm activ layer

argument
nout tupl desir size shape layer output
init initi option initi
initi layer weight bia
bia initi initi bia paramet
activ transform transform fprop bprop
function appli
name root name layer suffix automat
gener compon layer



init nout init bia
batch norm activ name
affin init bia bia batch norm batch norm
activ activ name name
append linear nout init bsum batch norm name name
postfilt layer


conv compound layer


convolut layer learn bia activ implement
compos separ convolut bia activ layer

argument
fshape tupl three dimension shape convolut window
init initi option initi
initi layer weight bia
stride dict option stride appli convolut
window appli dimens dict
appli dimens distinctli default

dict option pad appli edg
input appli dimens dict
appli dimens distinctli default

bia initi initi bia paramet
activ transform transform fprop bprop
function appli
name root name layer suffix automat
gener compon layer



init fshape init stride pad
bia
batch norm
activ
name
conv init bia bia batch norm batch norm
activ activ name name
append convolut fshape fshape stride stride pad pad
init init bsum batch norm
name name
postfilt layer


deconv compound layer


same conv layer composit deconvolut layer


init fshape init stride pad bia batch norm
activ name
deconv init bia bia batch norm batch norm
activ activ name name
append deconvolut fshape fshape stride stride pad pad
init init bsum batch norm
postfilt layer


layer


local respons normal layer thi layer normal output
pixel element across channel formula

math

output frac output ascal bpower

math input element coordin math featur
math output correspond normal output
taken math rang math depth depth

argument
depth neighbor featur map
normal depth must depth
neighbor includ side zero ad
need
ascal normal scale factor equat
bpower normal expon equat
name layer name



init depth alpha beta ascal bpower name
init name name
depth
depth depth need serial
alpha alpha
beta beta
ascal ascal
bpower bpower
own delta
lrnparam
nglayer

configur
configur
nglayer
isinst shape tupl
ikey shape
shapedict ikey shape
shapedict
lrnparam updat shapedict
nglayer layer dtype lrnparam
shape shape


alloc share output
alloc share output
denom iobuf shape

fprop input infer
input input
fprop nglayer
input output denom
alpha beta ascal bpower
output

bprop error
delta
bprop nglayer
input output error delta denom
alpha beta ascal bpower
delta


dropout layer


dropout layer

appli element wise multipl input keep mask

keep mask tensor one zero shape input

each fprop call gener keep mask stochast
distribut one mask control keep param

argument
keep fraction input stochast kept


init keep name
dropout init name
keep keep
keep mask
caff mode check caff compat
caff mode
train scale keep scale factor train

train scale scale factor retain binari mask
own output


dropout layer input output keep caff compat
name nout keep caff mode

configur
dropout configur
shape shape
nout interpret shape shape


alloc share output
dropout alloc share output
keep mask iobuf shape parallel parallel

fprop input infer
output input input
infer
fprop infer input

make binari mask keep mask keep
output keep mask input train scale

output

fprop infer input
caff mode
output input keep
output

bprop error alpha beta
delta
delta error
delta keep mask error alpha train scale beta error
delta


lookup tabl paramet layer


lookup tabl layer word embed layer

layer convert word dens represent when given sentenc
vector word integ matrix vector embed
word sentenc return

lookup tabl dimens embed vocab size learnt

input shape batch size

output shape embed batch size

weight shape embed vocab size

argument
vocab size number word vocabulari
embed desir size word embed
init initi initi initi layer weight
name option layer name default lookup tabl layer


init vocab size embed init updat
name
lookup tabl init init name
embed embed
vocab size vocab size
updat updat

output


lookup tabl layer input output size
embed

configur
lookup tabl configur
nstep interpret shape shape
shape embed
weight shape
weight shape vocab size embed


alloc
lookup tabl alloc
input
input zero
dtype int32 input float32



output
output like output

fprop input infer
input input reshap input shape
output take input axi
output output
output

bprop error alpha beta
updat

compound bprop input error output
alpha beta

delta


gener cost nervana object


cost layer appli provid cost comput error
respect input target

argument
costfunc cost costfunc comput error


init costfunc name
gener cost init name
costfunc costfunc
output
delta

classmethod
pdict
pdict costfunc
ccl load
config pdict costfunc
pdict costfunc config
pdict costfunc ccl pdict costfunc config
pdict

initi

determin dimens cost error buffer alloc space input layer

argument
layer input layer calcul cost


isinst layer
prev layer
nstep interpret shape shape
output iobuf nstep
delta iobuf shape
parallel prev layer parallel
cost

cost input target

comput cost input target

argument
input tensor tensor contain input valu compar
target
target tensor tensor contain target valu

return
tensor contain cost

output costfunc input target
cost mean output axi
cost

error input target

comput deriv cost

argument
input tensor tensor contain input valu compar
target
target tensor tensor contain target valu

return
tensor shape input contain respect
delta

delta costfunc bprop input target
delta


gener cost mask gener cost


cost layer appli provid cost comput error
respect input target appli mask delta

argument
costfunc cost costfunc comput error


cost input target mask

comput cost input target

argument
input tensor tensor contain input valu compar
target
target mask tensor tensor tupl tensor target valu tensor mask

return
tensor contain cost

target mask target mask
mask input input mask
output costfunc mask input target
cost mean output axi
cost

error input target mask

comput deriv cost

argument
input tensor tensor contain input valu compar
target
target mask tensor tensor tupl tensor target valu
tensor mask

return
tensor shape input contain respect
delta

target mask target mask
delta costfunc bprop input target mask
delta


batch norm layer


batch normal layer describ ioffe2015

normal batch worth input subtract batch mean
divid batch varianc then scale learn factor gamma
shift learn bia beta

use input fprop infer precomput batch
suppli previou layer input tupl still
need comput

note

ioffe2015 http arxiv 1502 03167


init name
batch norm init name
allparam
use point reshap view input
xhat

own delta
error view


state rang
relu
beta
gamma
gmean
gvar
stat dtype float64 dtype float64 float32


batch norm layer input step featur map
name nstep

configur
batch norm configur
shape shape
nstep interpret shape shape
shape isinst shape tupl


alloc share output
batch norm alloc share output
output reshap
xvar zero dtype stat dtype
allparam
init
prev layer getattr prev layer batch
xsum zero
dtype stat dtype param attr
xsum reduc
comput batch

xsum prev layer batch
comput batch

init dim0
beta zero dim0 dtype stat dtype param attr
gamma one dim0 dtype stat dtype param attr
beta gamma

grad zero like
zero like

grad beta grad gamma grad
gmean gvar

allparam

properti
plist
grad state

fprop input infer beta

normal input batch mean varianc
xhat xmean xvar

scale shift normal input xhat learn paramet gamma beta
xhat gamma beta

accumul partial result mean varianc buffer use infer

input input input
input input reshap

infer
fprop infer input beta

comput batch
xsum input axi

compound fprop
input xsum xvar gmean gvar
gamma beta output beta relu

output

fprop infer input beta

appli linear transform captur normal gamma scale beta shift

xhat input gmean sqrt gvar tree
beta xhat gamma beta
output

bprop error alpha beta

comput gradient learn gamma beta well layer weight

alpha beta
error view
error view error reshap

compound bprop delta grad gamma grad beta
error view
input xsum xvar gamma

delta


plist

serial keep state
descript weight keep state keep state

descript weight keep state

layer paramet

argument
weight control whether paramet return
weight serial default
keep state control whether state return

serial dict batch norm descript
weight
serial dict
beta gamma gmean gvar
serial dict getattr

keep state
serial dict state slist slist state
serial dict

pdict
pdict dict
pdict iteritem
isinst getattr tensor
getattr

setattr param attr

beta gamma
gmean gvar
allparam

logger error use serial format thi
deprec futur releas resav serial file
current format

allparam param attr pdict
allparam
allparam
beta gamma
gmean gvar

grad zero like
grad beta grad gamma grad

state pdict
state
state param attr slist
slist pdict state

dlist slist state pdict state
dlist slist



batch norm autodiff batch norm


exampl autodiff batchnorm


init name
batch norm autodiff init name

forward optre

initi fprop optre batchnorm

fprop tree
xvar axi
xmean mean axi
xhat xmean sqrt xvar
xhat gamma beta

fprop input infer

comput actual fprop tree updat estim

infer
fprop infer input
init buffer input
allparam
init
fprop tree forward optre

actual prop
fprop tree

infer
gmean gmean mean axi
gvar gvar axi

output

bprop error

autodiff back prop grad back propag gradient
correspond tensor

delta
delta error reshap

autodiff automat cach reus
know error buffer init also creat autodiff
layer init
autodiff fprop tree error delta

back propag
back prop grad gamma beta
delta grad gamma grad beta

error

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon layer layer paramet layer layer
neon util persist load


step shape

convert featur size step batch size
featur size batch size step view

step shape

step rang step
reshap shape
step step rang step


recurr paramet layer


basic recurr layer

argument
output size number hidden output unit
init initi function initi model input hidden weight
initi also use recurr paramet
init inner also specifi bias alway
initi zero
init inner initi option function initi model recurr
paramet absent
initi provid init
activ transform activ input modul
reset cell make layer state
stateless
name option name refer layer

attribut
input tensor weight input output unit
input size output size
recur tensor weight recurr connect
output size output size
tensor bias output unit output size


init output size init init inner activ
reset cell name
recurr init init name

delta
nout output size
output size output size
nout output size
activ activ
output
input
ngate
reset cell reset cell
init inner init inner

configur
recurr configur
nstep shape
shape nout nstep
gate shape nout ngate nstep
weight shape
weight shape nout


alloc share output
recurr alloc share output
step output shape
prev
state delta
delta step iobuf shape shape
buf reset output

input
init weight shape

delta delta buffer
recurr delta delta buffer
delta buffer delta
delta step delta buffer shape

init buffer input

initi buffer recurr unit output
buffer initi tensor second dimens step batch size
second dimens order s1b1 s1b2 s1bn s2b1 s2b2 s2bn
view creat buffer easi manipul
relat certain time step

argument
input tensor input tensor dimens
input size sequenc length batch size


input

buf reset

input
step input shape

init shape

initi includ weight bias
weight matrix bia matrix concaten weight
input weight recurr input bia

argument
shape tupl contain output input


nout shape
nout ngate nout
do fill


nout nout
zero like
do fill

deseri weight grad
shape nout nout
shape nout nout

input reshap nout
recur reshap nout nout
reshap nout

do fill
gatelist nout rang ngate
wtnm input recur
wtmat getattr wtnm
wtnm recur init inner
initfunc init inner

initfunc init

gatelist gatelist
initfunc fill wtmat
fill

input reshap input shape
recur reshap recur shape
reshap shape

fprop input infer

forward propag input recurr layer

argument
input tensor input model time step
unrol input minibatch
shape featur size sequenc length batch size


featur size input size
sequenc length degre model unrol
batch size input mini batch

infer option run
infer care forward
propag without associ backward
propag default

return
tensor layer output activ time step
unrol input minibatch
shape output size sequenc length batch size

init buffer input

reset cell


recurr layer need prev buffer bprop
prev bprop

prev prev
compound input
compound recur prev beta
activ

output

bprop delta alpha beta

backward propag error recurr layer

argument
delta tensor tensor contain error
step model unrol expect shape
output size sequenc length batch size
alpha option scale appli input activ
gradient bprop default
beta option scale appli output activ
gradient bprop default

return
tensor back propag error step time unrol
mini batch element
shape input size sequenc length batch size



delta
delta step delta shape
prev delta delta delta

prev bprop delta
delta prev delta delta

prev delta delta
prev delta delta revers

delta activ bprop delta
compound recur delta delta
prev delta prev delta delta
prev
compound delta prev recur beta
compound delta input beta
delta axi
save comput bprop activ gradient
delta
compound input delta delta alpha alpha beta beta

delta buffer

load weight pdict load state
recurr load weight pdict load state
activ member
lcfg pdict config
dict activ
lcfg lcfg config
setattr load


lstm recurr


long short term memori lstm layer base
hochreit schmidhub neural comput 1735 1997

argument
output size number hidden output unit
init initi function initi model input hidden weight
initi also use recurr paramet
init inner also specifi bias alway
initi zero
init inner initi option function initi model recurr
paramet absent
initi provid init
activ transform activ input modul
gate activ transform activ gate
reset cell make layer state
stateless
name option name refer layer

attribut
tensor input tensor dimens
input size sequenc length batch size
input tensor weight input unit
size input size
recur tensor weight recurs input
size size
tensor bias size

init output size init init inner activ
gate activ reset cell name
lstm init output size init init inner
activ reset cell name
gate activ gate activ
ngate input output forget cell

alloc share output
lstm alloc share output
indic slice gate buffer
ifo1 ifo2 nout
nout
nout nout
nout nout
nout nout

state hidden cell previou hidden previou cell
buffer iobuf shape
step buffer shape
prev
prev bprop

buffer iobuf shape
step buffer shape

gate input forget output input modul
ifog buffer iobuf gate shape
ifog step ifog buffer gate shape
gate ifo1 ifo2 gate ifog
gate gate ifog
gate gate ifog
gate gate ifog
gate gate ifog

state delta
delta buffer iobuf shape
delta step delta buffer shape
delta prev delta

activ gate delta
ifog delta buffer iobuf gate shape
ifog delta step ifog delta buffer gate shape
delta gate gate ifog delta
delta gate gate ifog delta
delta gate gate ifog delta
delta gate gate ifog delta
buf reset append buffer

fprop input infer

appli forward transform input input
input element time step
model unrol

argument
input tensor input tensor convert
slice dimens
input size sequenc length batch size
infer option run
infer care forward
propag without associ backward
propag default

return
tensor lstm output model time step

init buffer input

reset cell



prev ifog
prev

prev ifog prev
compound recur prev ifog
compound input ifog beta
ifog ifog

gate activ
activ

prev
activ


output

bprop delta alpha beta

backpropag error output delta previou layer
calcul updat model

argument
delta tensor tensor contain error
step model unrol
expect shape
output size sequenc length batch size
alpha option scale appli input activ
gradient bprop default
beta option scale appli output activ
gradient bprop default

attribut
input tensor input weight gradient
recur tensor recurs weight gradient
tensor bia gradient

return
tensor backpropag error time step
model unrol

delta buffer


delta
delta step delta shape
prev delta delta delta
ifog delta last step ifog delta buffer
first step output

delta delta prev delta
ifog delta
delta delta delta delta
delta delta prev prev bprop

delta delta prev delta
ifog delta delta delta delta delta
delta delta prev prev revers

current cell delta
delta delta activ bprop delta
delta gate activ bprop delta
delta gate activ bprop delta prev
delta gate activ bprop delta
delta activ bprop delta

delta
compound recur ifog delta delta

delta prev
delta prev delta

prev delta prev delta delta

weight delta accumul
compound ifog delta last step first step recur
compound ifog delta buffer input

bia delta accumul
ifog delta buffer axi

delta
delta buffer save comput
compound input ifog delta buffer delta buffer
alpha alpha beta beta

delta buffer


recurr


implement gate recurr unit base cho2014

use gate reset gate updat gate
updat gate decid much activ updat
reset gate decid much reset previou activ
activ linear interpol previou
activ candid activ
comput differ weight
gate activ unit activ usual differ
gate activ usual logist
unit activ usual tanh
consid gate

argument
output size number hidden output unit
init initi function initi model input hidden weight
initi also use recurr paramet
init inner also specifi bias alway
initi zero
init inner initi option function initi model recurr
paramet absent
initi provid init
activ transform activ input modul
gate activ transform activ gate
reset cell make layer state
stateless
name option name refer layer

attribut
tensor input tensor input size sequenc length batch size
input tensor weight input unit
size input size
recur tensor weight recurs input
size size
tensor bias size

refer

learn phrase represent encod decod
statist machin translat cho2014
empir evalu gate recurr neural network sequenc model
chung2014

cho2014 http arxiv 1406 1078
chung2014 http arxiv 1412 3555v1


init output size init init inner activ
gate activ reset cell name
init output size init init inner
activ reset cell name
gate activ gate activ
ngate candid

alloc share output
alloc share output
prev bprop

indic slice gate buffer
nout
nout
nout nout
nout nout

buffer
prev buffer previou hidden multipli
recur hcan delta
prev buffer iobuf shape
prev step prev buffer shape
iobuf nout

gate reset updat candid hcan
rzhcan buffer iobuf gate shape
rzhcan step rzhcan buffer gate shape
gate gate rzhcan
gate gate rzhcan
gate gate rzhcan
hcan gate gate rzhcan

buffer deal recurr input gate
rzhcan buffer iobuf gate shape
rzhcan step rzhcan buffer gate shape
gate gate rzhcan
hcan gate gate rzhcan

activ gate delta
rzhcan delta buffer iobuf gate shape
rzhcan delta step rzhcan delta buffer gate shape
delta gate gate rzhcan delta
delta gate gate rzhcan delta
delta gate gate rzhcan delta
hcan delta gate gate rzhcan delta

init shape

initi includ weight bias
weight matrix bia matrix concaten weight
input weight recurr input bia
shape weight input output
output

argument
shape tupl contain output input


init shape
nout shape

indic slice gate buffer
nout
nout nout

recur recur
whcan recur recur


hcan

d wrz recur recur
d whcan recur recur

fprop input infer

appli forward transform input input
input element time step model unrol

argument
input tensor input tensor convert tensor
dimens input size sequenc length batch size
infer option run
infer care forward
propag without associ backward
propag default

return
tensor output model time step

init buffer input

reset cell


hcan

prev prev hcan hcan rzhcan
prev prev
hcan hcan rzhcan

comput hcan input
compound input rzhcan

comput hcan recurr
compound recur prev
gate activ
prev prev
compound whcan recur prev hcan

hcan activ hcan hcan hcan
prev hcan

output

bprop delta alpha beta

backpropag error output delta previou layer calcul updat
model

argument
delta tensor error tensor time step unrol
act option carri activ default
alpha option scale appli input activ
gradient bprop default
beta option scale appli output activ
gradient bprop default

attribut
input tensor input weight gradient
recur tensor recurr weight gradient
tensor bia gradient

return
tensor backpropag error time step model unrol




delta
delta step delta shape
prev delta delta delta

hcan prev prev bprop
delta delta hcan delta delta rzhcan delta
delta delta prev delta

hcan prev prev delta delta hcan delta delta
rzhcan delta delta delta prev delta revers

hcan delta
hcan delta activ bprop hcan delta
delta gate activ bprop delta hcan prev

delta
compound whcan recur hcan delta delta
delta gate activ bprop delta prev

hidden delta
delta delta
compound recur delta delta beta
compound whcan recur hcan delta
delta delta

prev
compound delta prev d wrz recur beta
compound hcan delta prev d whcan recur beta

prev delta prev delta delta

weight delta accumul
compound rzhcan delta buffer input batch
rzhcan delta buffer axi

delta
delta buffer save comput
compound input rzhcan delta buffer delta buffer
alpha alpha beta beta

delta buffer


recurr output layer


layer combin recurr layer output time step
collaps time dimens sever way these layer
paramet optim train

option deriv
recurr sum recurr mean recurr last



init name
name name name classnm
recurr output init name
own output own delta



recurr output choic input output
name nstep

configur
recurr output configur
nstep shape
shape


delta delta buffer
recurr output delta delta buffer
delta buffer delta
delta
delta step delta buffer shape

delta simplifi bprop notat

init buffer input

initi buffer recurr unit output
buffer initi tensor second dimens step batch size
view creat buffer easi manipul
relat certain time step

argument
input tensor input tensor dimens
input size sequenc length batch size


input
input
step input shape


recurr sum recurr output


layer sum recurr layer output time

configur
recurr sum configur
sumscal


fprop input infer
init buffer input
output fill

output output sumscal
output

bprop error alpha beta
delta delta
delta alpha sumscal error delta beta
delta buffer


recurr mean recurr sum


layer get averag recurr layer output time

configur
recurr mean configur
sumscal nstep



recurr last recurr output


layer keep recurr layer output last time step


fprop input infer
init buffer input
output
output

bprop error alpha beta
delta
lstm layer alloc hidden unit delta buffer overwrit
bprop init zero
delta buffer fill
delta alpha error
delta buffer


bi rnn paramet layer


basic direct recurr layer

argument
output size number hidden output unit
init initi function initi model paramet
init inner initi option function initi model recurr
paramet absent
initi provid init
activ transform activ input modul
reset cell make layer state
stateless
split input expect input come sourc separ
sourc
name option name refer layer

attribut
input tensor weight input output unit
input size output size
recur tensor weight recurr connect
output size output size
tensor bias output unit output size


init output size init init inner activ
reset cell split input name
bi rnn init init name
delta
delta
nout output size
nout output size
output size output size
activ activ
buffer
input
ngate
split input split input
reset cell reset cell
init inner init inner


split input
bi rnn layer input output step
name nout nstep

bi rnn layer input output step
name nout nstep

configur
bi rnn configur
nstep shape

shape nout nstep
gate shape nout ngate nstep

split input
valu error input unit split input

shape nout nstep
shape nout ngate nstep
shape
nstep split input nstep

weight shape
weight shape nout


alloc share output
bi rnn alloc share output

nout shape
buffer output
delta buffer delta

forward
buffer buffer nout
step buffer shape
prev

backward
buffer buffer nout
step buffer shape

buf reset buffer

input
init weight shape

delta delta buffer
bi rnn delta delta buffer
delta buffer delta
shape
split input
delta buffer delta buffer
delta buffer delta buffer

delta buffer delta buffer
delta buffer delta buffer
delta step delta buffer shape
delta step delta buffer shape

init buffer input

initi buffer recurr unit output
buffer initi tensor second dimens step batch size
view creat buffer easi manipul
relat certain time step

argument
input tensor input tensor dimens
input size sequenc length batch size


split input
layer connect forward connect

input shape
input shape

input
input
step shape
step shape
buf reset


init shape

initi lstm includ weight bias
weight matrix bia matrix concaten weight
input weight recurr input bia
shape weight input output
output

argument
shape tupl contain output input


nout shape shape
nout ngate nout
wshape nout nout
do fill

weight input recurr bia

wshape
zero like
do fill

deseri weight grad
shape wshape
shape wshape

input reshap nout
input reshap nout

recur nout reshap nout nout
recur
nout nout reshap nout nout

reshap nout
reshap nout

input reshap input shape
input reshap input shape

recur
nout reshap recur shape
recur
nout nout reshap recur shape

reshap shape
reshap shape

do fill
gatelist nout rang ngate
wtnm input input recur recur
wtmat getattr wtnm
recur wtnm init inner
initfunc init inner

initfunc init

gatelist gatelist
initfunc fill wtmat
fill
fill

fprop input infer

forward propag input direct recurr layer

argument
input tensor input model time step
unrol input minibatch
shape featur size sequenc length batch size


featur size input size
sequenc length degre model unrol
batch size input mini batch

infer option run
infer care forward
propag without associ backward
propag default

return
tensor layer output activ time step
unrol input minibatch
shape output size sequenc length batch size

init buffer input

reset cell



recurr layer need prev buffer bprop
prev bprop
bprop
prev prev
compound input
compound recur prev beta
activ

revers
compound input
compound recur beta
activ

buffer

bprop error alpha beta

backward propag error direct recurr layer

argument
delta tensor tensor contain error
step model unrol
shape output size sequenc length batch size
alpha option scale appli input activ
gradient bprop default
beta option scale appli output activ
gradient bprop default

return
tensor back propag error step time unrol
mini batch element
shape input size sequenc length batch size



delta
delta step error nout shape
prev delta delta delta

delta
delta step error nout shape
delta delta delta

prev bprop delta
prev delta delta

bprop delta
delta delta

delta buffer
error propag right left
prev delta
prev delta delta revers

delta activ bprop delta
compound
recur delta prev delta beta
prev
compound
delta prev recur beta
compound delta input beta
delta axi
delta
compound input delta delta
alpha alpha beta beta

error propag left right
delta
delta delta

delta activ bprop delta
compound
recur delta delta beta

compound
delta recur beta
compound delta input beta
delta axi
delta
propag error input split input
compound input delta delta
alpha alpha beta beta split input

delta buffer


bi lstm bi rnn


long short term memori lstm

argument
output size number hidden output unit
init initi function initi model paramet
init inner initi option function initi model recurr
paramet absent
initi provid init
activ transform activ input modul
gate activ transform activ gate
reset cell make layer state
stateless
split input expect input come sourc separ
sourc
name option name refer layer

attribut
tensor input tensor dimens
input size sequenc length batch size
input tensor weight input unit
size input size
recur tensor weight recurs input
size size
tensor bias size



init output size init init inner activ
gate activ reset cell split input name
bi lstm init
output size init init inner activ split input name
gate activ gate activ
ngate input output forget cell
reset cell reset cell


bi lstm layer input output step
name nout nstep

alloc share output
bi lstm alloc share output
nout shape
indic slice gate buffer
ifo1 ifo2 nout
nout
nout nout
nout nout
nout nout

state hidden cell previou hidden previou cell forward cell
buffer iobuf shape
step buffer nout shape
prev
prev bprop
step buffer nout shape

bprop

buffer iobuf shape
step buffer nout shape
step buffer nout shape

hidden delta

forward gate input forget output input modul
ifog buffer iobuf gate shape
ifog step
ifog buffer ngate nout shape
gate ifo1 ifo2 gate ifog
gate gate ifog
gate gate ifog
gate gate ifog
gate gate ifog
backward gate input forget output input modul
ifog step
ifog buffer ngate nout shape
gate ifo1 ifo2 gate ifog
gate gate ifog
gate gate ifog
gate gate ifog
gate gate ifog

state delta
delta buffer iobuf shape
delta step delta buffer shape
delta prev delta
delta delta

activ gate delta
ifog delta buffer iobuf shape
ifog delta step ifog delta buffer shape
delta gate gate ifog delta
delta gate gate ifog delta
delta gate gate ifog delta
delta gate gate ifog delta
buf reset append buffer

fprop input infer

appli forward transform input

argument
input tensor tensor time
step model unrol
infer option run
infer care forward
propag without associ backward
propag default

return
tensor lstm output model time step

init buffer input call bi rnn init buffer code

reset cell





prev ifog
prev
ifog


prev ifog prev
compound recur prev ifog
compound input ifog beta
ifog ifog

gate activ
activ

prev
activ


ifog revers
compound recur ifog
compound input ifog beta
ifog ifog

gate activ
activ

activ


buffer

bprop error alpha beta

backpropag error output delta previou layer
calcul updat model

argument
error tensor error tensor time step
unrol
alpha option scale appli input activ
gradient bprop default
beta option scale appli output activ
gradient bprop default

return
tensor backpropag error time step model unrol



delta
delta step error shape shape
prev delta delta delta
ifog delta last step ifog delta buffer

first step buffer
delta delta delta

delta
delta step error shape shape
delta delta delta
ifog delta first step ifog delta buffer

last step buffer
delta delta delta

delta prev delta

ifog delta delta delta delta delta
delta delta prev prev bprop

delta delta

ifog delta delta delta delta delta
delta delta bprop

bprop forward direct connect error flow right left
delta buffer
ifog delta buffer
ifog delta
ifog delta
delta prev delta

ifog delta delta delta delta delta
delta delta prev prev revers

current cell delta
delta delta
activ bprop delta
delta gate activ bprop delta
delta gate activ bprop delta prev
delta gate activ bprop delta
delta activ bprop delta

bprop error prev delta delta prev
compound
recur ifog delta prev delta beta
delta prev
delta prev delta

weight delta accumul
compound
ifog delta last step first step recur
compound
ifog delta buffer input
ifog delta buffer axi
delta input unit
delta buffer
compound
input ifog delta buffer delta buffer
alpha alpha beta beta

bprop backward direct connect error flow left right
delta buffer
ifog delta buffer
delta delta

ifog delta delta delta delta delta
delta delta

current cell delta
delta delta
activ bprop delta
delta gate activ bprop delta
delta gate activ bprop delta
delta gate activ bprop delta
delta activ bprop delta

bprop error delta delta
compound
recur ifog delta delta beta
delta
delta delta

weight delta accumul
compound
ifog delta first step last step recur
compound
ifog delta buffer input
ifog delta buffer axi
delta input unit bprop input
split input
delta buffer
compound input ifog delta buffer
delta buffer alpha alpha
beta beta input
delta buffer


deep bi rnn


stack direct recurr layer

argument
nout tupl desir size shape layer output
init initi initi initi weight
activ transform activ input modul
reset cell make layer state
stateless
depth option number layer bi rnn



init nout init init inner activ reset cell depth
init
depth
valu error depth

append bi rnn nout init init inner activ reset cell split input
rang depth
append bi rnn nout init init inner activ reset cell split input


deep bi lstm


stack direct lstm layer

argument
nout tupl desir size shape layer output
init initi initi initi weight
activ transform activ input modul
reset cell make layer state
stateless
depth option number layer bi rnn



init nout init init inner activ gate activ
reset cell depth
init
depth
valu error depth
append
bi lstm nout init init inner activ gate activ
reset cell split input
rang depth
append
bi lstm nout init init inner activ gate activ
reset cell split input

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi


neon nervana object
neon layer layer layer branch node dropout data transform
neon util persist load


flatten item
hasattr item iter
iter item
flatten


item


layer contain layer

layer contain gener use encapsul group layer
provid method propag constitu layer alloc memori

properti
layer optim

layer
isinst layer contain
layer optim

hasattr init init name ident

append


nest level
padstr level
level classnm padstr
padstr join nest level layer


classmethod
pdict
layer
layer pdict layer
layer
ccl load
layer append ccl layer config

layer special paramet
serial use elsewher
lsave pdict layer
layer layer pdict
pdict layer lsave


descript weight keep state
desc layer contain descript skip layer
desc contain
desc config layer
layer layer
desc config layer append layer descript weight weight
keep state keep state
desc desc
desc

load weight pdict load state
pdict config layer layer
branch bdict layer pdict config layer
branch load weight bdict load state load state

propag parallel
layer
isinst layer contain
parallel
propag parallel
termin
parallel isinst parallel

parallel parallel unknown parallel
parallel

batch size
layer
batch size


layer



sequenti layer contain

layer contain encapsul simpl linear pathway layer

argument
layer list object either layer
includ layer contain

init layer name
sequenti init name

layer flatten layer
layer filter branch node layer
root layer
root own output
root dropout data transform sequenti root must output

configur

must receiv shape configur pathway
shape correspond layer contain attribut

argument
shape layer shape tensor dataset

config layer layer layer
layer
sequenti configur
prev layer
config layer
configur
prev layer
prev layer
prev layer
parallel parallel
shape shape


alloc share output
layer output
alloc layer layer own output
alloc layer alloc share output
layer
alloc

alloc delta delta
need extra delta
issubclass broadcast

delta delta

delta
incept layer
size
layer
size share iobuf size shape parallel
size size
size size

ndelta buf need extra delta layer
size
delta iobuf
size parallel data rang ndelta buf

layer
delta delta

fprop input infer beta

todo handl layer output bia activ

input
infer
infer revert

layer
revert
alter tensor distribut parallel
alter tensor
infer
infer revert append alter tensor

revert append alter tensor

layer beta
fprop infer beta beta

fprop infer

infer
layer tensor infer revert
layer revert tensor tensor



bprop error alpha beta
revers layer
alter tensor distribut error parallel
alter tensor
revert append alter tensor

prev layer branch node layer
error bprop error alpha beta

error bprop error

tensor revert
revert tensor tensor
layer delta

termin
termin layer termin
termin


tree layer contain

layer contain encapsul simpl linear pathway layer

argument
layer list sequenti contain correspond branch tree
branch must provid main trunk first auxiliari
branch order branch node encount
name option name contain
alpha option weight factor appli branch
backpropag error


init layer name alpha
tree init name name
layer
layer
isinst sequenti
layer append
isinst
layer append sequenti
isinst layer
layer append sequenti

valu error incompat element tree contain

alpha layer alpha alpha

alpha beta use back propag
want branch order accord origin root
beta last appear root rest
trunk alway sinc contain branch node
beta
root
revers layer
root layer
beta root root root branch node
root root
beta append beta
beta revers

nest level
classnm
join nest level layer


configur
tree configur
layer configur

layer
configur
shape shape layer


alloc share output
layer
alloc
output output layer

alloc delta delta
revers layer
alloc delta

fprop input infer
layer fprop input infer
fprop layer


bprop error
revers layer error alpha beta
bprop alpha beta

termin
termin layer


singl output tree tree

subclass tree contain return
output main branch branch index
infer

fprop input infer
layer fprop input infer
infer


fprop layer



broadcast layer contain
init layer name
broadcast init name
input layer convert
list sequenti contain
singleton layer sequenti contain
leav sequenti alon
layer
layer
isinst sequenti
layer append
isinst
layer append sequenti
isinst layer
layer append sequenti

valu error incompat element name layer
own output
output


join layer
classnm


configur

set shape base paramet layer given input tupl
input layer

argument
tupl layer tensor dataset provid shape
inform layer

return
tupl shape output

broadcast configur

receiv singl sourc distribut branch
layer
configur
configur merg


delta delta buffer
delta buffer need extra delta buffer pool broadcast layer
layer
alloc delta delta buffer
layer delta delta buffer

special origin branch node
prev layer branch node
delta iobuf shape share prev layer delta
parallel parallel

delta iobuf shape share delta buffer
parallel parallel
delta buffer revers

termin
termin termin layer
termin


merg sum broadcast

alloc share output
output
output iobuf shape share share output
parallel parallel
layer
alloc share output output

configur merg

helper configur output shape

shape shape layer
shape shape

fprop input infer
layer
beta layer
fprop input infer beta beta
output

bprop error alpha beta
revers layer
beta layer
bprop error alpha alpha beta
delta


merg broadcast broadcast

branch singl incom layer broadcast multipl output path
combin merg

argument
layer layer layer contain either layer list
layer contain element
list wrap sequenti
contain
alpha option alpha valu weight
backpropag error
name contain name default merg broadcast

init layer merg alpha name

todo docstr

merg broadcast init layer name

beta layer
beta
alpha layer alpha alpha

merg merg merg broadcast get merg
merg recurr depth stack
error view

partit slice

given partit slice activ buffer determin axi slice
along depend whether sequenti tensor

shape thi sequenti
slice

slice

alloc share output
output
output iobuf shape share share output
parallel parallel
output view partit output slice
view layer output view
alloc share output view

configur merg

helper configur shape depend merg concaten

shape shape layer
figur merg
merg recurr
catdim shape
shape shape catdim
stride size
merg depth
catdim shape
shape catdim shape
stride size prod shape
merg stack
catdim isinst prod shape
shape catdim
stride size
stride size cumsum catdim
start
slice slice start

fprop input infer
layer
fprop input infer
output

bprop error alpha beta
beta beta
error view
error view partit error slice
revers layer error view alpha beta
bprop alpha alpha beta
delta


merg multistream merg broadcast

merg multipl input sourc concaten thi contain similar merg broadcast
receiv differ stream input directli dataset

init layer merg name
merg multistream init layer merg merg name name

configur

must receiv shape configur pathway
shape correspond layer contain attribut

argument
tensor data tensor provid sequenti contain

prev layer
isinst
hasattr shape isinst shape
shape
isinst multistream input must interpret shape
layer
configur
configur merg


delta delta buffer
layer
alloc delta

fprop input infer
layer input
fprop infer
output

bprop error alpha beta
error view
error view partit error slice
layer error view
bprop


roi pool sequenti

use pool convert featur insid small
featur spatial extend layer
paramet indepdend particular
each defin tupl xmin ymin xmax ymax

roi pool appli independ featur channel standard
pool

construct layer contain order dataset
directli process imag dataset contain
layer usual imag net layer combin ro is dataset
featur map output layer

roi pool contain process imag preset batch size while
pool minibatch extend batch size roi
exampl minibatch
output shape shape tupl batch size roi
follow layer alloc buffer accordingli


init layer bprop enabl
spatial scale 0625 name
layer
roi pool init layer name name


spatial scale spatial scale 0625
output buffer besid contain
own output
own delta

roi
roi
roi batch
bprop enabl bprop enabl

nest level
name


configur

must receiv shape configur
need layer contain dataset configur shape
imag shape shape 1000

configur shape featur
prev layer

isinst
hasattr shape isinst shape
make sure inform roi
dataset
hasattr roi
roi roi
hasattr roi batch
roi batch roi batch

shape

isinst
pool layer must interpret input shape

configur imag network layer layer featur shape
output shape


shape previou sequenti shape

layer
layer
configur
shape shape layer shape
channel height width shape
reshap shape
channel height width
error reshap channel

make shape tupl imag
time step dimens
shape channel roi


alloc share output
roi pool alloc share output
own output
error iobuf shape
output iobuf shape share share output
iobuf shape dtype int32

delta delta buffer
alloc delta

init buffer input

initi buffer imag ro is

input input must contain imag ro is
input
input
roi input
roi shape entri must valu tupl

fprop input infer

init buffer input

output fill
fill

fprop input imag
roi pool fprop infer

fprop roipool layer
roipool fprop roi output
roi batch channel height
width spatial scale

output

bprop error alpha beta

error fill

bprop enabl
bprop roipool layer
roipool bprop error roi error
roi batch channel height
width spatial scale

bprop back imagenet layer contain
delta roi pool bprop error alpha beta

termin
termin termin layer
termin


multicost nervana object

class use comput cost tree contain multipl output
cost must match output cost appli output
order occur tree

target use cost either provid dataset tupl
cost singl target provid target use
cost thi use provid multipl cost branch comput error
differ stage network goog le net


init cost weight name
multicost init name
cost cost
weight cost weight weight
error
input
costfunc cost costfunc display callback

classmethod
pdict
cost
cost pdict cost
cost
ccl load
cost append ccl cost config
pdict cost cost
pdict

initi
hasattr layer multi cost must pass layer contain
termin termin
cost termin
initi

properti
cost
cost cost

properti
output
cost output

descript kwarg
desc multicost descript
cost desc config cost
desc config cost
cost cost
desc config cost append cost descript
desc desc
desc

cost input target

comput cost input target

argument
input tensor tensor contain input valu compar
target
target tensor tensor either tensor contain target valu
singl target tensor map
input

return
tensor contain cost

isinst input
cost cost input target

ltarget target target tupl target cost
costval cost cost input ltarget
optre reduc weight costval
costval optre
costval

error input target

error backpropag tree contain multipl output
node

argument
input tensor tensor contain input valu compar
target
target tensor tensor either tensor contain target valu
singl target tensor map
input
return
tensor contain error input


target target target tupl target cost
error
error delta cost

cost input target
error

error

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon layer layer linear bia affin conv convolut gener cost dropout
pool activ data transform batch norm batch norm autodiff
deconv deconvolut gener cost mask lookup tabl
branch node skip node color nois
neon layer recurr recurr lstm recurr sum recurr mean recurr last
bi rnn bi lstm deep bi rnn deep bi lstm
neon layer contain tree sequenti merg multistream merg broadcast multicost
roi pool merg sum singl output tree

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi


tarfil

neon dataiter nervana data iter
neon dataset dataset
neon text preprocess sentenc


nervana data iter

gener contain take dataset alreadi
vector creat iter feed train

init stori queri answer
init name
stori queri answer stori queri answer
ndata stori
nbatch ndata
stori length stori shape
queri length queri shape
shape stori length queri length

iter

gener use iter dataset

yield
tupl minibatch

batch index
shuf permut stori
stori stori shuf
queri queri shuf
answer answer shuf

batch index nbatch
batch slice batch index batch index
stori tensor stori batch copi
queri tensor queri batch copi
answer tensor answer batch copi

batch index

stori tensor queri tensor answer tensor

reset

reset start index dataset back zero
relev want call repeat evalu dataset
want wrap around last uneven minibatch
necessari ndata divis batch size

batch index


babi dataset

thi load facebook b ab i dataset vector stori
question answer describ
toward complet question answer prerequisit task
http arxiv 1502 05698


init path task singl support fact subset

load b ab i dataset extract text read stori
particular task read train test file
combin vocabulari

arg
path directori store dataset
task particular task solv b ab i task train
test separ
subset subset dataset
shuffl shuffl

http thespermwhal jaseweston babi
size 11745123
filenam task
babi init filenam

size
path path
task task
subset subset

prepar b ab i dataset extract path
task subset task
task
singl support fact
support fact
three support fact
relat
three relat
question
count
list set
simpl negat
qa10 indefinit knowledg
qa11 basic corefer
qa12 conjunct
qa13 compound corefer
qa14 time reason
qa15 basic deduct
qa16 basic induct
qa17 posit reason
qa18 size reason
qa19 path find
qa20 agent motiv

task task given task b ab i dataset

train file test file load path task
train pars babi pars babi train file
test pars babi pars babi test file

comput statist
train vector stori train pars
test vector stori test pars

load path task singl support fact
subset

fetch facebook b ab i dataset load memori
arg
path option local directori cach
dataset default current directori
task option b ab i task load
subset option data come english hindi shuffl
charact option
shuffl 1000 train test
exampl
shuffl 10000 exampl
return
tupl train test file return

workdir filepath valid path append path filenam
path exist filepath
fetch dataset filenam filepath size

babi name filenam split
task babi name subset task
train file path join workdir task format train
test file path join workdir task format test

path exist train file path exist test file
tarfil open filepath
extractal workdir

train file test file

staticmethod


clean block split line

arg
string b ab i

return
list clean line b ab i

split line split
line decod strip line split line

staticmethod
token sentenc

split sentenc token includ punctuat

arg
sentenc string sentenc token

return
list token

strip split sentenc strip

staticmethod
flatten

flatten

arg
list word

return
singl flatten word

reduc

staticmethod
pars babi babi file

pars b ab i stori queri answer

arg
babi string b ab i

return
tupl list stori queri answer word

babi open babi file read
line babi babi

stori
line line
line line split

stori
line
support line split
substori stori
append substori babi token
stori append

sent babi token line
stori append sent

babi flatten stori question answer stori question answer

word vector word

convert word vector form

arg
word list word

return
vector word

word index word index
vocab size word

vector answer

creat represent answer

arg
answer word answer

return
represent answer

vector zero vocab size
vector word index answer
vector

vector stori

convert stori queri answer word vector

arg
tupl tupl stori queri answer word

return
tupl tupl stori queri answer vector


stori queri answer
append word vector stori
append word vector queri
append vector answer

sentenc stori maxlen
sentenc queri maxlen



comput statist

comput vocab word index length stori queri

train pars test pars
vocab sort reduc
vocab vocab
reserv mask sequenc vocab size token
vocab size vocab
word index dict enumer vocab
index word dict enumer vocab
stori maxlen
queri maxlen

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin speech dataset handl



speech

init
not implement error
collect counter
numpi


neon dataiter nervana data iter
neon dataset dataset


imag caption nervana data iter

thi load sentenc imag featur imag caption
taken andrej karpathi
deep visual semant align http stanford peopl karpathi deepimages
work convert format avoid scipi load
imag featur

dataset assum model take precomput featur
imag sentenc convert represent model
transform imag sentenc space
prepend imag sentenc treat first word
sequenc


token
imag size 4096 hard code featur size

init path imag

load vocab imag featur convert sentenc indic

arg
path directori contain sentenc imag featur
imag number imag load

imag caption init name

path path
read train imag sentenc path
read imag train
load vocab

train sent train img
sent enumer iter imag sentenc pair
train sent imag imag

train img append sent imag
sent token sent sentenc token
vocab index
train sent append sent sentenc length

nbatch train img
ndata nbatch

zero train sent sentenc length
zero train sent sentenc length
imag vstack train img

sent length train sent
sent end arang sentenc length newaxi
sent sent enumer train sent
sent sent vocab index word word sent


load vocab

load vocab initi buffer
input sentenc batch dimens vocab size sentenc length batch size
column represent word first batch size column
first word sentenc


sentenc sent token sent iter sentenc
flatten word word
word word sentenc sentenc word sentenc
count word keep word greater threshold
word count counter word

vocab token word word word count key word count word
vocab size vocab
vocab index dict enumer vocab
index vocab dict enumer vocab

comput option bia vector initi linear layer bia
word count token sentenc
bia init word count index vocab
index vocab reshap vocab size
bia init bia init
bia init bia init
bia init bia init

sentenc length sent sent sentenc

imag iobuf imag size
imag t imag shape
iobuf vocab size sentenc length
iobuf vocab size sentenc length
creat mask deal variabl length sentenc
mask iobuf vocab size sentenc length
mask zero mask shape
dtype uint8 reshap vocab size
sentenc length
mask reshap mask reshap mask shape

iobuf sentenc length dtype int32
lbl t shape
lblflat reshap size

iobuf sentenc length dtype int32
lbl t shape
lblflat reshap size

shape imag size vocab size sentenc length
vocab size sentenc length vocab size
sentenc length

read imag split

read sentenc imag featur pickl dict

arg
split test train split

path path join path featur
neon util persist load
dataset load path
sent dataset sent split
featur dataset feat

iter

gener use iter dataset

yield
tupl tupl first tupl contain imag featur input sentenc
second tupl contain target sentenc mask
correspond sentenc end
zero elsewher


shuf permut
imag shuf shuf imag shuf
sent length sent length shuf

batch xrang nbatch

start batch
batch

imag batch imag start astyp float32 order
imag t imag start
imag imag t

batch start astyp float32 order
lbl t start
lbl t
onehot lblflat axi

mask
sent len sent length start
mask sent end sent len newaxi
mask mask reshap

batch start astyp float32 order
lbl t start
lbl t
onehot lblflat axi
mask

imag mask

prob word prob

convert probabl sentenc

arg
prob tensor word probabl sentenc batch
size vocab size batch size sentenc length

return
contain sentenc


sent

isinst prob ndarray
prob prob
word index vocab argmax prob axi tolist

sent index xrang
sent
xrang sentenc length
word word sent index
sent append word
word token

sent append join sent

sent

predict model

given model gener sentenc dataset

arg
model model imag caption model

return
contain predict sentenc target sentenc

sent
target
zero shape
enumer
fill
repeatedli gener word sentenc choos prob word time
step rang sentenc length
prob model fprop infer copi
pred argmax prob axi
prob fill
rang step
prob pred
prob
sent prob word
test keep target
isinst imag caption test
target
train target

target append

sent target

bleu score sent target

comput bleu score predict sentenc refer sentenc

arg
sent predict sentenc
target refer sentenc element
multipl refer


target
output file path output
refer file path refer rang
bleu script http githubusercont karpathi neuraltalk master
bleu script multi bleu perl

write output refer sent path

output open output file
sent sent
sent sent strip token split
output write join sent

refer open refer file
rang
target sent target
refer write target sent

output close
close refer

getcwd
chdir path
path exist bleu script
dataset fetch dataset bleu script bleu script bleu script
bleu command perl multi bleu perl refer output
execut bleu script bleu command
system bleu command
chdir

get imag
imag featur
featur imgid

iter sentenc
iter sentenc
sent
sent sentenc
sent

iter imag sentenc pair
iter imag sentenc pair imag repeat
enumer sent
sent sentenc

imag get imag
sentenc sent


iter imag sentenc group
iter imag sentenc group
enumer sent

imag get imag
sentenc sentenc



imag caption test imag caption

thi load imag sentenc featur test


init path
path path
read test imag sentenc path
load vocab train load test
read imag train
load vocab
read imag test

train iter iter imag sentenc group
train sent train img
sent enumer train iter
train img append sent imag
train sent append join sent token sent sent sentenc

nbatch train img
ndata nbatch

imag vstack train img

sent train sent

iter

gener use iter dataset

yield
tupl tupl first tupl contain imag featur input tensor
second tupl contain refer sentenc
placehold mask

batch xrang nbatch

start batch
batch

imag batch imag start astyp float32 order
imag imag batch

imag sent start


flickr8k dataset
init path imag
http west amazonaw neon stockdataset imag caption
flickr8k init flickr8k

49165563
path path
imag imag

iter
path load
dict train imag caption path path imag imag
dict test imag caption test path path
dict

load
load filenam size


flickr30k dataset
init path imag
http west amazonaw neon stockdataset imag caption
flickr30k init flickr30k

49165563
path path
imag imag

iter
path load
dict train imag caption path path imag imag
dict test imag caption test path path
dict

load
load filenam size


coco dataset
init path imag
http west amazonaw neon stockdataset imag caption
coco init coco

738051031
path path
imag imag

load
load filenam size

iter
path load
dict train imag caption path path imag imag
dict test imag caption test path path
dict

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin pascal datatset handl

numpi

minidom minidom
tarfil
imag

neon dataset dataset
neon util persist save load

background alway index
pascal class background
aeroplan bicycl bird boat
bottl chair
diningt hors
motorbik person pottedpl
sheep sofa train tvmonitor
pascal class class background

from caff
pixel mean valu order
these valu origin use train vgg16
pixel mean 9801 9465 7717
frcn pixel mean 9801 9465 7717

load imag need make
frcn swap

frcn

xmin
ymin
xmax
ymax

dataset meta
test 2007 dict size 460032000
file vo ctest 2007
http host robot pascal voc2007
subdir vo cdevkit voc2007
trainval 2007 dict size 451020800
file vo ctrainval 2007
http host robot pascal voc2007
subdir vo cdevkit voc2007
trainval 2012 dict size 2000000000
file vo ctrainval 2012
http host robot pascal voc2012
subdir vo cdevkit voc2012
select search dict size 628395563
file select search
http west amazonaw nervana pascal
subdir select search



pascalvoc dataset

pascal dataset
contain variabl function train test dataset

structur
root path vo cdevkit voc2007
root imag set main train test imag index file
root annot class imag

arg
imag trainval test
year string 2007
path string path file
option mani minibatch iter
valu smaller nbatch debug
batch option mani imag process batch
roi option mani roi pool imag


init imag year path batch
roi
is roi db
batch index
year year
imag imag

mani ro is imag
roi roi roi frcn imag
batch batch batch frcn batch
roi batch roi batch

cach file name cach file name

dataset

pascal index
class pascal class
index dict
pascal class xrang class

load dataset
root load imag year path

cach file path join root cach file name

load precomput result includ 2007
2012
path load path

path info
imag index file path join root imag set main
imag
imag path path join root jpeg imag
imag file

annot path path join root annot
annot file
annot
annot name
annot xmin xmin
annot xmax xmax
annot ymin ymin
annot ymax ymax

select search
select search file path join
path
join year imag selectivesearch

roi batch ro is
imag path batch size batch
need control batch size
backend batchsiz chang pascal dataset format
batch

batch

path exist imag index file
imag index file exist format imag index file
open imag index file
imag index strip readlin

reset

reset start index dataset back zero

batch index

load dataset year path

dataset trainval test
year 2007 2012 otherwis

select search
fetch comput select search convert
file avail
http berkeley fast rcnn select search

dataset select search year join
dataset year
dataset meta dataset
workdir filepath datadir valid path append
path file subdir

path exist filepath
fetch dataset file filepath size
tarfil open filepath
extractal workdir

datadir

load pascal groundtruth

load databas ground truth ro is


load pascal annot imag index

load pascal annot imag index

particular imag load ground truth annot class
bound pascal dataset file
directori annot each file correspond particular
imag index

annot file path join annot path
imag index annot file
open annot file
annot minidom pars string read

mani object
obj annot get element by tag name annot
obj obj

initi ground truth class
zero obj dtype uint16
class zero obj dtype int32
overlap zero obj class dtype float32
overlap zero obj
zero obj

load info
enumer obj
load annot xmin
load annot ymin
load annot xmax
load annot ymax
index
load annot
lower strip

class
overlap
overlap


target zero obj
target ravel


class class
overlap overlap
imag index
overlap area overlap
overlap
target target


calcul scale shape
shape size int32
size shape
size shape
scale frcn scale size
prevent biggest axi frcn scale
round scale size frcn scale
scale frcn scale size
shape shape scale astyp
scale shape


pascalvoc train pascalvoc


construct pascal dataset train
also load precomput select search result ro is

structur
root path vo cdevkit voc2007
root imag set main train test imag index file
root annot class imag

note
ground truth bound base pixel coordin need
make base input
bound coordin
preprocess save cach file
configur chosen

arg
imag trainval test
year string 2007
path string path file
flip bool whether augment dataset flip imag
overlap thre float threshold bbox use train
output option iter
provid frcn variant
normal frcn model imag roi label target mask
label stream imag roi label
label stream imag label
option mani minibatch iter
valu smaller nbatch debug
batch option mani imag process batch
roi option mani roi pool imag
roi random sampl bool option randomli sampl ro is default
although imag
mani ro is randomli
sampl train when
take first roi
train
shuffl bool option randomli shuffl sampl epoch

mani percentag sampl foreground
frcn frac
frcn thre threshold consid
frcn thre threshold consid foreground
threshold consid background
frcn thre
frcn thre high
frcn scale imag scale
frcn scale 1000 1000 imag scale

frcn batch
frcn imag

init imag year path flip
overlap thre output batch
roi roi random sampl shuffl

flip flip
overlap thre overlap thre overlap thre frcn thre
output output

pascalvoc train init imag year path
batch roi

roi frcn frac roi
roi roi roi
roi random sampl roi random sampl
shuffl shuffl

backend tensor push
imag shape frcn scale frcn scale
zero
frcn scale frcn scale dtype float32
iobuf imag shape dtype float32
reshap
frcn scale frcn scale
roi featur within batch
roi zero roi batch
label flat zero
roi batch dtype int32
label zero
class roi batch dtype int32
bbtarget zero
class roi batch
bbmask zero
class roi batch

shape indic shape path imag net model
path ro is
shape imag shape class

need follow
load imag index
imag load ground truth pascal annot
load select search ro is step need ro is
merg ro is
flip imag train
field overlap overlap class
bound target regress
minibatch feed
rescal imag
rescal ro is
random select foreground ro is bigger one
random select background roi smaller one
clamp label
convert ro is regress target ro is


imag imag index
imag entri imag flip imag
ndata imag entri roi
nbatch imag entri batch


nbatch

path exist cach file
cach load cach file
cach
bbtarget mean cach bbtarget mean
bbtarget std cach bbtarget std
dataset load file format cach file


load pascal groundtruth


load pascal selectivesearch


bbtarget mean bbtarget std combin

cach dict
cach
cach bbtarget mean bbtarget mean
cach bbtarget std bbtarget std
save cach cach file
wrote dataset format cach file

iter

gener use iter dataset

each minibatch construct batch imag
roi ro is

begin epoch shuffl dataset instanc
minibatch sampl ro is imag

yield
tupl tupl first tupl contain imag goe imag net model

second tupl contain label ro is
bound regress target

batch index

permut dataset epoch
shuffl
shuf rang imag entri

shuf permut imag entri
imag index imag index shuf

batch index xrang nbatch
start batch index batch
batch index batch

ind shuf start

ind

roi zero roi batch dtype float32
label blob zero roi batch dtype int32
bbox target blob zero roi batch class
dtype float32
bbox loss blob zero
bbox target blob shape dtype float32


enumer

load process imag
imag open file thi order

scale shape calcul scale shape

resiz shape imag linear

load numpi flip channel

flip

mean subtract scale imag
astyp float32 copi
frcn pixel mean

sampl fore ground back ground ro is propos
label
label overlap roi bbox target bbox loss
sampl roi roi roi
class roi random sampl
frcn thre frcn thre high
frcn thre

ro is blob
roi roi scale
roi imag roi shape
slice slice roi
roi roi imag
batch one roi imag
correspond imag within batch

roi imag hstack batch roi

roi slice roi imag

label bbox target bbox loss blob
label blob slice label ravel
bbox target blob slice bbox target
bbox loss blob slice bbox loss

write backend tensor
shape shape transpos
frcn swap


roi roi
label flat label blob reshap
label onehot
label flat axi
bbtarget bbox target blob astyp
order
bbmask bbox loss blob astyp int32 order

output
roi
label bbtarget bbmask
output
roi
label
output

label

valu error
support output format output



cach file name
train flip ovlp size format year
imag
flip
overlap thre
frcn scale
frcn scale

dataset
prepar pascal year flip imag overlap threshold
format imag year flip overlap thre

load pascal selectivesearch

load comput select search pascal pickl file

pickl file contain imag
imag imag indic dataset
name imag
propos ro is imag
propos ro is
coordin order

while ground truth coordin

need order


ground truth ro is need load first
path exist select search file
select search exist

load select search file
box ravel
imag ravel
shape

imag
number imag must match imag dataset



load compar
xrang
make sure imag index match
imag index

box shape
overlap zero
box class dtype float32


class class ravel

overlap calcul overlap astyp
astyp

overlap area overlap axi
overlap overlap argmax axi

zero overlap tabl
overlap area
overlap class overlap overlap area
overlap overlap argmax axi
overlap overlap axi

prepar bound target
target zero box float32
one larg enough overlap use
overlap overlap thre

target comput target overlap

overlap

target target

append

class zero box dtype int32
overlap overlap
overlap area overlap area reshap
overlap overlap reshap
target target




combin
imag
ro is match dataset imag

comput valu need mean std
count zero class frcn
sum zero class
squar sum zero class

imag entri

xrang imag

vstack

class vstack class
class
overlap vstack overlap
overlap
overlap area vstack overlap area
overlap area
overlap vstack overlap
overlap

flip

imag file path join imag path
imag file

file imag file

bound target train
target vstack target
target

target target

xrang class
ind target
ind size
count ind size
sum target ind axi
squar sum
target ind axi

flip
width imag open imag file size
flipe copi
flipe xmin width
xmax
flipe xmax width
xmin
target flip target
target flip

imag
flipe
class class
overlap overlap
overlap area overlap area
overlap overlap

flip
file imag file
target target flip

xrang class
ind target
ind size
count ind size
sum
target flip ind axi
squar sum
target flip ind axi

mean sum count
std sqrt squar sum count mean

bbtarget mean mean ravel
bbtarget std std ravel

normal target
xrang imag
target target
xrang class
ind target
target ind mean
target ind std

bbtarget mean bbtarget std

comput target label

calcul region propos center width height
width xmax xmin frcn
height ymax ymin frcn
xmin width
ymin height

calcul ground truth
width xmax xmin frcn
height ymax ymin frcn
xmin width
ymin height

target adjust bbox center width height
also notic target gener base origin
scale imag resiz
target width
target height
target width width
target height height

target concaten label newaxi
target newaxi
target newaxi
target newaxi
target newaxi
axi

target


pascalvoc infer pascalvoc


construct pascal dataset test infer
still load precomput select search result ro is

note
dataset iter batch size
infer test dataset keep precomput select
search model
preprocess save cach file
configur chosen

arg
imag trainval test
year string 2007
path string path file
option mani minibatch iter
valu smaller nbatch debug
batch option mani imag process batch
roi option mani roi pool imag
scale float option much imag scale
reach featur layer thi scale
use remov duplic ro is
project featur scale
shuffl bool option randomli shuffl sampl epoch
use test accuraci metric
use dataset iter
demo pick imag randomli insid dataset


frcn scale
frcn scale 1000
frcn batch
frcn imag 5403

init imag year path
roi scale shuffl
pascalvoc infer init imag year path
frcn batch roi


scale scale
last height
last width
last box
shuffl shuffl

backend tensor push
imag shape frcn scale frcn scale
zero
frcn scale frcn scale dtype float32
iobuf imag shape dtype float32
reshap
frcn scale frcn scale
roi featur within batch
roi zero roi batch

shape indic shape path imag net model
path ro is
shape imag shape class

path exist imag index file
imag index file exist format imag index file
open imag index file
imag index strip readlin

imag imag index
imag entri imag
ndata imag entri roi
nbatch imag entri batch


nbatch

path exist cach file
load cach file
dataset load file format cach file


load pascal groundtruth

load pascal selectivesearch

combin

save cach file
wrote dataset format cach file

iter

gener iter dataset

each minibatch construct batch imag
roi ro is

yield
tupl first tupl contain imag
second contain dataset structur imag
contain inform post process

batch index

permut dataset epoch
shuffl
shuf rang imag

shuf permut imag
imag index imag index shuf

batch index xrang nbatch
start batch index batch
batch index batch

ind shuf start
ind

roi zero roi batch dtype float32


enumer

load process imag
imag open file thi order
scale scale
roi scale

base unscal imag
adjust
shape size int32
last height shape
last width shape

shape scale
resiz shape imag linear

mean subtract scale imag
astyp float32 copi
frcn pixel mean

last box roi shape roi

roi roi last box
slice slice roi
roi last box
batch one last box
correspond imag within batch

roi imag hstack batch roi

roi slice roi imag

shape shape transpos
frcn swap

write backend tensor

roi roi
actual last box
roi



cach file name
infer size format year
imag
frcn scale
frcn scale

dataset
prepar pascal year infer format imag
year

load pascal selectivesearch

load comput select search pascal pickl file

pickl file contain imag
imag imag indic dataset
name imag
propos ro is imag
propos ro is
coordin order

while ground truth coordin

need order


ground truth ro is need load first
path exist select search file
select search exist

load select search file
box ravel
imag ravel
shape

imag
number imag must match imag dataset


load remov duplic
xrang
make sure imag index match
imag index


box shape

overlap zero
box class dtype float32


class class ravel

overlap calcul overlap astyp
astyp

overlap area overlap axi
overlap overlap argmax axi

zero overlap tabl
overlap area
overlap class overlap overlap area
overlap overlap argmax axi

file path join imag path
imag index imag file
append

imag index
file file
class zero box dtype int32
overlap overlap
overlap area overlap area reshap
overlap overlap reshap




combin
imag
ro is match dataset imag

imag entri

xrang imag


vstack


class vstack class
class


file file

load imag scale imag
know scale ro is remov duplic
imag open file thi order
shape size int32
scale calcul scale shape

scale scale
height shape
width shape

remov duplic one project featur
coordin
scale
roi scale
1e12
roi project round roi scale
index index uniqu roi project index
invers
keep uniqu one orign bbox
scale imag scale
index
index index



post process output

post process network output backend tensor
bound box predict

post process done numpi

argument
output backend tensor pad
current databas process network


score output
delta output


n roi shape roi
height
width

score score n roi
delta delta n roi

roi correct bbox delta

index index
roi roi index
score score index

score roi

correct bbox box delta height width

network bbox delta adjust origin bbox propos

argument
box ndarray box region propos extern routin
delta ndarray box bound adjust
height origin imag height make sure
width origin imag width make sure



box shape
zero delta shape

box box astyp copi
width box xmax
box xmin frcn
height box ymax
box ymin frcn

box xmin width
box ymin height

delta xmin
delta ymin
delta xmax
delta ymax

pred width newaxi newaxi
pred height newaxi newaxi
pred width newaxi
pred height newaxi

correct box zero delta shape

correct box xmin pred pred

correct box ymin pred pred

correct box xmax pred pred

correct box ymax pred pred

clip correct box imag boundari
correct box xmin maximum
correct box xmin

correct box ymin maximum
correct box ymin

correct box xmax minimum
correct box xmax width

correct box ymax minimum
correct box ymax height

correct box

appli box thresh

appli maximum suppress predict box output

argument
box ndarray detect class imag
box imag
detect score
thresh theshold elimin overlap box

return
box ndarray box appli supress


class box
imag box
box xrang imag
xrang class
xrang class
xrang imag
det box
det

keep nonmaximum suppress det det thresh
keep

box det keep copi
box

nonmaximum suppress detect score thre

appli maximum suppress indepd reject
region intersect overlap higher
score select region larger learn threshold

argument
detect ndarray detect bound box
score ndarray score associ
thre theshold elimin overlap box

return
keep ndarray indic keep appli supress



detect xmin
detect ymin
detect xmax
detect ymax

area
order score argsort

keep
order size
order
keep append
maximum order
maximum order
minimum order
minimum order

maximum
maximum

overlap area area order

ind overlap thre
order order ind

keep

evalu box output output

evalu detect collect
box imag detect score
write output text format
then call outsid step gener metric
text file

argument
box ndarray detect class imag
output save output file


comput result unoffici python code


path isdir output
mkdir output

enumer pascal class
background

write result file format
filenam format
year imag
filepath path join output filenam
open filepath
rang nbatch
index imag index
det box
det

vo cdevkit expect base indic
xrang det shape
write
format index det
det det
det det

annopath path join annot path
annot file
imagesetfil imag index file

annopath imagesetfil


calcul overlap

calcul overlap bound

argument
region propos shape
ground truth ro is shape

output
overlap matrix overlap shape


shape
shape
overlap zero dtype float32

rang
area



rang













area

overlap
overlap


sampl roi roidb roi roi class
random thre thre high thre

gener random sampl ro is compris foreground background
exampl

label overlap
label roidb overlap
overlap roidb overlap area
roi roidb

select foreground ro is thre overlap
ind overlap thre

guard imag fewer roi
foreground ro is
roi imag minimum roi ind size
sampl foreground region without replac
ind size
random
ind random choic ind size roi imag
replac

ind ind rang roi imag

select background ro is within thre
thre high
ind
overlap thre high overlap thre
comput background ro is take imag guard
fewer desir
roi imag minimum roi roi imag
ind size
sampl foreground region without replac
ind size
random
ind random choic ind size roi imag
replac

ind ind rang roi imag

indic select
keep ind append ind ind
select sampl valu variou array
label label keep ind
clamp label background ro is
label roi imag
overlap overlap keep ind
roi roi keep ind

bbox target bbox loss weight
bbox regress label roidb target keep ind
class

label overlap roi bbox target bbox loss weight


bbox regress label bbox target class

bound regress target store compact form
roidb

thi expand target represent use
network zero target loss weight
similarli expand

argument
bbox target ndarray target
class class

return
bbox target ndarray blob regress target
bbox loss weight ndarray blob loss weight

clss bbox target
bbox target zero clss size class dtype float32
bbox loss weight zero bbox target shape dtype float32
ind clss
ind
clss
start
start
bbox target start bbox target
bbox loss weight start
bbox target bbox loss weight


load element
element get element by tag name child node

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin video dataset handl



video

init
not implement error

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


function use load commonli avail dataset


log


urllib2
zipfil

neon nervana object

logger log get logger name


dataset nervana object

contain stock dataset

argument
filenam name file download
dataset
size file size
path local path place file
subset percentag train

init filenam size path subset
paramet dataset config serial
dataset init name
filenam filenam

size size
path path
subset subset
subset
placehold partial
not implement subset percentag featur implement

serial

gener dictionari requir paramet describ

descript

load filenam size

helper download test file
will download unzip file directori path

argument
filenam name file download
size size file byte

return
path download dataset

workdir filepath valid path append path filenam

path exist filepath
fetch dataset filenam filepath size
filepath
zipfil zip file filepath
extractal workdir
close
filepath filepath split
filepath

staticmethod
valid path append path arg

helper valid pass path directori append subsequ
filenam

argument
path initi filesystem path should expand valid
directori
arg option filenam path suffic append path
return

return
path prepend file arg path alon
arg specifi

rais
valu error path valid directori filesystem

full path path expandus path

path exist full path
makedir full path
path isdir full path
valu error path valid directori format path
suffix path arg
append path join full path suffix path

path





staticmethod
fetch dataset sourcefil destfil totalsz

download file specifi given

arg
base file download
sourcefil name sourc file
destfil path destin
totalsz size file download

cloudfil urllib2 urlopen path join sourcefil
download file format destfil
blockchar u2588 charact display progress
open destfil
read
chunksz 1024

cloudfil read chunksz


read totalsz read chunksz
progress download progress format
blockchar read totalsz
stdout write
stdout write progress encod
stdout flush

write
download complet

iter
children need implement method
not implement


i1 kmeta dataset

helper load dataset meta

actual dataset

init path
http west amazonaw neon stockdataset imagenet
i1 kmeta init neon ilsvrc2012 devmeta

758648
path path

load
file path dataset load i1kmeta path
file path


function deprec remov futur releas
load i1kmeta path
logger error thi move neon dataload
neon dataload load i1kmeta noqa
load i1kmeta path


valid path append path arg
logger error thi move neon dataload
neon dataload valid path append noqa
valid path append path arg


fetch dataset sourcefil destfil totalsz
logger error thi move neon dataload
neon dataload fetch dataset noqa
fetch dataset sourcefil destfil totalsz


load mnist path normal
logger error thi move neon dataload
neon dataload load mnist noqa
load mnist path path normal normal


comput transform img filter bia
logger error thi move neon dataload
neon dataload comput transform noqa
comput transform img filter bia filter bia


whiten train test cach
logger error thi move neon dataload
neon dataload whiten noqa
whiten train test cach cach


contrast normal scale divisor
logger error thi move neon dataload
neon dataload contrast normal
contrast normal scale scale divisor divisor


load cifar10 path normal contrast normal whiten
logger error thi move neon dataload
neon dataload load cifar10 noqa
load cifar10 path path
normal normal
contrast normal contrast normal
whiten whiten


load babi path task singl support fact subset
logger error thi move neon dataload
not implement load babi remov


load train path
logger error thi move neon dataload
neon dataload load train noqa
load train path


load valid path
logger error thi move neon dataload
neon dataload load valid noqa
load valid path


load test path
logger error thi move neon dataload
neon dataload load test noqa
load test path


load hutter prize path
logger error thi move neon dataload
neon dataload load hutter prize noqa
load hutter prize path


load shakespear path
logger error thi move neon dataload
neon dataload load shakespear noqa
load shakespear path


load flickr8k path
logger error thi move neon dataload
neon dataload load flickr8k noqa
load flickr8k path


load flickr30k path
logger error thi move neon dataload
neon dataload load flickr30k noqa
load flickr30k path


load coco path
logger error thi move neon dataload
neon dataload load coco noqa
load coco path


load imdb path
logger error thi move neon dataload
neon dataload load imdb noqa
load imdb path


load text dataset path
logger error thi move neon dataload
neon dataload load text noqa
load text dataset path path
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


process macro batch pipelin fashion


log

glob glob
gzip
numpi

tarfil
ctype

neon util compat rang

logger log get logger name


batch writer

parent batchwrit take input imag output
macrobatch imag loader provid

argument
directori output macrobatch
imag directori find imag gener batch writer directori
organ subdirectori subdirectori
contain differ categori imag imagenet batch writer
directori contain ilsvrc provid file
target size option size scale down shortest side
input imag exampl imag
target size imag scale
howev input imag
imag resiz
target size resiz done
default
valid option percentag indic percentag
hold valid default
sampl option maximum imag
input imag directori default
indic maximum
file pattern option file suffix glob imag
default
macro size option imag macrobatch
default 3072
pixel mean tupl option pixel mean valu save metafil
default


init imag target size valid
sampl file pattern macro size 3072
pixel mean

libpath path dirnam path realpath file

writerlib cdll load librari
path join libpath loader loader
writerlib write batch restyp
writerlib read item restyp

logger error unabl load loader ensur
file compil

random seed
path expandus
imag path expandus imag imag
macro size macro size
target size target size
file pattern file pattern
sampl sampl
valid valid
train file path join train file
file path join file
batch prefix macrobatch
meta file path join batch prefix meta
pixel mean pixel mean
item size 25000 reason imag size
post init

post init


write file
label subdir
subdir glob path join imag
label name sort path basenam subdir

index rang label name
label dict label name index

tline
vline
subdir subdir
subdir label label dict path basenam subdir
file glob path join subdir file pattern
sampl
file file sampl
line filenam subdir label filenam file
valid line
tline line
vline line
random shuffl tline

path exist
makedir

train file file tline vline
gzip open
write filenam

write format

train nrec tline
train start

nrec vline
start train nrec macro size

pars file infil
line loadtxt infil delimit skiprow dtype name fname
format
imfil line
label line
nclass label
imfil label

write individu batch batch file label batch jpeg file batch
ndata jpeg file batch
jpgfile ndata
jpgfile jpeg file batch

thi batchfil allow specifi
destin file input file file
correspond integ label
writerlib write batch batch file
ndata
jpgfile
ndata label batch
target size

write batch offset label imfil
npt imfil macro size
start macro size rang npt
imfil imfil macro size start
label macro size label iteritem start

jpeg file batch enumer imfil
bfile path join cpio batch prefix offset
label batch label
path exist bfile
file exist skip bfile

write individu batch bfile label batch jpeg file batch
wrote batch

check batchfil item valu
batch item writerlib read item bfile
batch item
valu error batch file probabl corrupt bfile

item size batch item item size

save meta
open meta file
settyp train
write start settyp getattr settyp start
write nrec settyp getattr settyp nrec
write nclass nclass
write item size item size
write label size
write mean pixel mean
write mean pixel mean
write mean pixel mean


write file
valid
namelist train
filelist train file
startlist train start
valid
namelist valid
filelist file
startlist start

namelist train valid
filelist train file file
startlist train start start
sname fname start namelist filelist startlist
write sname fname start
fname path exist fname
img label pars file fname
write batch start label img

skip file miss sname
item size store meta file
save meta


batch writer i1 k batch writer

post init
zlib


load imag
train path join load ilsvrc2012 train
path join load ilsvrc2012
devkit path join load ilsvrc2012 devkit

infil train devkit
path exist infil
io error infil found pleas imag net download
more info http imag download imageurl

tarfil open devkit
synsetfil ilsvrc2012 devkit meta
valfil ilsvrc2012 devkit ilsvrc2012 valid ground truth

synset map hack around matlab terribl compress format
meta buff extractfil synsetfil read
decomp zlib decompressobj
synset findal compil decomp decompress meta buff
train label enumer synset

ground truth valid label offset zero
label
enumer extractfil valfil
valid

train nrec 1281167
train start

nrec 50000
start train nrec macro size
pixel mean 41227722 21331787 80609131

extract imag overwrit
setn train
path join setn

extract file setn
toptar getattr setn
label dict getattr setn label
name slice slice setn train slice
tarfil open toptar
getmemb
label label dict name name slice
subpath path join label
path exist subpath
makedir subpath
setn train
tarfp tarfil open fileobj extractfil
file tarfp getmemb

tarfp
file

fobj file
fname path join subpath fobj name
path exist fname overwrit
open fname
write tarfp extractfil fobj read

write file overwrit
extract imag
setn train
path join setn
csvfile getattr setn file
get file setn
path exist csvfile overwrit
file exist overwrit csvfile

fline

subdir glob path join
subdir subdir
subdir label path basenam subdir thi label
file glob path join subdir file pattern
fline filenam subdir label filenam file

setn train
random seed
random shuffl fline

gzip open csvfile
write filenam
fline
write format


batch writer csv batch writer

post init
img label dict dict
check need file exist
setn train
infil path join imag setn file
path exist infil
io error infil found thi need creat prior run
batch writer option
img setn label setn pars file infil

valid

train nrec img train
nrec img

train start
start train nrec macro size
pixel mean 41227722 21331787 80609131

pars file infil
line loadtxt infil delimit dtype name fname
format
imfil path join imag line
label line
nclass label
imfil label


path exist
makedir
write train macrobatch
write batch train start label train img train
write valid macrobatch
write batch start label img
save meta


batch writer cifar10 batch writer i1 k

post init
size target size target size
width size size size size

valid

train nrec 50000
train start

nrec 10000
start train nrec macro size

extract imag overwrit
neon load cifar10
imag
dataset dict
dataset train dataset load cifar10 normal

setn train
label dataset setn

path join setn
ulabel uniqu label
ulabel ulabel
subdir path join ulabel
path exist subdir
makedir subdir

rang shape
reshap width mode mean
uint8 transpos axe copi
imag fromarray
path path join label
save path format

setn train
pixel mean mean axi reshap mean axi
pixel mean revers order opencv


name main
neon util argpars neon argpars
parser neon argpars
parser argument help cifar10 directori requir
choic cifar10 directori
parser argument imag help directori find imag
parser argument target size
help size pixel scale shortest side down mean scale
parser argument macro size 5000 help imag process batch
parser argument file pattern help imag extens
directori crawl
arg parser pars arg

logger log get logger name

arg
arg target size mayb simonyan methodolog
batch writer i1 k arg imag arg imag
target size arg target size macro size arg macro size
file pattern jpeg
arg cifar10
batch writer cifar10 arg imag arg imag
target size arg target size macro size arg macro size
file pattern
arg
batch writer csv arg imag arg imag
target size arg target size macro size arg macro size

batch writer arg imag arg imag
target size arg target size macro size arg macro size
file pattern arg file pattern



copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin basic input datatset type

log
numpi

neon nervana object
logger log get logger name


nervana data iter nervana object

abstract iter

serial iter inherit

init name
nervana data iter init name

nbatch
not implement

reset
not implement

iter
not implement


array iter nervana data iter


thi gener defin iter minibatch
preload memori form numpi array
thi use entir dataset small enough within memori


init nclass lshape make onehot name

implement load given backend tensor object
backend specif accelar devic copi
devic

arg
ndarray shape exampl featur size input featur within
dataset
ndarray shape exampl option label correspond
input featur
absent input featur return
target valu auto encod
nclass option possibl type label
necessari provid label
lshape tupl option local shape input featur
height width channel imag
make onehot option label convert
need convert



treat singleton like iter follow syntax
array iter init name name
isinst
ndata
ndata
start
nclass nclass
ybuf

make onehot nclass
attribut error must provid class creat onehot label

store shape input
shape shape lshape lshape
shape
shape shape
lshape lshape

helper make dataset minibatch unpack transpos onehot
transpos
iobuf shape
copi transpos

onehot
reshap dtype int32 iobuf nclass
onehot axi

xdev xbuf unpack func transpos

shallow copi append iter
dbuf hbuf xdev xbuf
unpack func unpack func


ydev ybuf yfunc onehot make onehot transpos
dbuf append ydev
hbuf append ybuf
unpack func append yfunc

properti
nbatch
start ndata

reset

reset start index dataset back zero
relev want call repeat evalu dataset
want wrap around last uneven minibatch
necessari ndata divis batch size

start

iter

defin gener use iter dataset

yield
tupl minibatch includ featur label

rang start ndata
ndata
islice1 oslice1 slice slice
islice2 oslice2

islice2 oslice2 slice slice
start

unpack func hbuf dbuf unpack func
unpack func oslice1 islice1
oslice2
unpack func oslice2 islice2

input xbuf xbuf xbuf
target ybuf ybuf input
input target


data iter array iter

thi renam array iter deprec
thi place holder remov pleas
array iter

init arg kwarg
logger error data iter deprec renam
array iter pleas name
data iter init arg kwarg


name main
neon load mnist
train train test test load mnist

neon backend nervanagpu nervana gpu
nervana gpu devic

nervana object

train array iter
test 1000 test 1000 test 1000 nclass
rang
bidx batch batch enumer train
bidx train start


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


c pickl
functool partial
glob glob
multiprocess pool




convert file iopair keylist

function convert imageset batch cpickl file
flat binari choic key
input file cpickl dict follow field
dict jpeg string
dict label dict integ list categori
label correspond jpeg

follow condit label jpeg
dict dict label

arg
iopair tupl name input output file
keylist key use flat binari file

ifnam ofnam iopair
open ifnam
convert ifnam
tdata c pickl load
jpeg tdata
label tdata label
img jpeg

open ofnam
write pack img
write pack keylist

keylist

write pack bytearray
write pack img label

rang img
jpeg
pack bytearray jpeg
write

locat origin imageset batch gener batch writer
ipath local imageset batch

locat dump flat binari imageset batch
opath local imageset batch

ifil glob path join ipath batch
ofil fname replac ipath opath fname ifil
keylist

pool pool process
pool partial convert file keylist keylist ifil ofil

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


class definit stock set


c pickl
gzip
log
numpi

tarfil

neon dataset dataset
neon dataiter array iter

logger log get logger name


mnist dataset
init path subset normal
mnist init mnist
http amazonaw dataset
15296311
path path
subset subset
normal normal

load

fetch mnist dataset load memori

arg
path option local directori cach
dataset default current directori
normal option whether scale valu
default

return
tupl both train test set return

filepath valid path append path filenam
path exist filepath
fetch dataset filenam filepath size

gzip open filepath mnist
train train test test c pickl load mnist
train train reshap
test test reshap

normal
train train
test test

train train test test

iter
train train test test nclass load
train array iter train
train
nclass nclass
lshape
name train
array iter test
test
nclass nclass
lshape
name valid
dict train train
valid
dict


cifar10 dataset

cifar10 dataset contain

argument
path local path copi file
normal flag normal
whiten flag appli whiten transform
class flag count
compat conv layer

init path subset normal
contrast normal whiten class
cifar10 init cifar python
http toronto kriz
170498071
path path
subset subset
cifar10 load method specif option
normal normal
contrast normal contrast normal
whiten whiten
class class

load

fetch cifar dataset load memori

arg
path option local directori cach
dataset default current directori
normal option whether scale valu
default

return
tupl both train test set return

workdir filepath valid path append path filenam
batchdir path join workdir cifar batch
path exist path join batchdir batch
path exist filepath
fetch dataset filenam filepath size
tarfil open filepath
extractal workdir

train batch path join batchdir batch rang
xlist ylist
batch train batch
open batch
c pickl load
xlist append
ylist append label

train vstack xlist
train vstack ylist

open path join batchdir test batch
c pickl load
test test label

train train reshap
test test reshap

contrast normal
norm scale goodfellow
train contrast normal train scale norm scale
test contrast normal test scale norm scale

normal
train train
test test

whiten
cach path join workdir cifar cach
train test whiten train test cach cach

train train test test

iter
dataset load

train train test test nclass dataset
class
nclass

train array iter train
train
nclass nclass
lshape
name train
test array iter test
test
nclass nclass
lshape
name valid
dict train train
valid test
dict

staticmethod
comput transform img filter bia

comput whiten transform matrix

logger info comput transform matrix
mean x mean img

cov x img
linalg eigh cov x

isnan
isnan




diag
mean x

staticmethod
whiten train test cach

train statist appli whiten transform
train test set

cach path isfil cach
open cach
mean x c pickl load

mean x cifar10 comput transform train
cach
logger info cach transform matrix
open cach
c pickl dump mean x

logger info appli whiten transform
train train mean x
test test mean x

train test

staticmethod
contrast normal scale divisor

subtract mean normal vector norm


mean axi newaxi

normal sqrt axi scale
normal normal divisor

normal newaxi



copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin text datatset handl


log
numpi
path splitext

neon dataiter nervana data iter array iter
neon dataset dataset
neon text preprocess sentenc


logger log get logger name


text nervana data iter

thi defin method load iter text dataset


init time step path vocab token
onehot input

construct text dataset

arg
time step length sequenc
path path text file
vocab python uniqu token
token token
onehot input represent input

text init name
figur remov length dataload
length time step
onehot input onehot input
batch index

text open path read
token token text token

make method
extra token token time step
extra token
token token extra token
nbatch token time step
ndata nbatch leftov

vocab sort vocab token vocab
nclass vocab

vocab dict
token index dict enumer vocab
index token dict enumer vocab

token indic
asarray token index token dtype uint32
concaten

reshap preserv sentenc continu across batch
reshap nbatch time step
reshap nbatch time step

stuff comment need clean comment
nout vocab
onehot input
shape nout time step
iobuf nout time step

shape time step
iobuf time step dtype int32

iobuf nout time step
iobuf time step dtype int32
lblflat reshap

staticmethod
creat valid file path valid split

creat separ file train valid

arg
path path file
valid split fraction asid valid

return
path train file valid file

text open path read

creat train valid path
filenam splitext path
train path filenam train
valid path filenam valid

split
train split text valid split
train text text train split
valid text text train split

write train file
open train path train file
train file write train text

write valid file
open valid path valid file
valid file write valid text

train path valid path

staticmethod
token token

token

arg
string token
token token

return
token

token charact
token


token

staticmethod
vocab token vocab

construct vocabulari given token

arg
token list token

return
python uniqu token

vocab check contain token
vocab
token

vocab vocab
vocab token predefin vocab must contain token
vocab

staticmethod
sentenc sentenc sentenc length dtype int32
logger error sentanc text deprec thi
neon text preprocess
sentenc sentenc
sentenc length sentenc length
dtype dtype


staticmethod
path vocab size 20000 sentenc length
start index seed test split
logger error text deprec thi
neon text preprocess
path
vocab size vocab size
sentenc length sentenc length

start start
index index
seed seed
test split test split

reset

reset start index dataset back zero
relev want call repeat evalu dataset
want wrap around last uneven minibatch
necessari ndata divis batch size

batch index

iter

gener use iter dataset

yield
tupl minibatch

batch index
batch index nbatch
batch batch index astyp float32 order
batch batch index astyp float32 order

onehot input
batch
onehot lblflat axi

batch

batch
onehot lblflat axi

batch index




shakespear dataset
init timestep path
http stanford peopl karpathi
shakespear init shakespear input

4573338
path path
timestep timestep

load
filepath load filenam size
filepath

iter
load
train path valid path text creat valid file filepath
dict
dict train text timestep train path
vocab dict train vocab
dict valid text timestep valid path vocab vocab
dict


dataset

penn tree bank

argument
timestep timestep emb
onehot input
token name token within


init timestep path
onehot input
token
http githubusercont wojzaremba lstm master
filemap train 5101618
test 449945
valid 399782
key filemap key
filenam filenam phase phase key
size filemap phase phase key
init filenam

size
path path
timestep timestep
onehot input onehot input
token token
token
hasattr token
token func getattr token

token func

staticmethod
newlin token
replac newlin
newlin count word
replac split

staticmethod
filenam phase
phase

load
file path
phase filemap
filenam phase
size filemap phase
file path phase load size
file path

iter
load

dict
vocab
phase train test valid
file path file path phase
dict phase text timestep
file path
token token func
onehot input onehot input
vocab vocab
vocab
vocab dict train vocab
dict


hutter prize dataset
init path
hutter prize init enwik8
http mattmahoney
35012219
path path

load
filepath load filenam size
filepath


imdb dataset
init vocab size sentenc length path
http amazonaw text dataset
imdb init imdb

33213513
path path
vocab size vocab size
sentenc length sentenc length
filepath

load
filepath load filenam size
filepath

iter
filepath
load

filepath vocab size vocab size
sentenc length sentenc length
train train test test nclass

dict nclass nclass
dict train array iter train train nclass
dict test array iter test test nclass
dict

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


ctype
log
numpi

atexit

neon nervana object
neon dataset dataset
neon dataiter nervana data iter

logger log get logger name


imag loader nervana data iter

encapsul loader librari expos backward compat
iter minibatch imag

argument
repo directori find imag batch load
inner size side dimens imag loader spatial
dimens imag datum inner size inner size
scale rang tupl scale rang scale side given input imag
imag exampl scale rang
inner size imag first scale
random crop size
taken result transform center
crop taken scale rang tupl like
resiz dimens randomli select
transform
lower valu alway use scale rang
entir imag use without regard aspect
ratio imag entir imag use
rescal inner size inner size output
transform option whether appli transform scale flip
random crop flip
center crop taken shuffl
argument also ignor default
option whether channel input pure
grayscal support default
shuffl option whether shuffl order imag load
use batch normal default
subset option valu indic percentag
dataset partit default
name option which dataset partit either train valid
default train
nlabel option mani label exist imag default
macro option whether macrobatch input use input
file read imag use debug
default
contrast rang tupl option specifi contrast contrast
percentag valu indic rang
randomli vari contrast imag contrast
variat appli contrast contrast
default
aspect ratio option zero interpret
randomli stretch imag either horizont
vertic direct amount
aspect ratio exampl aspect ratio impli
squar crop stretch horizont
vertic direct randomli determin rang

transform random stretch occur
default


init repo inner size scale rang transform
shuffl name train subset
nlabel macro
contrast rang aspect ratio
imag loader init name name

valu error imag current support
configur repo inner size scale rang transform
shuffl name subset macro
contrast rang aspect ratio
libpath path dirnam path realpath file

loaderlib cdll load librari
path join libpath loader loader
loaderlib start restyp
loaderlib argtyp
loaderlib stop argtyp
loaderlib reset argtyp

logger error unabl load loader ensur
file compil
npix inner size inner size
ishap inner size inner size

shape ishap

nlabel nlabel

iobuf npix

view subtract mean
find shape fast broadcast
imag reshap ishap shape
fast rang imag
view reshap ishap imag fast fast

buffer
label
rang
buffer append shape dtype uint8
label append iobuf nlabel dtype int32
onehot label iobuf nclass

mean
mean mean

just center uint8 valu miss mean
mean
start
atexit stop

configur repo inner size scale rang transform
shuffl name subset macro
contrast rang aspect ratio

dataset config option

subset subset
subset must
name train valid
name name name train

repo repo
inner size inner size
isinst scale rang
scale rang scale rang scale rang

scale rang scale rang
minibatch size

center transform
flip transform
contrast rang contrast rang transform
aspect ratio aspect ratio transform
transform
scale rang scale rang scale rang
transform
aspect ratio aspect ratio
valu aspect ratio augment

shuffl shuffl transform


start
macro macro
batch prefix macrobatch

macro
filenam path join repo filelist
path exist filenam
io error cannot find filenam
filelist genfromtxt filenam dtype
ndata filelist subset
ndata
macro start
nlabel
nclass
mean
size inner size


load repo dataset cach
cach filepath path join repo batch prefix meta

dataset cach dict
open cach filepath
line
line split
dataset cach endswith mean
rgbmean dataset cach mean
dataset cach mean rgbmean dtype float32
io error
io error cannot find batch writer preprocess
creat batch file imageset cach filepath

should follow defin
attribut mean nclass start train start
train nrec nrec
item size label size

attribut
dataset cach
valu error
dataset cach miss requir attribut

dict updat dataset cach
filenam path join repo batch prefix

label
isinst nclass dict
nclass nclass label

rec avail getattr name nrec
macro start getattr name start
ndata rec avail subset

properti
nbatch
start ndata ceildiv

init batch provid

backward compat



batch provid

backward compat



start

launch background thread load

data buffer pair pointer ubyt
label buffer pair pointer

devic param structur
field

data buffer pair
label label buffer pair

devic
buffer data buffer pair
buffer tensor ctype pointer ubyt
buffer tensor ctype pointer ubyt
label buffer label buffer pair
label tensor ctype pointer
label tensor ctype pointer

buffer data buffer pair
cast buffer gpudata pointer ubyt
cast buffer gpudata pointer ubyt
label buffer label buffer pair
cast label gpudata pointer
cast label gpudata pointer
devic param devic devic
buffer label buffer
loader loaderlib start inner size
center
flip

scale rang
scale rang
contrast rang
contrast rang
ignor rotat
aspect ratio
minibatch size
filenam
macro start
ndata
nlabel
macro
shuffl
item size
label size
pointer devic param
start

stop

clean background thread

loaderlib stop loader

reset

restart index

reset local state

start
loaderlib reset loader

iter
start rang start ndata
start ndata
ndata
start ndata start
loaderlib loader
separ step avoid possibl cast error
buffer

mean
view view mean

hack decent performnac
real broadcast support
rang view shape
view view mean

expand label devic
onehot label onehot label
axi

onehot label


dataset
init inner size subset

inner size inner size
subset subset

load
path isdir

iter
option dict repo
inner size inner size
subset subset
train imag loader name train transform option
imag loader name valid transform option

dict train train
valid
dict


name main
timeit timer
neon backend backend
neon util argpars neon argpars
parser neon argpars
arg parser pars arg

backend backend seed
nervana object

master imag loader repo arg name train scale rang
inner size subset
timer
total time

epoch rang
master
epoch master start master master ndata
argmax axi
master stop

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


neon dataiter nervana data iter data iter array iter
neon dataset dataset
neon dataload load mnist load cifar10 load babi load flickr8k
load flickr30k load coco load i1kmeta load text
i1 kmeta load shakespear
neon text text shakespear hutter prize imdb
neon batch writer batch writer batch writer i1 k
neon imageload imag loader
neon questionansw babi
neon ticker ticker copi task repeat copi task prioriti sort task
neon speech speech
neon video video
neon imagecapt imag caption imag caption test flickr8k flickr30k coco
neon imag mnist cifar10
neon pascal pascalvoc train pascalvoc infer

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


function use load commonli avail dataset


log

neon dataset dataset
neon imag mnist cifar10
neon imagecapt flickr8k flickr30k coco
neon text shakespear imdb hutter prize

logger log get logger name


i1 kmeta dataset

helper load dataset meta

thi actual dataset instead meta


init path
http west amazonaw neon stockdataset imagenet
i1 kmeta init neon ilsvrc2012 devmeta

758648
path path

load
file path dataset load i1kmeta path
file path


function deprec remov futur releas
load i1kmeta path
i1kmeta dataset i1 kmeta path path
i1kmeta dataset file path


valid path append path arg
dataset valid path append path arg


fetch dataset sourcefil destfil totalsz
dataset fetch dataset sourcefil destfil totalsz


load mnist path normal
mnist dataset mnist path path normal normal
mnist dataset load


comput transform img filter bia
cifar10 comput transform img filter bia filter bia


whiten train test cach
cifar10 whiten train test cach cach


contrast normal scale divisor
cifar10 contrast normal scale scale divisor divisor


load cifar10 path normal contrast normal whiten
cfiar10 dataset cifar10 path path
normal normal
contrast normal contrast normal
whiten whiten
cfiar10 dataset load


load babi path task singl support fact subset
not implement load babi remov


load train path
dataset timestep path path
dataset load
dataset file path train


load valid path
dataset timestep path path
dataset load
dataset file path valid


load test path
dataset timestep path path
dataset load
dataset file path test


load hutter prize path
dataset hutter prize path path
dataset load


load shakespear path
dataset shakespear timestep path path
dataset load


load flickr8k path
dataset flickr8k path path
dataset load


load flickr30k path
dataset flickr30k path path
dataset load


load coco path
dataset coco path path
dataset load


load imdb path
dataset imdb vocab size sentenc length path path
dataset load


load text dataset path
logger error load text deprec meta dictionari
pleas dataset class specif load
dataset use
deprec method load text use dataset index
dataset meta dictionari temporari backward compat place
dataset meta dictionari
dataset meta
mnist
size 15296311
file mnist
http amazonaw dataset
func load mnist

cifar
size 170498071
file cifar python
http toronto kriz
func load cifar10

babi
size 11745123
file task
http thespermwhal jaseweston babi
func load babi

train
size 5101618
file train
http githubusercont wojzaremba lstm master
func load train

valid
size 399782
file valid
http githubusercont wojzaremba lstm master
func load valid

test
size 449945
file test
http githubusercont wojzaremba lstm master
func load test

hutter prize
size 35012219
file enwik8
http mattmahoney
func load hutter prize

shakespear
size 4573338
file shakespear input
http stanford peopl karpathi
func load shakespear

flickr8k
size 49165563
file flickr8k
http west amazonaw neon stockdataset imag caption
func load flickr8k

flickr30k
size 195267563
file flickr30k
http west amazonaw neon stockdataset imag caption
func load flickr30k

coco
size 738051031
file coco
http west amazonaw neon stockdataset imag caption
func load coco

i1kmeta
size 758648
file neon ilsvrc2012 devmeta
http west amazonaw neon stockdataset imagenet
func load i1kmeta

imdb
size 33213513
file imdb
http amazonaw text dataset
func load imdb


meta dataset meta dataset
dataset meta file meta meta size path path
load filenam size

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


machin gener dataset


numpi

neon nervana object


task nervana object

base ticker task inherit


fetch time step

gener input output numpi tensor
pair size appropri minibatch

column time step
input zero column
output zero nout column
input output

fill buffer time step input output tensor tensor mask

logist stuff numpi array safe devic
thi almost certainli clean

input output small properli shape array
column time step
zero column
out c zero nout column
column input
out c column output

copi array devic
tensor
tensor out c

mask unus part buffer
mask column
mask column


copi task task

copi task neural ture machin paper
http arxiv 1410 5401

thi version task batch
sequenc mini batch length
everi minibatch randomli chosen minibatch length

when given minibatch length mask output
time step time step

gener laid neon


init size

attribut ticker need

arg
longest allow sequenc length
size width vector copi paper



size size
nout size output dimens underli vector
size input dim start stop channel
time step func
time step
time step time step func
column time step

synthes tensor tensor mask


creat minibatch ticker copi task

arg
tensor devic buffer hold input
tensor devic buffer hold output
mask devic buffer output mask


sequenc minibatch length conveni
random randint
time step time step func

gener intermedi buffer right size
input output copi task fetch time step

start
input

gener sequenc copi
random randint
size size


stop
stop
input stop stop

place actual sequenc copi input
input size stop

place sequenc differ place output
output

fill devic minibatch buffer
copi task fill buffer time step input output
tensor tensor mask


repeat copi task task

copi task neural ture machin paper
http arxiv 1410 5401

comment copi task detail


init count size

attribut ticker need

arg
longest allow sequenc length
count repeat
size width vector copi paper



count
size size
nout size output sequenc stop stop channel
size input dim start stop channel

seen input count time output
start stop output stop
time step func
time step time step func count
column time step

synthes tensor tensor mask


creat minibatch ticker copi task

arg
tensor devic buffer hold input
tensor devic buffer hold output
mask devic buffer output mask

sequenc minibatch length conveni
random randint
count random randint count
time step time step func count

minibatch specif numpi buffer
input output repeat copi task fetch time step

start
input

gener sequenc copi
random randint
size size


count
todo normal count
stop
input stop stop count

place actual sequenc copi input
input size stop

place sequenc copi time output
rang count
start
stop start
output start stop

place output finish
output

fill devic minibatch buffer
repeat copi task fill buffer time step input output
tensor tensor mask


prioriti sort task task

prioriti sort task neural ture machin paper
http arxiv 1410 5401

comment copi task detail


init size

attribut ticker need

arg
longest allow sequenc length
size width vector copi paper



size size
nout size output sort sequenc stop
size extra channel start stop prioriti

seen input start stop bit
output sort order
time step func
time step time step func
column time step

synthes tensor tensor mask


creat minibatch ticker prioriti sort task

arg
tensor devic buffer hold input
tensor devic buffer hold output
mask devic buffer output mask


sequenc minibatch length conveni
random randint
time step time step func

minibatch specif numpi buffer
input output prioriti sort task fetch time step

start
input

gener sequenc copi
random randint
size
astyp

zero start stop prioriti channel


gener scalar prioriti
prioriti random uniform size
prioriti

stop
stop
input stop stop

place actual sequenc copi input
input stop

sort sequenc
rang
everi sequenc batch

everi column sequenc


sort column last prioriti
argsort

column back minibatch right place


output nout

fill devic minibatch buffer
prioriti sort task fill buffer time step input output
tensor tensor mask


ticker nervana object

thi defin method gener iter ticker dataset


reset

reset mean context ticker



init task

construct ticker dataset

arg
task repres task train
contain inform input output size
sequenc length also synthes
use gener minibatch


task task

these attribut make much sens context ticker
suspect hard
batch index
nbatch
ndata nbatch

alia code reli dataset nout
nout task nout
task

configur elsewher reli exist
shape task time step

initi input output mask
iobuf task time step
iobuf nout task time step
mask iobuf nout task time step

iter

gener use iter dataset

yield
tupl minibatch

second element tupl tupl
actual target gener task
output mask account differ
length minibatch
also column


batch index

batch index nbatch

task write minibatch buffer
task synthes mask

batch index

mask

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin text datatset preprocess routin


c pickl
numpi



clean













strip lower


sentenc sentenc sentenc length dtype int32
length sent sent sentenc

nsampl sentenc
sentenc length
sentenc length length

one nsampl sentenc length astyp dtype int32
sent enumer sentenc
trunc sent sentenc length
trunc trunc



path vocab size 20000 sentenc length
start index seed test split

open path
c pickl load
close

random seed seed
random shuffl
random seed seed
random shuffl

start
start index

index

vocab size
vocab size

convent word
reserv index charact pad
start

vocab size

train test split
train test split

test test split
test test split

train sentenc train sentenc length sentenc length
train train reshap train

test sentenc test sentenc length sentenc length
test test reshap test

nclass train test

train train test test nclass


pad xy vocab size 20000 sentenc length
start index seed shuffl

shuffl
random seed seed
random shuffl
random seed seed
random shuffl

start
start index

index

vocab size
vocab size

word start

vocab size

vocab size

sentenc sentenc length sentenc length
dtype int32 reshap




googl word2vec fname vocab vocab size 50000 index
open fname
header readlin
vocab1 size embed header split
binari dtype float32 items embed
vocab size vocab index vocab size
zero vocab size embed

found word
line enumer rang vocab1 size
word

read

word join word


word append
word vocab
vocab word index
vocab size
fromstr
read binari dtype float32
found word

read binari


rang vocab size
found word
random uniform embed

found word vocab size
embed vocab size

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


verifi differ way load dataset lead result

thi test util accept command line paramet neon
download cifar dataset save individu jpeg file
proce evalu model differ way load
macrobatch written disk need

follow
python compar bcpu place live



numpi
neon array iter
neon initi uniform
neon layer affin conv pool gener cost
neon model model
neon optim gradient descent momentum
neon transform misclassif rectlin softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars
neon load cifar10 imag loader batch writer
imag
glob glob

trainimg trainimg
testimg testimg


process dataset label inputpath leafdir
datadir path join inputpath leafdir
save imag datadir
mkdir datadir
ulabel uniqu label
ulabel ulabel
mkdir path join datadir ulabel
rang shape
reshap
uint8 transpos axe copi
imag fromarray
path path join datadir label
save path format


process inputpath
train train test test nclass load cifar10 inputpath
normal
process dataset train train inputpath trainimg
process dataset test test inputpath testimg


load dataset basepath datadir shuffl
path path join basepath datadir
path exist path
process basepath
subdir glob path join path
labelnam sort path basenam subdir
ind rang labelnam
labeldict labelnam ind
line
subdir subdir
subdirlabel labeldict path basenam subdir
file glob path join subdir
line filenam subdirlabel filenam file
line

shuffl
random seed
random shuffl line
rang line
asarray imag open line
transpos axe ravel

line shape dtype float32
label line dtype int32

label line
label


load cifar10 img path
train train load dataset path trainimg shuffl
test test load dataset path testimg shuffl
train train test test


write batch arg macrodir datadir
path exist macrodir

write batch macrodir
batch writer macrodir
imag path join arg datadir
target size macro size 1024
file pattern valid



arg train test
init uniform high
gradient descent momentum learn rate
momentum coef
stochast round arg round
layer conv init init activ rectlin batch norm
pool
conv init init activ rectlin batch norm
pool
affin nout init init activ rectlin batch norm
affin nout init init activ softmax
cost gener cost costfunc cross entropi multi
model layer layer
callback callback train test arg callback arg
train optim epoch arg epoch cost cost callback callback
test metric misclassif
misclassif error



test iter
test iter base reader
parser neon argpars
arg parser pars arg
train train test test nclass load cifar10 img path arg
train array iter train train nclass nclass lshape
test array iter test test nclass nclass lshape
arg train test


test loader
test imag loader
parser neon argpars
arg parser pars arg

train path join arg macrotrain
test path join arg macrotest
write batch arg train trainimg
write batch arg test testimg
train imag loader name train transform inner size
scale rang repo train
test imag loader name valid transform inner size
scale rang repo test
arg train test



test iter test loader
imag pil imag


numpi

open input binari file
infil argv
open infil
content read

unpack content

sqrt

offset
imlist
rang
unpack content offset offset
dtype uint8 reshap transpos copi
imlist append
offset

pil imag fromarray vstack imlist
save infil

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


tool pars neon model definit file yaml format
gener neon model object definit


copi deepcopi
numpi
yaml

neon nervana object
neon layer gener cost
neon model model
neon optim
neon layer contain sequenti


format yaml dict yamldict prefix

helper format yaml model config
proper format layer initi

argument
yamldict dict dictionari model paramet

prefix path

return
dict format dict

yamldict prefix yamldict
yamldict


creat object root yaml

batch size
seed
devic
dtype float32
stochast round

instanti object given specif

argument
root yaml dict model definit dictionari pars yaml file

backend either mgpu

seed random gener seed

devic backend devic

dtype numpi format type

stochast round bit stochast round
round

return
tupl contain model cost optim object


nervana object must gener backend run

give filenam pars dictionari
root yaml
open root yaml
root yaml yaml load read

refer use
root yaml deepcopi root yaml

initi layer
yaml layer root yaml layer

current support sequenti yaml
layer dict layer yaml layer
layer sequenti layer dict

initi model
model model layer layer

cost layer shortcut deriv
cost name root yaml cost
cost gener cost costfunc cost name

creat optim

optim root yaml
yaml root yaml optim
yaml
getattr neon optim yaml config

model cost

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


command line argument parser neon deep learn librari

thi wrapper around configargpars argument parser
add neon command line allow
addit ad argpars librari
method lower prioriti default also read configur file
specifi command line argument


configargpars
log
log handler rotat file handler
numpi

inspect

neon version neon version
neon backend backend
neon backend util check comput capabl devic count
neon callback callback callback

logger log get logger name


extract valid arg arg func startidx

given argpars arg extract applic func

argument
arg namespac arg argpars
func function inspect determin valid arg

return
dict valu pair arg valid func

func arg inspect getargspec func arg startidx
dict var arg item func arg


neon argpars configargpars argument parser

setup command line parser pars
configur file pars
option configur log

argument
desc string docstr call
thi use descript command receiv

init arg kwarg
pars
work path join path expandus nervana
config file kwarg
kwarg config file path join work
neon
config file help kwarg
turn gener config help config file sinc
referenc unsett config option like version
kwarg config file help
neon argpars init arg kwarg

valu display help
formatt configargpars argument default help formatt

setup arg

setup arg

setup use neon


argument version action version version neon version
argument config config file
help read valu
configur file specifi first
argument verbos action count
help verbos level multipl
increas verbos
store negat progress arg progress
pars
argument progress
action store
help suppress run display progress
train loss

runtim specifc option
argument group runtim
argument
path join work
help work directori cach
download preprocess dataset
argument epoch
help complet pass dataset
argument save path
help file path save model snapshot
argument serial narg
metavar
help serial model everi epoch
argument model file help load model file
argument dest logfil narg
path join work neon
help file
argument output file
help hdf5 file metric comput
option use nvi
visual
argument freq
help frequenc epoch test
argument histori
help checkpoint file retain

argument group backend
argument backend choic mgpu argon
comput capabl

help backend multi support premium
featur avail exclus
nervana cloud pleas contact
info nervanasi detail
argument devic
help devic use backend
argument devic devic count
help gp us use mgpu backend

argument seed
metavar seed
help random gener seed
argument round


narg
metavar bit

help stochast round round bit
bit specifi
argument datatyp choic
metavar datatyp
help float point
precis backend
argument batch size
help batch size
argument caff action store
help match caff comput conv pool layer output
size dropout implement
argument determinist action store
help determinist kernel applic


yaml

yaml file argument need script
pars model config yaml file


yaml configur file
argument yaml file
configargpars file type
help neon model specif file

argument arg kwarg

method command line ad parser pass
straight parent argument method

pars
logger warn ad pars
need rerun pars arg
reset warn come
pars

neon argpars argument arg kwarg


never config arg pars defin
prevent document indent warn



never config arg pars defin
prevent document indent warn



pars arg

pars command line setup neon
runtim environ accordingli

argument
parser
gener backend

return
contain pars attribut

arg neon argpars pars arg
use relay except logger

log
thresh critic debug higher

thresh arg verbos
attribut error type error
default given
latter error
thresh
arg thresh thresh

log format
fmtr log formatt asctim name levelnam messag

parent logger neon
main logger log get logger neon
main logger set level thresh

setup consol stderr handler
stderrlog log stream handler
stderrlog set formatt fmtr

expand user directori path
path save path model file output file
logfil
getattr arg path
setattr arg path path expandus getattr arg path

arg logfil
file well
filelog rotat file handler filenam arg logfil mode
max byte 10000000 backup count
filelog set formatt fmtr
filelog set level thresh
main logger add handler filelog

file specifi progress display
error consol
arg progress
stderrlog set level thresh

stderrlog set level log error

stderrlog set level thresh

handler instead
main logger propag
main logger add handler stderrlog

need write otherwis numpi
gener byte bit bit
arg datatyp arg datatyp
arg datatyp dtype arg datatyp

invert progress mean store arg progress
arg progress arg progress

arg backend arg round
backend support stochast round
logger except
not implement error

done front avoid lose incorrect path
arg save path
savedir path dirnam path abspath arg save path
access savedir

makedir savedir
os error
creat save path savedir
path exist arg save path
logger warn save file exist attempt overwrit arg save path
access arg save path
write save path file arg save path

logger except
io error

arg serial arg save path
arg save path neon model
logger warn path given model serial
arg save path
arg save path arg serial
arg serial
logger warn schedul given model serial
arg serial

arg model file

path exist arg model file
model file present arg model file
access arg model file
read access model file arg model file

logger except
io error

arg caff
arg compat mode caff

arg compat mode

arg determinist
logger warn determinist flag deprec specifi random seed
determinist behavior
extend parser need gener backend argpars

gener backend
backend backend arg backend
seed arg seed
devic arg devic
batch size arg batch size
datatyp arg datatyp
devic arg devic
compat mode arg compat mode

display command line config option
logger info format valu

pars
arg arg
arg callback arg extract valid arg arg callback init startidx
arg

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

importlib
log

pkgutil


neon util compat pickl

logger log get logger name


dir exist path

simpl helper ensur directori specifi path
creat prior

argument
path path file directori intermedi
directori creat

return
unmodifi path valu

outdir path dirnam path
outdir path isdir outdir
makedir outdir
path


save save path

dump python structur save disk represent
current support write follow file format expect filenam
extens bracket

python pickl

argument
python save
save path where write serial full path
file name

also
func neon model model model serial

save path save path

save path path expandvar path expandus save path
logger debug serial save path
dir exist save path

pickl dump open save path


load load path

load save disk represent python structur
current support follow file format

python pickl

argument
load path load serial full path
file name


isinst load path
load path path expandvar path expandus load path
load path endswith
gzip
load path gzip open load path

load path open load path
fname load path name

logger debug deseri fname

pickl load load path
attribut error
problem deseri possibl
chang sinc serial
need remov recreat load path
logger error
attribut error


load ctype

helper take neon
classnam

argument
ctype neon
neon layer layer linear
return


extract name neccessari
path ctype
part path split
join part

clss
comp part
clss getattr clss comp
clss
valu error import error

find insid neon
modul neon
prfx name
imptr pkgutil iter modul path prefix prfx
importlib
hasattr ctype
getattr ctype



serial model callback dataset dump weight keep state
pdict model serial keep state keep state
callback
pdict callback callback serial

dataset
pdict dataset dataset serial

pdict
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


script convert batch writer dataset cach mean format
format full imag mean format singl mean valu
channel input imag thi script overwrit exist
cach pickl file

argument
cach file path cach file path print
except rais neon detect
cach mean format


argpars

numpi
neon util persist load save


name main
parser argpars argument parser
parser argument cach file help path cach file
arg parser pars arg

cach file arg cach file

check access file
path exist cach file file exist cach file
access path abspath cach file
io error need read write permiss file cach file

load cach file

mean size
valu error cach file miss mean

size
mean

shape shape shape
valu error mean shape match format expect shape

collaps full tensor mean channel mean correct order
mean mean reshap axi reshap

save cach file

updat format cach file

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

log

neon model model model
neon callback callback callback
neon util persist load load

logger log get logger name


deseri dataset infer

helper load object serial file
includ callback dataset well model layer


argument
dataset data set option dataset serial
file pass
argument thi also
dataset serial
file
infer option weight load
state
return
model model
dataset
callback callback

config dict load

dataset
logger warn ignor dataset serial archiv file
dataset config dict
load config dict dataset
dataset config dict dataset config
dataset dataset iter

train dataset
iter dataset train

dataset key
iter dataset
logger warn could find train iter
instead

model model config dict iter

callback
callback config dict
callback look dataset object
replac correspond
config dict callback callback

config
config
config
config dict config
config data
config name
dataset
config dataset

config
gener callback
callback callback load callback config dict callback model
model dataset callback

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi



neon util persist load


model descript dict

contain model serial dictionari provid
helper method search manipul dicitonari

argument
pdict dict configur dictionari gener
model serial name
pickl file contain dictionari

init pdict
pdict
pdict load pdict
model descript init pdict

properti
version

print neon version

return
version


neon version

layer field name regex

print layer name model
option filter result

argument
field option configur field file
layer name
regex option regular express appli field
file result conv

exampl
layer field name regex conv layer
name contain conv

regex
regex compil regex
find layer model config field regex regex

staticmethod
find layer layer field regex
match
layer layer
field config
valu config field
regex regex match valu
match append valu
dict layer config
match extend model descript find layer config field regex regex
match

getlay layer name

find layer name

argument
name name layer

return
dict layer config dictionari

find name model config layer name

staticmethod
find name layer layer name
layer layer
name config config name layer name

dict config layer config
model descript find name config layer name



staticmethod
match

compar model descript instanc

argument
model descript dict compar
model descript dict compar

return
object match





dict
key key
miss key


name
ignor layer name

model descript match

tupl


val1 val2
model descript match val1 val2

ndarray
match equal
match





check model match
model model
match model model



copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


contain variou function wrapper make code python python
compat



log


logger log get logger name
version info

keep rang call consist python
note need iter rang
rang rang

logger info xrang rang
rang xrang

keep c pickl queue string io consist python
renam

c pickl pickl
queue queue
string io string io

pickl pickl
queue queue
string io

pickl pickl
queue queue
string io string io

copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


templat cuda kernel
gener
stage
red32




init rand func initi lfsr
init rand round func
finish rand func
common urand
common frand
common round random
nearest
common fp16 fp32 assembl convers
type
string
finit assembl test
unari binari element oper
reduct argmax argmin


rand pool size 65536 2048



defin 402823466 e
defin rand pool size 65536

common

defin thread thread

name
rand state


thread idx
block idx

share s partial

init



stage


thread

load





red32

pragma unrol


shfl






s partial
syncthread

pragma unrol
thread


share1
syncthread




share2

syncthread seem prevent race condit caus problem

pragma unrol

shfl

s partial

syncthread
s partial


















finish




init rand func
lfsr0 lfsr1 lfsr2
thread
rand state rand pool size
lfsr0 rand state rand pool size
lfsr1 rand state rand pool size
lfsr2 rand state rand pool size



init rand round func
rand scale mantissa bit
rand scale rand scale
rand mask 0xffffffff mantissa bit



finish rand func
rand state rand pool size lfsr0
rand state rand pool size lfsr1
rand state rand pool size lfsr2


common kepler
defin


common urand
devic urand lfsr0 lfsr1 lfsr2

lfsr0 lfsr0 0xfffffffe lfsr0 lfsr0
lfsr1 lfsr1 0xfffffff8 lfsr1 lfsr1
lfsr2 lfsr2 0xfffffff0 lfsr2 lfsr2
lfsr0 lfsr1 lfsr2




common frand
devic forceinlin frand lfsr0 lfsr1 lfsr2

urand urand lfsr0 lfsr1 lfsr2


0 f2f800000
urand





common round

random


devic fp32 fp32 rand
lfsr0 lfsr1 lfsr2 rand scale
rand mask

urand urand lfsr0 lfsr1 lfsr2



expon frand result
expon 0xff800000
expon expon
frand
result expon frand
result
rand scale urand rand mask





devic fp32 fp16 rand
lfsr0 lfsr1 lfsr2 rand scale
rand mask

urand urand lfsr0 lfsr1 lfsr2

half

result16
expon frand result32
expon 0xff800000
expon expon
frand
result32 expon frand
result32 result32
result16 result32
result16
half rand scale urand rand mask

half



devic forceinlin fp32 int32 rand
lfsr0 lfsr1 lfsr2

urand urand lfsr0 lfsr1 lfsr2


frand result32
frand
copysign frand frand
frand frand 0 f2f800000
result32 frand
result32
urand




devic forceinlin fp32 int16 rand
lfsr0 lfsr1 lfsr2

urand urand lfsr0 lfsr1 lfsr2
half

frand result32
frand
copysign frand frand
frand frand 0 f2f800000
result32 frand
result32
half urand
half



devic forceinlin fp32 int8 rand
lfsr0 lfsr1 lfsr2

urand urand lfsr0 lfsr1 lfsr2


frand result32
frand
copysign frand frand
frand frand 0 f2f800000
result32 frand
result32
urand




nearest


devic forceinlin fp32 fp16











devic forceinlin fp32 int32







devic forceinlin fp32 uint32







devic forceinlin fp32 int16







devic forceinlin fp32 uint16







devic forceinlin fp32 int8







devic forceinlin fp32 uint8








random round use type
dtype
common round random dtype common round nearest dtype

mode random nearest
xtype ityp
common round mode xtype common round mode ityp


common fp16 fp32
devic forceinlin fp16 fp32











common
devic forceinlin










type


type4 float4





type4 ushort4
fp16 fp32
fp32 fp16



























scale



scale



scale




string

stage

strd strd
init strd strd
thread strd
load



strd strd take
init take strd
strd
thread strd
load



strd strd take
init strd
take take
load take
take thread

out0
strd strd
init strd strd
thread strd
output

out1
strd strd take
init take strd strd
thread strd
output


out2
strd strd take
init strd
take

output take take thread


onehot0
onehot
init onehot
load onehot onehot
onehot thread

onehot1
onehot
init onehot onehot
load




round
random
fp32 fp32 rand lfsr0 lfsr1
lfsr2 rand scale rand mask
fp32 fp16 rand lfsr0 lfsr1
lfsr2 rand scale rand mask
fp32 uint32
fp32 uint16
fp32 uint8
fp32 int32 rand lfsr0 lfsr1 lfsr2
fp32 int16 rand lfsr0 lfsr1 lfsr2
fp32 int8 rand lfsr0 lfsr1 lfsr2
fp32 int32 rand lfsr0 lfsr1 lfsr2
fp32 int16 rand lfsr0 lfsr1 lfsr2
fp32 int8 rand lfsr0 lfsr1 lfsr2

nearest
fp32 fp16
fp32 uint32
fp32 uint16
fp32 uint8
fp32 int32
fp32 int16
fp32 int8
fp32 int32
fp32 int16
fp32 int8






finit


pred finit
testp finit finit
selp 0 f3f800000 0 f00000000 finit




note binari operand come stack revers order

assign unus










minimum fminf
maximum fmaxf
powf
finit finit


copysignf
sqrt sqrtf

expf
logf
safelog logf
exp2 exp2f
log2 log2f
expf
sig2 exp2f
tanh tanhf
tanh2 exp2f exp2f
rand frand lfsr0 lfsr1 lfsr2
onehot



reduct

init

shfl shfl
share1 s partial s partial
share2 s partial s partial


init
fmaxf
shfl fmaxf shfl
share1 s partial fmaxf s partial s partial
share2 fmaxf s partial s partial


init
fminf
shfl fminf shfl
share1 s partial fminf s partial s partial
share2 fminf s partial s partial

argmax
init

shfl max2 shfl arg max2 shfl
max2 max2 arg max2
max2 arg max2 arg max2

argmin
init

shfl min2 shfl arg min2 shfl
min2 min2 arg min2
min2 arg min2 arg min2



copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


float point elementwis oper


path

traceback
numpi
pycuda compil sourc modul
pycuda tool context depend memoiz
pytool memoiz
pytool memoiz method
pycuda driver comment stylecheck

neon backend nervanagpu

neon backend cuda templat
stage

init rand func
init rand round func
finish rand func
common kepler
common urand
common frand
common round
common fp16 fp32
type
string
finit

reduct

neon backend cuda batchnorm fprop kernel
bprop kernel
neon backend kernel cuda lookupt bprop kernel
sort kernel


build tree arg

rebuild tree stack
flag node whether scalar
also count reduct node
node tensor scalar count left child right child


stack
arg


numop
zero arg scalar
node numop
rang numop
operand stack
child anoth node tree
operand
accumul reduct count
node operand
child scalar neither node
operand
node
child input tensor output tensor
node scalar
output tensor check shape axi flag
operand gpu tensor operand operand
node
children start posit ad revers order
node insert operand
stack append node

reduct
operand stack
red
child anoth node accumul reduct count
operand
red operand
reduct scalar definit
stack append red operand


tensor scalar ad stack
later process oper
stack append

stack contain singl node complet
tree
stack

debug


tree node level

tree indent


node
level join node
node
tree node level
node
tree node level

level node


post order node stack

gener stack portion tree


stack
stack

node
node
post order node stack
node
post order node stack
stack append node

stack append node
stack


process node node alias duplic

take node tree search previous process
duplic
duplic return stage base node
duplic node replac stage
case tree remov node remain


gener uniqu stack everyth reduct
stack post order node

item stack
oper append name
alias well sinc encapsul specif
tensor constant
item item alias
append item
tensor constant append

append item
tupl

gener look duplic
node duplic
node
duplic replac stack node
origin reduct
node node
stage return node convert

stack

first time see reduct record dict
last item stack reduct
duplic stack
record node alias
alias stack

drop children children start posit
node
node

stack


split stage node duplic alias stage parent

split reduct post reduct scalar oper seper
stack stage
thi leav remain tree anyth categori


init structur
duplic
duplic dict
alias
stage
parent

node

count assign node parent
alway exist stage process outsid

node assign
parent append node

post order travers pull stage deepest tree first
node
split stage node duplic alias stage parent
node
split stage node duplic alias stage parent

parent
parent

node reduct

stack process node node alias duplic
stack
reduct stack stage
stage append reduct stack

decrement reduct count parent
parent parent
parent

walk parent
todo potenti iter find longest common
oper
scalar parent
parent parent
find highest parent scalar
child reduct
parent parent
scalar parent parent



scalar oper reduct remov
tree well
scalar parent

scalar stack process node
scalar parent alias duplic
scalar stack
scalar stack stage
stage append scalar scalar stack

stage


init rand val

val common append common urand
val init append init rand func
val finish append finish rand func



context depend memoiz
compound kernel arg comput capabl

gener compound kernel optre arg


stack rebuild tree
tree build tree arg
tree tree


split reduct post reduct scalar oper tree
tree convert stack push onto stage
stage split stage tree
tree tree


stage output scalar elementwis
last stage tree
convert remaind tree stack
stage append last stage post order tree

stage stage enumer stage
stage stage
stage



stack
placehold
stage dict
dict dict

fp16 in
rand init
rand func
thread arg

val
thread thread
name kernel name
common
init
finish


stage stage enumer stage

stage stage stack stage
placehold

build process stage
stage reduct

placehold append load stage
placehold append stage
placehold append shfl stage
stage format stage
thread
placehold append stage
placehold append share1 stage
placehold append share2 stage
stage format stage

stage red32 format stage

stage scalar

placehold append stage
stage format stage

stage

placehold append stage
stage format stage



placehold append load stage
placehold append stage
stage format stage

placehold
val
placehold extend placehold

enumer stage stack



array operand
gpu tensor

dtype take axi

tensor stage
stage

first output stack
tensor
dtype dtype
take take axi

stack append

stage
dtype type dtype
stage dtype dtype

first time tensor initi everyth



stage


take axi


output tensor
tensor
string take axi
format
val init append
init format
input tensor

string take axi
load load stage
format
val init append
init format
val load append
load format

dtype fp16 in
val common append common fp16 fp32
fp16 in

dict

subsequ time tensor initi init
load
stage
stage
string take axi
load load stage
val init append init format
val load append load format

constant operand


stack append
dict
dict
string format

oper name


assign

stage

condit last stage

stage

round mode

mode random

append mantissa bit
rand init
rand init init rand val
val init append init rand round func

mode nearest

dict join

stack
last stack valu came argmax
convers
dtype
round

round string round
mode dtype
common common round mode dtype
common
val common append common

round
round
val append
round format round

round

val append
string take output format round

stage

stack append stage



val name
val name append

stage

code

rand
rand init
rand init init rand val
rand func
val common append common frand
rand func



build operand stack
rang
append stack

onehot

axi
test axi

string axi
load load stage
val init append
init format
val load append
load format
append onehot
append test

dict
format

val append code format

last current stack store stage
stage output dict
stage stack
stage
otherwis push onto stack normal

stack append

reduct

val name
val name append

condit current stage
regardless duplic reduct stage
dict stage

avoid convers argmax


stage
shfl shfl stage

string reduct
stack stack

val init append
string init format
val append
string format stack
val shfl append
string shfl format
thread
stage
shr1 share1 stage
shr2 share2 stage
val append
val shr1 append
string share1 format
val shr2 append
string share2 format

reduct alway last stack
store state stage output dict
stage


valu error

comput capabl comput capabl comput capabl
val common append common kepler



sinc reorderd oper need gener argument
origin order


unus
arg
dict


append
dict
fill counter duplic reduct
remov
reduct

append unus unus
unus

convert list string
val name join val name
val common join val common
val join
val init join val init
val finish join val finish

dynam placehold load reduct
placehold
val join val

popul
code val

debug
compil val name
open kernel
open val name
code
close

keep
sourc modul code option fast math
sourc modul code option
kernel val name
kernel name val name
kernel prepar

kernel


memoiz
fast dim size

todo probabl much better code
think tensor evenli divis
size
size
size size

size
size
size
size
size size

size

shape size size size
shape contigu stride shape

todo build program wide call startup
assign


call compound kernel rand state comput capabl arg

pass gpu tensor object constant oper postfix notat


call compound kernel assign






kernel arg rand state
arg
shape stack
thread
depth
appli reduct constraint determin thread axi
block alloc counter axi
also detect broadcast transpos
contigu
reduct
broadcast
transpos
argminmax
takeop
axi
shape arg shape
arg
dict
name
name reduct

name
argminmax

reduc whole tensor axi reduc along axi
success
axi
valu error
onli reduct along axi current support

keep axi valu consist within kernel
reduct
axi axi
valu error
reduct allow along axi kernel

reduct
axi axi
name onehot
takeop

isinst gpu tensor
shape
broadcast
shape shape shape shape
broadcast
tran
transpos
take
takeop
contigu
contigu

reduc along axi need revers stridess
each block get column thread work column
stride order axi

arg

array operand
isinst gpu tensor

complex oper dimens
broadcast reduct transpos takeop contigu
shape
shape shape
stride stride stride order

valu error
oper simpl elementwis
current support dimens

effici dimens plain

shape stride fast dim size
stride stride stride order

pass multipl time express
consolid kernel argument

indx


first pass output
duplic first
need pointer
subsequ present
pointer


indx

indx


support broadcast
need shape determin stride
oper take
take
shape
stride axi
shape
stride axi

shape
stride axi
shape
stride axi

kernel arg extend gpudata stride stride

fanci index take
take
kernel arg append take gpudata

swap take axi reduc axi
also distinguish take oper
take
axi
take axi take

take axi take
take oper

take axi

arg append
gpu tensor indx dtype take axi shape axi

shape stack append shape

constant operand




indx

indx


kernel arg append

arg append indx
shape stack append

oper
dict

name

name

need shape arithemt current oper
shape
rang name
shape shape stack
rang
shape shape
support broadcast
todo allow output tensor broadcast
output fine broadcast exampl
assign constant
dont want tensor assign
smaller shape
shape shape
shape shape shape

type error
input shape compat shape

name assign

axi thread stop condit
kernel arg append shape axi

round round

support round arbitrari mantissa size
round
convert mantissa
round
round
dtype float32
round round
dtype float16
round round

kernel arg append round

speed deep reduct thread
argminmax
reduct
depth
thread

bring code back figur race condit
depth 4096
thread 1024
depth 2048
thread
depth 1024
thread
depth
thread
depth
thread
speed deep broadcast thread
reduct transpos shape
thread

arg append name round thread

name onehot

flip axi reduc axi
axi axi axi axi

arg append name axi
shape stack append shape
kernel arg append gpudata


arg append name
shape stack append shape

name reduct

shape shape stack

depth depth shape axi

allow axi size post reduct broadcast
need know axi size prior reduct
kernel arg append shape axi
arg append name

reduc current shape
shape axi

udpat current shape state
shape stack append shape


type error valid oper name




type error
arg must gpu tensor dict oper

argsprint
kernel arg
arg

creat kernel memoiz cach
kernel compound kernel tupl arg comput capabl

share thread reduct thread

backend bench
backend bench
start event
start record backend stream



rang

call kernel block size axi
maxwel well thread size block need autotun
kernel arg
kernel prepar async call shape axi
thread backend stream
kernel arg share size share

backend bench
record backend stream
synchron
msec time sinc start
msec shape
msec shape shape shape axi thread kernel name




context depend memoiz
compens kernel dtype round

compens

common

compens rand state



scale scale
strd strd mantissa bit

thread idx
block idx

offset strd strd
strd

offset
offset
offset

init







adjust amount previou compens
scale scale

accumul truncat storag



convert accumul back fp32 math


recov order bit lost truncat










finish


val dict
common init finish
val

dtype
val common common fp16 fp32

round
val common common urand
val common common round nearest dtype
val init init rand func init rand round func
val finish finish rand func
mode random

mode nearest

val common common round mode dtype

val type dtype
val type dtype



string round mode dtype
string round nearest dtype

val format
val format

code compens val

open compens
code
close

sourc modul code
kernel compens
kernel prepar ppp pffiiii
kernel


compil nervanagpu
name compil


kernel name

return path kernel

name kernel

nvprof environ
frame extract stack
search frame

caller frame

file path file name path split caller
path1 path2 path split file path
file path splitext file name

name path2 file
name name name
name
name append name

name append caller

name


context depend memoiz
hist kernel dtype nbin offset

build kernel comput histogram

templat gener custom kernel depend input

memoiz avoid compil kernel twice

type dtype
templat
code templat common fp16 fp32

defin
defin

kernel histo
hist
stride size

thread idx
block idx

share nbin
nbin



nbin
hist


block dim size stride

convert

absval fab

logab round log2f absval

nbin logab offset

atom add



syncthread

nbin
atom add hist




sourc modul code substitut
convert
nbin nbin
offset offset
option
kernel kernel histo
kernel prepar ppii
kernel


comput hist tensor hist nbin offset

helper comput histogram tensor

argument
tensor gpu tensor tensor comput histogram
hist pointer memori region store hist
nbin option histogram bin repres power

offset option offset valu power
offset mean repres

thread
nbin thread nbin

size tensor size
stride floor sqrt size thread thread
stride thread
stride size thread thread thread

block stride thread

kernel arg hist tensor gpudata stride size
hist kern hist kernel tensor dtype nbin offset
hist kern prepar call block thread kernel arg

pycuda compil sourc modul
pycuda tool context depend memoiz

neon backend cuda templat
stage

init rand func
init rand round func
finish rand func
common urand
common frand
common round
common fp16 fp32
type
string
finit

reduct
neon backend cuda templat common round
common kepler
type
common fp16 fp32
string


context depend memoiz
fprop kernel dtype thread comput capabl

thread
code share s partial thread
code
s partial xvar
syncthread

pragma unrol
thread


s partial s partial
syncthread



xvar s partial s partial
pragma unrol

xvar shfl xvar

s partial xvar rcp n

syncthread
xvar s partial


code
code
pragma unrol

xvar shfl xvar
xvar rcp n


code
defin thread thread

common

batchnorm fprop
xvar gmean gvar
xsum gmean
gvar gamma beta
accumbeta relu

share

thread idx
block idx
offset

offset

rcp n

xmean xsum rcp n

xvar
thread


thread

xmean
xvar



gamma gamma
beta beta



gmean gmean
gvar gvar

xvar xvar
gmean gmean xmean
gvar gvar xvar


xvar sqrt sqrtf xvar

start thread
offset start
offset
offset

start thread thread

thread thread
thread thread
thread thread
thread

thread

xhat0 xmean xvar sqrt
xhat1 xmean xvar sqrt
xhat2 xmean xvar sqrt
xhat3 xmean xvar sqrt

xhat0 gamma beta
xhat1 gamma beta
xhat2 gamma beta
xhat3 gamma beta

relu

fmaxf
fmaxf
fmaxf
fmaxf






accumbeta

thread thread
thread thread
thread thread
thread



thread thread thread accumbeta
thread thread thread accumbeta
thread thread thread accumbeta
thread thread accumbeta

thread



code string round nearest dtype
common code common round nearest dtype
dtype
common code common fp16 fp32

comput capabl comput capabl comput capabl
common code common kepler

code code
common common code
share code
code
thread thread
type dtype
type dtype
code format
code format
code format
code format

sourc modul code option fast math
kernel batchnorm fprop
kernel prepar ppppppppp pfff ii
kernel name batchnorm fprop
kernel


context depend memoiz
bprop kernel dtype thread comput capabl

thread
code share s partial thread
code
s partial thread grad gamma
s partial thread grad beta
syncthread

pragma unrol
thread



s partial thread s partial thread
s partial thread s partial thread

syncthread



grad gamma s partial thread s partial thread
grad beta s partial thread s partial thread

pragma unrol


grad gamma shfl grad gamma
grad beta shfl grad beta

s partial thread grad gamma
s partial thread grad beta

syncthread
grad gamma s partial thread
grad beta s partial thread


code
code
pragma unrol


grad gamma shfl grad gamma
grad beta shfl grad beta



code
defin thread thread

common

batchnorm bprop
delta grad gamma grad beta
delta xsum
xvar gamma


share

thread idx
block idx
rcp n
offset

offset
delta offset

xmean xsum rcp n
xvar xvar
gamma gamma

xvar sqrt sqrtf xvar
grad gamma
grad beta

thread


thread

thread

xhat xmean xvar sqrt

grad gamma xhat
grad beta





grad gamma grad gamma
grad beta grad beta


start thread
offset start
offset
delta offset
delta offset

start thread thread

thread thread
thread thread
thread thread
thread

thread thread
thread thread
thread thread
thread

thread
thread

xhat0 xmean xvar sqrt
xhat1 xmean xvar sqrt
xhat2 xmean xvar sqrt
xhat3 xmean xvar sqrt

xtmp0 xhat0 grad gamma grad beta rcp n
xtmp1 xhat1 grad gamma grad beta rcp n
xtmp2 xhat2 grad gamma grad beta rcp n
xtmp3 xhat3 grad gamma grad beta rcp n

delta0 gamma xtmp0 xvar sqrt
delta1 gamma xtmp1 xvar sqrt
delta2 gamma xtmp2 xvar sqrt
delta3 gamma xtmp3 xvar sqrt

delta0
delta1
delta2
delta3
thread delta thread delta0
thread delta thread delta1
thread delta thread delta2
delta thread delta3
delta thread



code string round nearest dtype
common code common round nearest dtype
dtype
common code common fp16 fp32

comput capabl comput capabl comput capabl
common code common kepler

code code
common common code
share code
code
thread thread
type dtype
type dtype
delta0 code format delta0 delta0
delta1 code format delta1 delta1
delta2 code format delta2 delta2
delta3 code format delta3 delta3

sourc modul code option fast math
kernel batchnorm bprop
kernel prepar ppppppp pf i
kernel name batchnorm bprop
kernel

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


backend layer

math



ceil

ceil need math




conv layer


conv layer paramet
thi pass argument convolut oper

number imag mini batch
number input featur map
number output featur map

depth input imag
height input imag
width input imag

depth filter kernel
height filter kernel
width filter kernel

pad amount zero pad around given edg
stride factor step filter given direct


init dtype





bsum

comput output spatial dimens
output
output
output










pad
stride
bsum bsum

dim i
dim f
dim o
dim i2
dim f2
dim o2
size i reduc dim i
size f reduc dim f
size o reduc dim o
n out reduc

m slice fprop slice rang
p slice fprop slice rang
q slice fprop slice rang
d slice bprop slice rang
h slice bprop slice rang
w slice bprop slice rang

fprop slice pad stride
first f
last f
stride pad
last f

first f



last f

slice first f last f slice last f first f

bprop slice pad stride
pad
slice f
slice o
rang

stride
stride

slice f append
slice o append
slice f slice o


deconv layer conv layer


deconv layer paramet
thi pass argument convolut oper

number imag mini batch
number output featur map
number input featur map

height input
width input

depth output imag
height output imag
width output imag

depth filter kernel
height filter kernel
width filter kernel

pad amount zero pad around given edg
stride factor step filter given direct


init dtype






const




cannot exact uniqu



track












pad
stride

chang name dim i dim o even though dim i technic
dimens output
dim i
dim f
dim o
dim i2
dim f2
dim o2
size i reduc dim i
size f reduc dim f
size o reduc dim o
n out chang input
n out reduc

d slice bprop slice rang
h slice bprop slice rang
w slice bprop slice rang
m slice fprop slice rang
p slice fprop slice rang
q slice fprop slice rang


pool layer


pool layer paramet
thi pass argument pool kernel

pool
number imag mini batch

number input featur map
depth input imag
height input imag
width input imag

size featur pool window maxout piec
depth pool window
height pool window
width pool window

pad amount zero pad around given imag featur edg
stride factor step window given direct overlap allow

leav spatial dimens allow featur pool layer



init dtype






overlap










overlap math ceil
math ceil
math ceil
math ceil

overlap

comput output dimens
output pool
output pool
output pool
output pool








jtr


pad
stride

dim i
dim o
dim f2
dim i2
dim o2
size i reduc dim i
size o reduc dim o
n out reduc

k slice pool slice rang
m slice pool slice rang
p slice pool slice rang
q slice pool slice rang

pool slice pad stride
stride pad
first i
rang


first i
first i
last i
slice first i last i last i first i

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


base backend tensor structur




numpi
pycuda driver
log
pycuda tool context depend memoiz
pycuda curandom mrg32k3a random number gener
pycuda gpuarray gpu array gpuarray
unpack
pytool memoiz method
functool wrap
math

neon backend kernel spec
neon backend backend tensor backend op tree node op collect
neon backend layer conv layer deconv layer pool layer count
neon backend kernel cuda pool roipool
scikit cuda cubla

none slice slice

logger log get logger name


gpu tensor tensor


dimension structur resid memori
meant manipul

argument
dtype numpi ndtype option underli element
alloc option memori alloc
gpu tensor option tensor tensor
differ view keep track
origin tensor
gpudata pycuda driver devic alloc option actual
memori store
tensor
stride tupl option tupl byte step dimens travers

take indic valu extract
tran option whether tensor transpos
round option desir mantissa bit
stochasicali round zero disabl
stochast roud

also
nervana gpu

note
unlik numpi implement never collaps dimens
minim dimens dim current
match cudanet implement wrap scalar
dimens


init
backend
shape
dtype float32
name
persist valu
alloc alloc

gpudata
stride
take
tran
round

gpu tensor init backend shape dtype name
persist valu

support dtype
dtype float16 float32 uint8 int8 uint16
int16 uint32 int32

dtype dtype dtype

isinst shape tupl shape dim
shape shape


size
shape
size
type error
isinst shape integ
size shape
shape shape

isinst size integ
size asscalar size

support order
stride
stride contigu stride shape

stride tupl stride


shape shape
size size
dtype dtype
nbyte dtype items size
alloc alloc
take take
tran tran
round round
kahan count
kahan reset

gpudata
alloc
size
info
gpudata alloc nbyte

gpudata



gpudata gpudata



return represent tensor

return
represent

gpu tensor name shape dtype stride
tran contigu gpudata name
shape dtype
stride tran
contigu

repr

return unambigu represent tensor

return
represent





return size lead dimens

return
size lead dimens

shape
shape



setitem index valu

getitem index assign valu

getitem index

return slice view

isinst index tupl
speed common
index none slice

index index

shape
offset
stride

seen ellipsi
take

index axi
axi

index axi index

index entri index index axi

axi shape
index error mani axe index

standard slice start stop step
isinst index entri slice
start stop stride index entri indic
shape axi

stride stride axi

ceil
shape append start stop stride
stride append stride stride
offset stride start dtype items

index axi
axi

fanci index
isinst index entri gpu tensor ndarray tupl

isinst index entri tupl
index entri index entri dtype int32

isinst index entri ndarray
index entri
backend index entri shape dtype int32 index entri

size index entri shape
size index entri size
index error
fanci index current support singl dimens

take
index error
fanci index current support axi time

index entri dtype int32
todo work type need
test
index error
fanci index current support int32 type

take index entri axi

shape append size
stride append stride axi

index axi
axi

isinst index entri integ
shape shape axi
index entri
index entri shape

index entri shape
index error
subindex axi rang index axi

offset stride axi
index entri dtype items

shape
shape append
stride append stride axi

index axi
axi

index entri ellipsi
index axi

remain index count index index axi
axi shape remain index count
axi axi
index error invalid ellipsi index
axi axi
shape append shape axi
stride append stride axi
axi

seen ellipsi
index error
ellipsi allow index
seen ellipsi


index error invalid subindex axi index axi

axi shape
shape append shape axi
stride append stride axi

axi


backend backend
shape tupl shape
dtype dtype
alloc alloc

gpudata gpudata offset
stride stride
take take
name name
round round



return integ represent underli memori buffer

return
represent

gpudata

assign valu

assign valu tensor

argument
valu gpu tensor op tree node valu assign


stream backend stream
isinst valu

contigu speedi driver kernel
contigu

valu dtype valu

dtype items
memset async
gpudata unpack valu size stream
dtype items
memset async
gpudata unpack valu size stream

memset async
gpudata unpack valu size stream

otherwis copi kerel

op tree node build assign valu

isinst valu gpu tensor
todo binari compat like
contigu valu contigu dtype valu dtype
memcpi dtod async
gpudata valu gpudata nbyte stream

op tree node build assign valu

collaps execut tree kernel
isinst valu op tree node
op tree node build assign valu

assign numpi
isinst valu ndarray
valu


type error invalid assign valu





copi host devic

argument
host need contigu

return
gpu tensor

stream backend stream
size size
contigu array must contigu
dtype dtype
astyp dtype
ndim dim
reshap size
stride tupl
dtype items stride

memcpi htod async gpudata stream



stream

copi devic host

return
numpi ndarray host numpi


contigu
shape dtype
memcpi dtoh async gpudata stream

contigu need copi devic
backend shape dtype
copi
shape dtype
memcpi dtoh async gpudata stream


asnumpyarray

deprec
schedul remov
instead



asbuff

asbuff return buffer

gpudata buffer nbyte

take indic axi

take element along axi

axi
view getitem none slice indic

view getitem indic none slice


assign view
view

fill valu
assign valu

copi
assign

copi
copi


reshap shape

reshap view

isinst shape tupl
shape tupl shape

shape dim
shape shape

shape
miss size prod shape
shape tupl miss shape

shape shape


size prod shape

size size
valu error total size must unchang

contigu
type error reshap contigu array support


backend backend
shape shape
dtype dtype
alloc alloc

gpudata gpudata
stride contigu stride shape
name name
round round

properti


transpos view

shape
shape shape
stride stride

support batch
perserv outer dimens revers inner dim
shape shape
stride stride
shape tupl shape shape
stride tupl stride stride


backend backend
shape shape
dtype dtype
alloc alloc

gpudata gpudata
stride stride
tran tran
name name
round round

transpos

return transpos view alia properti need
compat


op tree node build assign


share shape dtype name

view size size
allow easi share temporari memori

size prod shape
size size
valu error total size must size parent

contigu
type error share contig
array support

dtype
dtype dtype

dtype dtype dtype




backend backend
shape shape
dtype dtype
alloc alloc

gpudata gpudata
stride contigu stride shape
name name
round round

hist

comput histogram current tensor valu

argument
identifi current state tensor
use disambigu multipl histogram
tensor differ point time

return
tensor contain histogram


nbin backend hist bin
offset backend hist offset
neon backend comput hist
hist tensor backend hist tensor
comput hist hist tensor gpudata nbin offset
hist tensor

properti


return integ represent underli memori buffer

return
represent

gpudata

properti
memoiz method
contigu

return whether memori tensor contigu

return
whether memori tensor contigu

take stride contigu stride shape


memoiz stack func

memoiz stack intrins map

cach

wrap func
memoiz optre
optre tensor index index tensor optre intrins map
make sure backend
optre optre
optre cach
replac tensor
stack cach tensor index cach optre
stack stack
rang stack
isinst stack tensor
stack cach tensor index
stack index tensor
cach tensor index stack
updat cach tensor index
cach optre stack tensor index

cach stack tensor index
creat memoiz stack
stack func optre
cach optre stack tensor index
stack

memoiz


nervana gpu backend

primari factori gpu tensor

argument
stochast round option desir mantissa
bit stochas round
disabl
stochast round

round width
bench option perform
kernel call
perform print
compat mode option flag match implement librari
compat current caff support

todo defin keyword paramet


size pool devic
current hard wire
pool size 2048
init
seed
dtype float32
stochast round
determinist
devic
bench
scratch size
hist bin
hist offset
compat mode
enabl winograd
cach path join path expandus nervana cach
dtype float16 float32
valu error default nervanagpu
backend must float16

dtype float32
stochast round
stochast round
valu error default round width
support fp32 pleas specifi
bit round
logger warn use float point set stochast
round bit stochast round

context
init
devic
devic devic devic
devic devic make context

store rand pool context
context rand state store memori refer
context rand state aliv whether randstat fresh

init
nervana gpu init seed
dtype
compat mode compat mode
determinist determinist


logger info initi nervana gpu

stochast round
stochast round sure global backend
stochast round
stochast round
stochast round

stochast round

attribut
scratch size scratch size
scratch offset
round mode stochast round
bench bench
stream

activ
warmup

store histogram batch memcpi
hist bin hist bin
hist offset hist offset
hist dict
hist
hist 4096
hist alloc hist bin hist
memset hist hist bin hist

fall back cuda kernel older maxwel gener
comput capabl devic devic comput capabl
comput capabl
cudac kernel
cubla handl cubla cubla creat

logger warn neon highli optim maxwel gp us although
might speedup cp us note
run maxwel might
experi fastest perform faster
perform nervana cloud contact
info nervanasi

cudac kernel

enabl winograd enabl winograd
cach cach
path isdir cach
makedir cach

scratch buffer size

size
size size

size scratch size
runtim error nervanagpu scratch size small oper scratch size

scratch offset size

scratch scratch size

scratch buffer offset size

size
size size

size scratch offset scratch size
runtim error nervanagpu scratch size small oper scratch size

scratch scratch size scratch offset
scratch offset size



scratch size arg

total size
size arg
size
size size
total size size

total size scratch size
scratch size total size



detach



event
event

seed

gener random gener devic host

argument
seed random gener seed

return
seed numpi

gener host
random random state seed

handl normal distribut number devic

save initi state host
init state state

gener random integ seed lsfr
rn gs devic
init state randstat

call mainli devic state
init state
reset

current context alreadi clear
context current
context rand state aliv
context rand state aliv

gener devic
rand state state init state


randstat

gener random uint32 number seed lfsr
state devic

return
vector uint32 number

numpi gener state
want reset done
state save state

smaller 32bit system
maxexp maxint

draw pool size int seed lfsr devic
lower bound avoid seed lfsr
rand init random integ maxexp nervana gpu pool size
rand init rand init astyp uint32

numpi host back state
state state save

rand init

reset

reset initi state store
init state init state
host devic respect

state init state init state

state state

state devic host rn gs

argument
state tupl array tupl element
numpi random state vector
uint32 specifi state

state tupl state
rand state state state
state state

state

return current state host devic rn gs

return
host devic state vector
respect

state rand state
state local zero nervana gpu pool size astyp uint32
memcpi dtoh state local state
state state local

rand state state

devic state valu given state input

argument
state uint32 valu use
state devic lf rs
state creat
randomli

context current
state
state randstat
context rand state
rand state context rand state

rand state alloc state nbyte
context rand state rand state
memcpi htod rand state state
context rand state aliv


fill normal mean stdv

fill gaussian nois given mean

fill normal gpuarray shape dtype gpudata gpudata
mean stdv
stdv mean

rand state

similar context depend memoiz addit abil reset
random pool reset

initi common pool random
thread multiprocessor somewhat futur proof
power thi size current hardcod kernel
parameter

context current
context rand state context rand state aliv
rand state
context rand state

malloc shape

return buffer size shape equival call shape

creat buffer shape
shape
shape
shape activ
activ shape
alloc buffer need
shape
shape append shape dtype dtype
activ
shape
activ shape append


free

move tensor buffer activ buffer
idea reus tensor optre

shape activ
shape extend activ shape
activ shape

hist tensor

creat tensor right size histogram memori alloc
contigu histogram buffer track later refer

hist hist
hist hist hist hist bin
hist hist
hist
gpu tensor shape hist bin dtype int32
gpudata hist name

dump hist
hist gpu tensor
shape hist hist bin
dtype int32
gpudata hist
hist hist
hist dict
hist
hist hist

memoiz stack
split stack optre

split optre stack

post order travers
whole stack optre travers

build stage stage contain optre
stage
main stage
main stage axi

minor axi binari oper suport axi
axi count
whole stack
isinst dict op collect reduct
axi axi
axi count axi
minor axi axi count axi count

travers stack split stage
whole stack
isinst dict

convert left right child tensor
right main stage
main stage axi care valu
left main stage
main stage axi care valu
isinst left op tree node
left malloc left shape
stage append op tree node assign left
left
left left
isinst right op tree node
right malloc right shape
stage append op tree node assign right
right
right right
buffer store result
malloc left shape right shape
save stage
stage append op tree node assign
op tree node left right
push main stage
main stage append
main stage axi append
transpos
transpos must optre
operand main stage
main stage axi care valu
alloc operand shape
malloc operand shape
evalu
stage append op tree node assign operand
back main stage
main stage append
main stage axi append
op collect reduct
sinc reduct convert
axi
operand main stage
prev axi main stage axi
prev axi prev axi axi
everyth previou reduct
malloc operand shape
stage append
op tree node assign operand
current reduct main stage
main stage append op tree node
main stage axi append axi

standari op collect unari
main stage append op tree node operand
main stage axi append axi
op collect unari
multipl axi reduct problem
build optre back
operand main stage
axi main stage axi
main stage append op tree node operand
main stage axi append axi cancel
op collect binari
binari might multipl axi reduct
right main stage
prev axi right main stage axi
left main stage
prev axi left main stage axi
prev axi right
prev axi left
prev axi left prev axi right
reduct minor axi
prev axi left minor axi
malloc left shape
stage append
op tree node assign left
left
axi prev axi right

malloc right shape
stage append
op tree node assign right
right
axi prev axi left
append main stage
main stage append op tree node left right
main stage axi append axi

multipl axi reduct perform standard process
main stage append op tree node left right
axi
prev axi left
axi prev axi left

axi prev axi right
main stage axi append axi

not implement

tensor scalar push main stage
main stage append
main stage axi append

append last stage
stage append main stage

build stack call compound kernel
stack
stage stage
stage exact simpl optre
isinst stage op tree node
creat stack
stack append stage travers

free buffer activ without loos refer
free

stack

simpl stack stack

todo move split stack deal memoiz better
todo test func

reduct axe
stack
isinst dict
transpos

op collect reduct
reduct axe axi
reduct axe axi



execut optre

execut optre break optre optre necessari

neon backend call compound kernel

post order stack
stack optre travers

bypass stage creation
simpl stack stack
call compound kernel rand state comput capabl stack

creat stage evalu
stack split stack optre

stack stack
stack isinst stack dict
stack
evalu simpl
compound stack stack stack

call compound kernel rand state comput capabl stack

stack todo remov use partial

shape dtype name persist valu
parallel distribut alloc alloc

alloc space gpu tensor

dtype dtype dtype dtype
gpu tensor shape dtype dtype name name
persist valu persist valu alloc alloc
round round mode

dtype name persist valu
parallel distribut alloc alloc

convert numpi gpu tensor

dtype dtype dtype dtype
ndim dim
reshap size
gpu tensor shape dtype dtype name name
persist valu persist valu alloc alloc
round round mode

zero shape dtype name persist valu
parallel distribut alloc alloc

return given shape dtype fill

dtype dtype dtype dtype
gpu tensor shape dtype dtype name name
persist valu persist valu alloc alloc
round round mode assign

one shape dtype name persist valu
parallel distribut alloc alloc

return given shape dtype fill

dtype dtype dtype dtype
gpu tensor shape dtype dtype name name
persist valu persist valu alloc alloc
round round mode assign

like name

return anoth

gpu tensor shape dtype dtype
name name persist valu persist valu
alloc alloc round round mode

zero like name

return anoth

gpu tensor shape dtype dtype
name name persist valu persist valu
alloc alloc
round round mode assign

compound alpha beta relu bsum size

alpha beta
alpha beta
alpha beta

relu appli output prior beta addit

size 32x128 128x32 64x128 128x64 128x128 sometim
fastest tile chosen

dtype dtype dtype

cudac kernel
rang
cubla alpha alpha beta beta

bsum
bsum


diment must contigu
stride
stride
stride

stride
stride
stride

tran

dtype items save kernel



tran



dtype items save kernel




shape
shape
shape

shape
shape
shape

some basic tile size select
your best benchmark code size
manual fine tune select layer
todo perhap autotun mode
size
find shorter side

anyth bigger

comput remaind
short128
remaind
short128
figur need calc
occup
short128
occupancy64
wide
occupancy64 wide wide
count
faster occup
warp schedul
occupancy64
size

size

size

size
there larg regim faster hard
character

size

match kernel optim size avoid
implement kernel


size
size a size b size


size
temp till write kernel come soon
size
size
size a size b size

size size a size b


size a size b size split

grid a size a size a
grid b size b size b

size a size b



stride stride



stride stride



stride stride



effici
dtype float16
clss hgemm
dtype float32
clss sgemm

type error onli float point current support

flag
relu
flag

kernel kernel spec kernel join clss size

grid a grid b kernel thread stream
gpudata gpudata gpudata alpha beta flag



warmup

rang
kernel prepar async call

bench
start event
start record stream

rang
kernel prepar async call

bench
record stream
synchron
msec time sinc start
gflop msec 1000000
msec gflop size grid
msec gflop clss size grid a grid b

gflop
bsum
bsum


batch alpha beta relu size
dtype dtype dtype

cudac kernel
not implement error batch implement kepler

flag
relu
flag

dima dimb dimc
ldaz ldbz ldcz
batch grid batch loop

shape
dima
ldaz stride

shape
dimb
ldbz stride

dima dimb tensor must dim batch

shape
dimc
ldcz stride
batch grid shape
dima shape batch grid
dimb shape batch grid

dima
batch loop shape
dimb shape batch loop

dimb
batch loop shape
dima shape batch loop

shape dima
shape dimb
shape dima

shape dimc
shape dimc
shape dimb

stride dima
stride dimb
stride dimc

tran

dtype items save kernel



tran



dtype items save kernel





batch loop
size
size

size
temp
size

size



size
size a size b size


size
temp till write kernel come soon
size
size
size a size b size

grid a size a size a
grid b size b size b
thread size
size size a size b

size a size b






effici
dtype float16
clss hgemm
dtype float32
clss sgemm

type error onli float point current support

kernel kernel spec kernel join clss size

batch grid grid a grid b thread stream
gpudata gpudata gpudata alpha beta flag

ldaz ldbz ldcz batch loop

warmup

rang
kernel prepar async call

bench
start event
start record stream

rang
kernel prepar async call

bench
record stream
synchron
msec time sinc start
gflop batch loop batch grid
msec 1000000
msec gflop size grid loop
msec gflop clss size batch grid grid a grid b batch loop

gflop



make binari mask keepthresh

creat binari mask dropout layer

argument
gpu tensor output tensor
keepthresh fraction one

dropout keep keepthresh

rand

gener random uniformli distribut

argument
tensor option result store
tree return

return
op tree node result tree

op tree node build rand

dropout keep

return keep mask dropout

argument
keep option keep threshold valu smaller keep
otherwis
tensor option result store
tree return

return
op tree node result tree

less equal rand keep

compens tensor tensor tensor scale scale
neon backend compens kernel fast dim

tensor kahan reset tensor kahan count tensor kahan reset
scale
tensor kahan count

tensor dtype tensor dtype tensor dtype

tensor kahan count

shape stride fast dim tensor size

kernel compens kernel
tensor dtype tensor round

kernel prepar async call
shape stream rand state
tensor gpudata tensor gpudata tensor gpudata
scale scale
stride stride
shape tensor round

conv layer dtype





relu bsum

creat conv layer paramet
thi pass argument convolut oper

number imag mini batch
number input featur map
number output featur map

depth input imag
height input imag
width input imag

depth filter kernel
height filter kernel
width filter kernel

pad amount zero pad around given edg
stride factor step filter given direct

dtype need know dtype setup proper kernel

relu appli relu output fprop bprop

bsum calcul along batchnorm axi fprop bprop
output fp32 tensor size

conv layer dtype

relu bsum

fprop conv layer alpha beta bsum
layer size i size
layer size f size
layer size o size

layer fprop kernel bind alpha beta bsum

execut conv fprop layer layer fprop kernel

bprop conv layer grad alpha beta bsum
layer size f size
layer size o size
layer size i grad size

layer bprop kernel bind grad alpha beta bsum

execut conv bprop layer layer bprop kernel

updat conv layer grad alpha
layer size i size
layer size o size
layer size f grad size

layer updat kernel bind grad alpha

execut conv updat layer layer updat kernel

execut conv layer kernel
warmup

kernel execut unbind

bench
start event
start record stream stream

kernel execut

todo sure part need cuda kernel
convert
convert gpudata convert reduc shape
comput capabl

bench
record stream stream
synchron
msec time sinc start
gflop layer flop msec 1000000
layer
msec gflop
msec gflop layer flop 1000000 layer
msec gflop


deconv layer dtype





relu bsum

creat deconv layer paramet
thi pass argument convolut oper

number imag mini batch
number output featur map
number input featur map

height input
width input

depth output imag
height output imag
width output imag

depth filter kernel
height filter kernel
width filter kernel

pad amount zero pad around given edg
stride factor step filter given direct

dtype need know dtype setup proper kernel

relu appli relu output fprop bprop

bsum calcul along batchnorm axi fprop bprop
output fp32 tensor size


deconv layer dtype

relu bsum

layer dtype

creat pool layer paramet
thi pass argument pool kernel

number imag mini batch

number input featur map
height input imag
width input imag

size featur pool window maxout piec

pad amount zero pad around given imag featur edg
stride factor step window given direct overlap allow

leav spatial dimens allow featur pool layer

onli support window size


opt dict




pool layer dtype dtype opt

fprop layer denom alpha beta ascal bpower

forward propag layer

argument
layer pool layer pool layer specd
tensor input tensor
tensor output tensor
denom tensor denomin tensor store result squar pool contrast
ascal scale paramet alpha multipli pool
bpower exponenti paramet beta denomin


layer size i size
layer size o size

layer jtr
layer dim i
layer dim o
layer pad
layer stride



kernel arg layer fprop kernel
share layer bprop size

execut layer denom
alpha beta ascal bpower kernel arg share

bprop layer delta denom
alpha beta ascal bpower

backward propag pool layer

argument
layer pool layer pool layer differ backend
differ pool layer
tensor input tensor
tensor error tensor
delta tensor gradient tensor delta
denom tensor denomin tensor comput bprop
ascal scale paramet alpha multipli pool
bpower exponenti paramet beta denomin


layer size i size
layer size o size
layer size i delta size
layer

layer jtr
layer dim i
layer dim o
layer pad
layer stride



kernel arg layer bprop kernel
share layer bprop size

execut layer delta denom
alpha beta ascal bpower kernel arg share

execut layer delta denom
alpha beta ascal bpower kernel arg share

dtype dtype
denom gpudata denom
kernel pool string2func kernel arg layer dtype comput capabl

flag
kernel arg kernel arg stream
gpudata gpudata alpha beta ascal bpower flag
extend kernel arg

kernel arg backprop kernel
kernel arg kernel arg stream
gpudata gpudata gpudata delta gpudata
alpha beta ascal bpower flag
extend kernel arg

warmup

rang
kernel prepar async call share size share

bench
start event
start record stream

rang
kernel prepar async call share size share

bench
record stream
synchron
msec time sinc start
msec grid msec layer kernel arg

pool layer dtype






creat pool layer paramet
thi pass argument pool kernel

pool
number imag mini batch

number input featur map
depth input imag
height input imag
width input imag

size featur pool window maxout piec
depth pool window
height pool window
width pool window

pad amount zero pad around given imag featur edg
stride factor step window given direct overlap allow

leav spatial dimens allow featur pool layer

overlap









pool layer dtype


fprop pool layer argmax alpha beta
layer size i size
layer size o size
layer
argmax pool requir argmax buffer
execut pool layer argmax alpha beta layer fprop kernel
layer fprop size

bprop pool layer argmax alpha beta
layer size i size missmatch size i layer size i size
layer size o size missmatch size o layer size o size
layer
argmax pool requir argmax buffer
argmax
layer size o argmax size pool argmax size match input size
dtype dtype
execut pool layer argmax alpha beta layer bprop kernel
layer bprop size

execut pool layer argmax alpha beta kernel arg share

dtype dtype
argmax gpudata argmax
kernel pool string2func kernel arg layer dtype comput capabl
flag
kernel arg kernel arg stream
gpudata gpudata alpha beta flag
extend kernel arg

warmup

rang
kernel prepar async call share size share

bench
start event
start record stream

rang
kernel prepar async call share size share

bench
record stream
synchron
msec time sinc start
msec msec layer


roipool fprop roi argmax count channel height width
pool height pool width spatial scale

function perform fprop roi pool

argument
tensor
roi tensor ro is
tensor pool height pool width count
argmax tensor pool height pool width count

thread 1024
count roi shape
count shape argmax shape

count channel pool height pool width count
count size argmax size
argmax dtype int32

block thread
thread thread

layer dtype dtype

kernel roipool string2func fprop roipool layer dtype

block count thread thread stream
count count channel height width
pool height pool width gpudata
roi gpudata gpudata argmax gpudata
spatial scale

kernel prepar async call

roipool bprop roi argmax count channel height width
pool height pool width spatial scale

function perform bprop roi pool

argument
tensor input error pool height pool width count
argmax tensor arg fprp pool height pool width count
roi tensor ro is
tensor output delta


thread 1024
count roi shape
count shape argmax shape

count channel height width
count size
argmax dtype int32

block thread
thread thread

layer dtype dtype

kernel roipool string2func bprop roipool layer dtype

block count thread thread stream
count count channel height width
pool height pool width gpudata
roi gpudata gpudata argmax gpudata
spatial scale

kernel prepar async call


compound fprop xsum xvar gmean gvar gamma beta
accumbeta relu thread

function perform compound kernel call batch normal
forward

argument
tensor input previou layer
xsum tensor precomput batch dimens
xvar tensor buffer varianc comput kernel
gmean tensor mean
gvar tensor varianc
gamma tensor scale paramet
beta tensor locat paramt
tensor normal output
constant numer stabil
exponenti window averag constant
accumbeta valu scale output accumul
relu compuound re lu activ kernel
thread number thread
repeat benchmark

xsum dtype float32

shape
shape

thread
8192
thread round

occup count

occup
thread

thread
thread 1024

thread backend stream
gpudata xvar gpudata gmean gpudata gvar gpudata
gpudata xsum gpudata gmean gpudata gvar gpudata
gamma gpudata beta gpudata accumbeta relu

neon backend fprop kernel

kernel fprop kernel dtype thread comput capabl

execut kernel nbyte

compound bprop delta grad gamma grad beta delta
xsum xvar
gamma thread

delta tensor delta buffer write output delta
grad gamma tensor gradient gamma
grad beta tensor gradient beta
delta tensor delta buffer input delta
tensor feedforward input
xsum tensor batch dimens
xvar tensor batch varianc
gamma tensor scale paramet
constant numer stabil
thread number thread
repeat benchmark

xsum dtype float32 xsum fp32

shape
shape

thread
8192
thread round

thread

thread backend stream
delta gpudata grad gamma gpudata grad beta gpudata delta gpudata
gpudata xsum gpudata xvar gpudata gamma gpudata

neon backend bprop kernel

kernel bprop kernel dtype thread comput capabl

execut kernel nbyte

execut kernel size

warmup

rang
kernel prepar async call

bench
start event
start record stream

rang
kernel prepar async call

bench
record stream
synchron
msec time sinc start
bandwidth size msec 1024 1024
block
thread
occup block thread count
msec g bp
msec bandwidth kernel name block thread occup


compound bprop input error error alpha beta

backward propag lookup tabl layer

argument
integ number input word
input tensor input tensor
error tensor error tensor
error tensor transpos error tensor
tensor gradient tensor delta
integ
alpha
beta

neon backend bprop kernel
sort kernel
embed shape
vocab size shape




determinist
index buffer error shape dtype int32
offset buffer error shape dtype int32
word count zero vocab size dtype int32

kernel rang
thread
kernel
block vocab size thread
vocab size thread
block block
kernel
block

block error shape thread
error shape thread
block block

block thread input backend stream
input gpudata index buffer gpudata offset buffer gpudata word count gpudata
vocab size error shape
kernel sort kernel kernel thread
kernel prepar async call

thread
block error shape

error error
block thread input backend stream
input gpudata index buffer gpudata gpudata error gpudata
embed vocab size

kernel bprop kernel error dtype
kernel prepar async call

thread
block error shape

error error
block thread input backend stream
input gpudata gpudata error gpudata embed vocab size


kernel bprop kernel error dtype
kernel prepar async call

cubla alpha beta

matrix multipl cubla librari intend kepler
gp us maxa kernel support

alpha beta

argument
tensor input tensor
tensor input tensor
tensor output tensor
alpha scalar
beta scalar

stride
stride
stride

tran
tran

shape
shape
shape

swap order fortran
dtype float32
cubla cubla sgemm cubla handl alpha gpudata
gpudata beta gpudata
dtype float16
fp16 gemm support cubla convers
temp malloc shape shape
temp malloc shape shape
temp malloc shape shape

fp32 gpu tensor shape dtype float32 gpudata temp gpudata
stride stride tran tran
fp32 gpu tensor shape dtype float32 gpudata temp gpudata
stride stride tran tran
fp32 gpu tensor shape dtype float32 gpudata temp gpudata
stride stride tran tran

fp32
fp32
fp32
cubla cubla sgemm cubla handl alpha fp32 gpudata
fp32 gpudata beta fp32 gpudata
fp32

free

type error unsupport cubla gemm

copi transpos axe

function perform fast copi transpos dimshuffl oper
work like numpi transpos requir output tensor argument

dtype dtype
size size
gpudata gpudata

axe
axe tupl rang shape
axe tupl
axe tupl axe

shape shape enumer axe

neon backend convolut copi transpos kernel

kernel copi transpos kernel dtype shape axe

arg kernel arg stride stride

warmup

rang
kernel prepar async call kernel grid kernel block
stream gpudata gpudata arg

bench
start event
start record stream

rang
kernel prepar async call kernel grid kernel block
stream gpudata gpudata arg

bench
record stream
synchron
msec time sinc start
bandwidth nbyte msec 1024 1024
msec g bp copi transpos msec bandwidth

init mark

gener time mark

return
time mark pycud driver

event

record mark marker

mark current time

argument
marker time mark time mark gener init mark

marker record stream

synchron mark marker

synchron given marker

argument
marker time mark time mark gener init mark

marker synchron

time start

return time start mark

argument
start time maker start time mark

time marker time mark

return
time elaps start time mark millisecond

time sinc start


note stride comput dtype items
contigu stride shape
shape
stride
shape
stride append stride
tupl stride




context depend memoiz
scratch scratch size
alloc scratch size


context depend memoiz
event
event event

debug tool

traceback

compil nervanagpu
trace
caller
frame extract stack
gpu tensor search frame

caller frame frame
caller
python
copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi
pycuda driver
neon backend nervanagpu nervana gpu
neon backend layer layer data layer conv layer pool layer full layer incept batch norm

compar result
http github soumith convnet benchmark

avail net
alexnet overfeat goog le net1 goog le net2
note goog le net2 fit fp16 current need work delta share incept layer
net alexnet alexnet bn goog le net1 bn

avail dtype float16 float32
dtype float16

full iter
loop
show bechmark detail layer
layer bench
show layer stat oper
stat
network zero speed differ
zero
stuff
verbos

nervana gpu bench layer bench

context current devic name

common convolut layer set
conv11
conv11p0
conv7
conv5
conv5p0
conv3
conv2
conv1

tradit pool
pool2s2p0
pool3s2p0
pool3s2p1
pool3s1p1
pool7s1p0

maxout pool
pool1j2 maxout layer
pool2j2
pool3j2

inception1 conf

layer incept partit

layer conv layer common conv1 relu conf


layer conv layer common conv1 relu conf
layer conv layer common conv3 relu conf


layer conv layer common conv1 relu conf
layer conv layer common conv5 relu conf


layer pool layer common pool3s1p1
layer conv layer common conv1 relu conf



inception1 bn conf

layer incept partit

layer conv layer common conv1 conf bsum
layer batch norm relu bsum


layer conv layer common conv1 conf bsum
layer batch norm relu bsum
layer conv layer common conv3 conf bsum
layer batch norm relu bsum


layer conv layer common conv1 conf bsum
layer batch norm relu bsum
layer conv layer common conv5 conf bsum
layer batch norm relu bsum


layer pool layer common pool3s1p1
layer conv layer common conv1 conf bsum
layer batch norm relu bsum




inception2 conf
layer layer incept partit
partit layer partit

conf
partit append
layer conv layer common conv1 relu conf


partit extend

layer conv layer common conv1 relu conf
layer conv layer common conv3 relu conf


layer conv layer common conv1 relu conf
layer conv layer common conv3 relu conf
layer conv layer common conv3 relu conf


conf
partit append
layer pool layer common pool3s1p1 conf
layer conv layer common conv1 relu conf


partit append
layer pool layer common pool3s1p1 conf

layer

inception2 bn conf
layer layer incept partit
partit layer partit

conf
partit append
layer conv layer common conv1 conf bsum
layer batch norm relu bsum


partit extend

layer conv layer common conv1 conf bsum
layer batch norm relu bsum
layer conv layer common conv3 conf bsum
layer batch norm relu bsum


layer conv layer common conv1 conf bsum
layer batch norm relu bsum
layer conv layer common conv3 conf bsum
layer batch norm relu bsum
layer conv layer common conv3 conf bsum
layer batch norm relu bsum


conf
partit append
layer pool layer common pool3s1p1 conf
layer conv layer common conv1 conf bsum
layer batch norm relu bsum


partit append
layer pool layer common pool3s1p1 conf

layer

network
alexnet
warmup
layer data layer
layer conv layer common conv11 relu
layer pool layer common pool3s2p0
layer conv layer common conv5 relu
layer pool layer common pool3s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool3s2p0
layer full layer n out 4096 relu
layer full layer n out 4096 relu
layer full layer n out 1000 relu

alexnet bn
warmup
layer data layer
layer conv layer common conv11 bsum
layer batch norm relu bsum
layer pool layer common pool3s2p0
layer conv layer common conv5 bsum
layer batch norm relu bsum
layer pool layer common pool3s2p0
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool3s2p0
layer full layer n out 4096
layer batch norm relu
layer full layer n out 4096
layer batch norm relu
layer full layer relu n out 1000

overfeat
warmup
layer data layer
layer conv layer common conv11p0 relu
layer pool layer common pool2s2p0
layer conv layer common conv5p0 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu 1024
layer conv layer common conv3 relu 1024
layer pool layer common pool2s2p0
layer full layer n out 3072 relu
layer full layer n out 4096 relu
layer full layer n out 1000 relu

overfeat bn
warmup
layer data layer
layer conv layer common conv11p0 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer conv layer common conv5p0 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer conv layer common conv3 1024 bsum
layer batch norm relu bsum
layer conv layer common conv3 1024 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer full layer n out 3072
layer batch norm relu
layer full layer n out 4096
layer batch norm relu
layer full layer relu n out 1000

http arxiv 1409 1556 variat

warmup
layer data layer
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer full layer n out 4096 relu
layer full layer n out 4096 relu
layer full layer n out 1000 relu

http arxiv 1409 1556 variat

warmup
layer data layer
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool2s2p0
layer full layer n out 4096
layer batch norm relu
layer full layer n out 4096
layer batch norm relu
layer full layer n out 1000 relu

here biggest model layer

warmup
layer data layer
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer conv layer common conv3 relu
layer pool layer common pool2s2p0
layer full layer n out 4096 relu
layer full layer n out 4096 relu
layer full layer n out 1000 relu

http arxiv 1409 4842
goog le net1
warmup
layer data layer
layer conv layer common conv7 relu
layer pool layer common pool3s2p1
layer conv layer common conv1 relu
layer conv layer common conv3 relu
layer pool layer common pool3s2p1
inception1
inception1
layer pool layer common pool3s2p1
inception1
inception1
inception1
inception1
inception1
layer pool layer common pool3s2p1
inception1
inception1
layer pool layer common pool7s1p0
layer full layer n out 1000 relu

http arxiv 1409 4842
goog le net1 bn
warmup
layer data layer
layer conv layer common conv7 bsum
layer batch norm relu bsum
layer pool layer common pool3s2p1
layer conv layer common conv1 bsum
layer batch norm relu bsum
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool3s2p1
inception1 bn
inception1 bn
layer pool layer common pool3s2p1
inception1 bn
inception1 bn
inception1 bn
inception1 bn
inception1 bn
layer pool layer common pool3s2p1
inception1 bn
inception1 bn
layer pool layer common pool7s1p0
layer full layer n out 1000 relu

adapt http github soumith kaggl retinopathi starter torch blob master model googlenet cudnn
goog le net2
warmup
layer data layer
layer conv layer common conv7 relu
layer pool layer common pool3s2p1
layer conv layer common conv1 relu
layer conv layer common conv3 relu
layer pool layer common pool3s2p1
inception2
inception2
inception2
layer conv layer common conv2 relu
inception2
inception2
inception2
inception2
inception2
layer conv layer common conv2 relu 1024
inception2
inception2
layer pool layer common pool7s1p0
layer full layer n out 1000 relu

adapt http github soumith kaggl retinopathi starter torch blob master model googlenet cudnn
goog le net2 bn
warmup
layer data layer
layer conv layer common conv7 bsum
layer batch norm relu bsum
layer pool layer common pool3s2p1
layer conv layer common conv1 bsum
layer batch norm relu bsum
layer conv layer common conv3 bsum
layer batch norm relu bsum
layer pool layer common pool3s2p1
inception2 bn
inception2 bn
inception2 bn
layer conv layer common conv2 bsum
layer batch norm relu bsum
inception2 bn
inception2 bn
inception2 bn
inception2 bn
inception2 bn
layer conv layer common conv2 1024 bsum
layer batch norm relu bsum
inception2 bn
inception2 bn
layer pool layer common pool7s1p0
layer full layer n out 1000 relu



net

dtype dtype

warmup network warmup
network network
name dtype dtype dtype name network

first need warmup
network warmup


benchmark name


layer
prev layer
delta
weight
delta layer
weight layer
share weight
share delta
incept

conf network

layer layer creat conf prev layer dtype

layer incept
incept

find size largest buffer share
layer size f weight
weight layer size f
weight layer layer

layer size i delta prev layer data layer
delta layer size i
delta layer layer

prev layer layer
layer append layer

init share buffer assum consist dtype
share delta append delta layer dim i dtype delta layer dtype
share delta append delta layer dim i dtype delta layer dtype
incept
share delta append delta layer dim i dtype delta layer dtype
share delta append delta layer dim i dtype delta layer dtype

share updat weight layer dim f dtype float32

layer enumer layer
verbos
layer

intit buffer alern share delta buffer
layer buffer error error
layer init activ
layer init weight share share updat zero zero

layer init delta share share delta

verbos
remain total info
3f gb 3f gb alloc 3f gb remain
total remain 1024 total 1024 remain 1024

zero
layer init

give first layer
layer init random uniform layer dim o

scale initi weight activ bound around
run forward collect mean stat
bench
propag
layer layer
propag layer fprop propag scale weight
bench layer bench

start event
event

fprop time
bprop time
fprop flop
bprop flop

away first run includ pycuda kernel load time clock warmup
count
rang loop warmup

warmup


start record
flop

fprop
propag
layer layer

propag layer fprop propag

flop layer flop
stat
layer fprop stat

record
synchron
msec time sinc start
fprop msec gflop
msec flop msec 1000000

fprop time msec
fprop flop flop

start record
flop

bprop
layer layer

propag layer bprop propag

flop layer flop
stat
layer bprop stat

record
synchron
msec time sinc start
bprop msec gflop
msec flop msec 1000000

bprop time msec
bprop flop flop

loop


name result

fprop msec gflop
loop fprop time loop fprop flop fprop time 1000000

bprop msec gflop
loop bprop time loop bprop flop bprop time 1000000

fprop time bprop time
fprop flop bprop flop

total msec gflop
loop fprop time loop fprop flop fprop time 1000000
python
copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

level control build instal clean variou target

optpars


path
subprocess
pycuda driver
kernel spec file kernel sass cubin dump

optpars option parser
option kernel action store dest kernel
help build updat kernel
option clean action store dest clean
help gener file
option preprocess action store dest preprocess
help preprocess sass file devel debug
option dump action store dest dump
help disassembl cubin file devel debug
option warn action store dest warn
help enabl warn devel debug
option concurr
help concurr launch maximum mani process
option verbos action store dest verbos
help output nvcc call
opt arg pars arg

opt preprocess opt dump
opt kernel


pycuda autoinit
attribut context devic attribut
major attribut devic attribut comput capabl major
minor attribut devic attribut comput capabl minor

work local cuda
major
minor

major minor
arch

arch

ptxa opt ptxa arch arch
maxa opt maxa
maxa opt maxa
dump opt nvdisasm

opt warn
maxa opt append

compil includ file
kernel compil n kernel


extract includ name includ
includ
includ
sass file path join sass name
includ append sass file
line open sass file
match search line
match
extract includ match group includ
includ

cubin dump
path exist
mkdir

compil cubin
build cubin
build
dump cubin

kernel name kernel spec kernel item

sass name kernel spec sass sass
cubin name kernel name cubin
name kernel name sass
dump name kernel name dump sass

file file kernel name arch
sass file path join sass sass name
file path join name
cubin file path join cubin cubin name
dump file path join dump dump name

maxa maxa opt kernel name
maxa maxa opt

arg kernel spec
pair kernel spec arg item
maxa append pair
maxa append pair

opt clean
file cubin file file dump file
path exist
remov


path exist sass file
miss sass file kernel sass file kernel name


path getmtim file
path getmtim file path exist file
cubin path getmtim cubin file path exist cubin file
dump path getmtim dump file path exist dump file

opt kernel cubin
compil cubin append ptxa opt cubin file file
cubin

opt dump cubin dump
dump cubin append dump opt cubin file dump file

opt kernel opt preprocess
extract includ sass name
path getmtim
opt preprocess

build append maxa sass file file

opt kernel
cubin
build cubin append maxa sass file cubin file



command command
kernel made
command
proc
cmdlist command opt concurr
cmdline join cmdlist
proc subprocess popen cmdline
shell
stdout subprocess pipe
stderr subprocess pipe
proc append proc cmdline

command opt concurr
proc cmdline proc
code proc wait
opt verbos
cmdline
code
proc stderr read
output proc stdout read
match kernel search output
match
kernel made append match group
output opt verbos
output

kernel made opt verbos
kernel compil kernel made

command compil cubin
command build cubin
command build
command dump cubin
python

copyright 2015 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi
ipdb trace
pack unpack

ceil


pad stride
ceil pad stride

strip mantissa
unpack pack 0x7f800000
unpack pack


quantiz bit sign
maxval absolut
scale strip mantissa maxval bit sign
around scale astyp int64
float64 scale

direct convolut

fconv slice pad stride


stride pad








slice slice

bconv slice pad stride
pad
first f
rang todo remov logic

stride
stride

first f
first f
first e
last f
last e
slice first f last f stride slice first e last e stride

xprop direct pad stride backward

shape
shape
shape
backward
cx hwn kx hwn
reshap reshap reshap shape

kx hwn cx hwn
reshap reshap reshap shape


backward
mirror
transpos copi
xconv slice bconv slice

xconv slice fconv slice

shape
shape
shape

q slice xconv slice pad stride rang

rang
slice r slice y xconv slice pad stride

rang
slice s slice x q slice

slice f slice r slice s reshap
slice i slice y slice x reshap

slice f slice i

updat direct pad stride

shape
shape
shape


cx hwn kx hwn
reshap reshap reshap shape


fill

q slice fconv slice pad stride rang

rang
slice r slice y rlen fconv slice pad stride

rang
slice s slice x slen q slice

slice i slice y slice x reshap
slice e

slice r slice s slice i slice e reshap rlen slen

winograd convolut











































































rcp3
rcp4
rcp6
rcp12
rcp24

tran minim tran
minim


















rcp6
rcp6
rcp24
rcp12

rcp4









tran tran

tran minim tran
minim






rcp6
rcp6
rcp24

rcp4
rcp6
rcp6
rcp12
rcp12















tran tran

tran minim tran
minim



















tran tran


tran minim tran
minim


















rcp6
rcp4 rcp6
rcp6
rcp4 rcp3

rcp4









tran tran

tran minim tran
minim






rcp6
rcp6
rcp6


rcp4
rcp12


rcp6
rcp6

rcp4
rcp6 rcp12












tran tran

imag slice
start
stop start

start
start
start
stop
stop
start stop

output slice






xprop winograd pad minim tran backward

backward
mirror
transpos copi
invert pad
pad pad

shape
shape



ceil
ceil



dtype int64

transform filter
rang
rang
tran minim tran

iter imag transform dimens slice tile imag
rang
start stop imag slice pad

rang
start stop imag slice pad

slice i start stop start stop

zero pad need

slice i slice i constant

appli imag transform
rang
rang
tran slice i minim tran

scale f quantiz
scale i quantiz

astyp float16 astyp float64
astyp float16 astyp float64

batch gemm pointwis multipl step
rang
rang
yw xw n
reshap reshap




astyp float64 scale f scale i

iter convovl result pointwis space appli invers transform
rang
plen output slice
rang
qlen output slice
rang
rang
toss point
plen qlen
tran minim tran

plen qlen
plen qlen


updat winograd pad minim tran inner

shape
shape



ceil
ceil



inner

fill

zero

rang
start stop imag slice pad
start stop imag slice

rang
start stop imag slice pad
start stop imag slice

slice i start stop start stop
slice e start stop start stop


slice i slice i constant


slice e slice e constant

rang
rang
tran slice i minim tran

rang
rang
tran slice e minim tran





astyp float16 astyp float64
astyp float16 astyp float64

rang
rang

inner




transform appli inner outer
inner
rang
rang
tran minim tran

outer transform
inner
rang
rang
tran minim tran



test code

printopt threshold 8192 linewidth formatt

minim
tran
one



fix winograd
stride fix winograd
pad

pad stride
pad stride



dim i
dim f
dim o

one
zero dim i
one dim f
zero dim o

ndindex
ident

ndindex
rang
rang

rang
rang
arang reshap

rang
rang
arang reshap


random uniform dim i
random normal dim f
random uniform dim f
random uniform dim o

dim o
dim o dtype float32

dim i
dim i dtype float32

dim f
dim f


xprop direct pad stride
xprop winograd pad minim minim tran tran

xprop direct pad stride backward
xprop winograd pad minim minim tran tran backward

updat direct pad stride
updat winograd pad minim minim tran tran

dif o
dif b
dif u

dif o
dif b
dif u






dif u
copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

python code wrap convolut kernel



log
numpi
pycuda driver
pycuda compil sourc modul
pycuda tool context depend memoiz
kernel spec
neon backend cuda templat common round common fp16 fp32 type
path
shelv
convolut kernel group shuffl kernel count ceil magic64 magic32 flatten convert closest divisor


logger log get logger name


xprop winograd kernel group

init dtype



relu bsum

xprop winograd init dtype

count

autotun join
dtype items
autotun file path join cach autotun

allow second worth warmup autotun
assum tflop
warmup 5e12 1000

relu bsum
init

scratch size tran size

init autotun filter


relu bsum

autotun

dtype float32
filter

filter
initi

autotun shelv open autotun file

autotun autotun
filter autotun autotun
initi

filter
initi

autotun close

filter autotun

filter tran filter

kernel name winograd 32x32 clss filter tran


shift n

shift n

shift n
blk n shift n

shift y shift x super y super x
0x203 0x300
0x203 0x201
0x104 0x202
0x104 0x103
0x000 0x104
0x000 0x000
blk n

blk n super y super x

grid k ceil
grid y ceil shift y
grid x ceil shift x
grid n ceil blk n
grid y
grid x
dtype items
yx np dtype items
dtype items
rs kp dtype items
c4 kp grid k dtype items

process group tile time
perhap tune smaller cach size
group k closest divisor grid k
yxgk grid y grid x group k
x2 gk group k

magic yxgk magic64 yxgk
magic x2 gk magic64 x2 gk
magic group k magic32 x2 gk group k

grid grid k grid y grid x grid n
block

kernel kernel name grid block
kernel extend flatten

shift y shift x shift n super y super x grid x grid k
yxgk x2 gk group k magic yxgk magic x2 gk magic group k
yx np rs kp c4 kp

flag relu bsum

filter

autotun

start stop event

onli need warmup
warmup
warmup
init autotun filter
bind alpha beta bsum flag
execut warmup unbind

result
extern

init autotun filter extern
bind alpha beta bsum flag
start record stream stream
execut warmup unbind
stop record stream stream
stop synchron
msec stop time sinc start warmup

result append msec extern

result sort
extern result
autotun
result


autotun shelv open autotun file
autotun autotun extern
autotun close

init autotun filter extern


fprop winograd xprop winograd

init dtype relu bsum

fprop winograd init fprop dtype
relu bsum


init autotun filter

filter fprop winograd init autotun filter



grid k ceil

filter

tran size grid k dtype items
tran share dtype items
tran arg grid k


tran size
tran arg

bind alpha beta bsum flag

dtype dtype dtype

initi
initi
autotun

bsum gpudata flag init bsum bsum flag

tran size
filter temp scratch buffer tran size
tran arg stream filter temp gpudata

filter temp gpudata

kernel stream bsum gpudata gpudata gpudata filter temp
alpha beta flag

execut unbind

kernel kernel spec kernel kernel
tran size
tran kernel fprop filter tran kernel dtype

rang

tran size
tran kernel prepar async call tran arg share size tran share

bsum zero
memset async bsum zero

kernel prepar async call kernel

unbind
bsum zero
kernel
tran size
tran arg


fprop winograd kernel

bprop winograd xprop winograd

init dtype relu bsum

swap invert pad
bprop winograd init bprop dtype
relu bsum

init autotun filter

filter bprop winograd init autotun filter



grid c ceil
grid k ceil
filter filter

transform plu shuffl crsk krsc
filter

c blk ceil grid c
k blk ceil

tran size grid c dtype items
tran arg k blk c blk
c blk

plain shuffl crsk krsc

tran size dtype items
tran arg grid k grid c
tran arg extend flatten


magic32 magic32

bind alpha beta bsum flag

dtype dtype dtype

initi
initi
autotun

bsum gpudata flag init bsum bsum flag

filter temp scratch buffer tran size
tran arg stream filter temp gpudata

kernel stream bsum gpudata gpudata gpudata filter temp
alpha beta flag

execut unbind

kernel kernel spec kernel kernel

filter
tran kernel bprop filter tran kernel dtype

tran kernel shuffl kernel dtype

rang

tran size
tran kernel prepar async call tran arg

bsum zero
memset async bsum zero

kernel prepar async call kernel

unbind
bsum zero
kernel
tran size
tran arg


bprop winograd kernel

updat winograd kernel group

superblock
blk n shl y shl x sup y sup x sup n
0x101 0x100 0x000 cccccyx
0x000 0x101 0x100 cccccxn
0x000 0x000 0x200 cccccnn

extern superblock
blk n shl y shl x sup y sup x sup n
0x106 0x105 0x000 yxccccc
0x000 0x106 0x105 xnccccc
0x000 0x000 0x205 nnccccc


init dtype

support multipl


updat winograd init dtype

count

autotun updat
dtype items
autotun file path join cach autotun


init

output size determ size dtype float32

scratch size output size tran size

allow second worth warmup autotun
assum tflop
warmup 5e12 1000


init autotun



loop n
blk n
super i updat winograd extern superblock blk n imag
super e updat winograd superblock blk n error
blk xi super i
blk y super e
blk x super e
ceil
ceil
ceil blk y
ceil blk x

autotun
stride y stride x extern autotun

autotun shelv open autotun file
autotun join autotun

autotun autotun
stride y stride x extern autotun autotun
stride y stride x extern autotun
initi


stride y
stride x

stride y
stride x
extern
initi

autotun close

loop xi stride x blk xi
loop xe stride x blk x
dtype items
dtype items
xn2p dtype items
dtype items

grid k ceil
grid c ceil
find even grid divisor closest prioriz larger valu equal distanc
size closest divisor grid k
size closest divisor grid c
size grid c size

size size
stride x
p qkc stride y
cp qkc size p qkc
grid pqkc stride y stride x grid k grid c
magic cp qkc magic64 cp qkc
magic p qkc magic64 p qkc
magic magic64
magic magic32
magic magic32 size

block ck grid k grid c

extern
extern imag transform




imag transform

intern imag transform



super i super e

tran size

output grid atom kernel determinist
stride y stride x
determ
determ size
determ shape
zero
determinist
determ
determ size stride y stride x
determ shape stride y stride x
zero

determ
determ size
determ shape
zero

kernel name winograd 32x32 clss determ

blk blk grid kc grid yx stride
grid pqkc grid pqkc grid k grid c stride y stride x

kernel kernel name grid pqkc
kernel extend flatten

super i super e loop xi loop xe loop n stride y stride x
xn2p
cp qkc p qkc size size
magic cp qkc magic p qkc magic magic magic

imag transform


shl n

shl n

shl n

ceil
ceil

maxim point superblock larg contigu access
shl n
shl y shl x mask y shr y mask x shr x mask n
1x16 xxxx
xxxn
xxnn
xnnn
nnnn
shl n
onli superblock small
shl n
shl y shl x mask y shr y mask x shr x mask n
yxxx
yxxn
shl n
small point superblock

shl y shl x mask y shr y mask x shr x mask n
yyxx
shl n

blk n shl n
blk y shl y
blk x shl x

grid c ceil

ceil grid c
ceil blk y
ceil blk x
ceil blk n
gys2
gxs2

sinc share memori shuffl block 16x16 process
block thi give perform 32x32 block
group c alway divis
group n
shift group c
shift group n

x2cn gxs2 group c group n
magic x2cn magic64 x2cn

tran size grid c dtype items
tran arg group c group n group n group c


gys2 x2cn
magic x2cn magic x2cn shift shift
shl y shl x mask y shr y mask x shr x shl n mask n


autotun

autotun join autotun
autotun autotun

start stop event

onli need warmup
warmup
warmup
warmup conserv
init autotun
bind
execut warmup unbind

want least mani block
block slot count
loop given size
loop n
bother mode
mode



small

result
stdout write autotun
progress
threshold
extern mode
stride y rang
stride x rang
progress
stdout write
stdout flush
progress

crsk copi determ mode
output stride y stride x

minim occup filter
block block ck stride y stride x
gemm size filter
depth stride y stride x loop n

filter output block block slot depth

filter set though loop
time look set
small threshold filter threshold filter

set stride y stride x extern
set

init autotun set
bind
start record stream stream
execut unbind
stop record stream stream
stop synchron
msec stop time sinc start
result append msec set


stride y stride x extern block round depth

result need disabl filter
result

stdout write

result sort
set result
result


autotun shelv open autotun file
autotun autotun set

copi layer small stride
determinist determ make speed differ
set set
autotun autotun
autotun join autotun
autotun autotun set

autotun close

init autotun set


bind alpha

dtype dtype

initi
initi
autotun

dtype float32 determ size

updat temp scratch buffer output size
convert arg updat temp determ shape

tran size
input temp scratch buffer offset tran size


updat temp gpudata
convert arg

tran size
input temp scratch buffer tran size

tran size
tran arg stream input temp gpudata

input temp gpudata

zero
zero arg updat temp size stream

kernel stream updat temp input temp gpudata alpha

execut unbind

kernel kernel spec kernel kernel

tran size
tran kernel updat imag tran kernel dtype

rang

tran size
tran kernel prepar async call tran arg

zero
memset async zero arg

kernel prepar async call kernel

convert arg
convert convert arg

unbind
zero arg convert arg
kernel



kernel


xprop winograd kernel group

init dtype



relu bsum

xprop winograd init dtype

items dtype items
kernel name winograd 32x32 clss


shl n

shl n

shl n

shl y shl x mask y shr y mask x shr x mask n sup y sup x
0x18 0x07 0x00 0x203 0x300 yyxxx
0x18 0x06 0x01 0x203 0x201 yyxxn
0x10 0x0c 0x03 0x104 0x202 yxxnn
0x10 0x08 0x07 0x104 0x103 yxnnn
0x00 0x18 0x07 0x000 0x203 xxnnn
0x00 0x10 0x0f 0x000 0x104 xnnnn
0x00 0x00 0x1f 0x000 0x000 nnnnn
shl n


ceil shl y
ceil shl x
ceil shl n
ceil
gys2
gxs2
closest divisor



magic gxs2 magic64 gxs2
magic magic64
magic magic64
magic magic32

imag size items 1152
imag arg


gys2 gxs2 magic gxs2 magic gxs2
shl y shl x mask y shr y mask x shr x shl n mask n
1152 1152 1152



kernel
kernel name

kernel extend flatten
magic magic magic
1152 1152 1152
items items items
items items
mask n shl x shl y sup x sup y

scratch size imag size filter size

flag relu bsum
mode

bind alpha beta bsum flag

dtype dtype dtype

bsum gpudata flag init bsum bsum flag

warn beta bsum mutual exclus kernel
beta
mode beta
bsum
bsum
mode bsum

mode

imag temp scratch buffer imag size
imag arg stream imag temp gpudata

filter temp scratch buffer offset filter size
filter arg stream filter temp gpudata

kernel stream bsum gpudata gpudata imag temp filter temp
alpha beta flag

execut unbind

imag kernel xprop imag tran kernel dtype
filter kernel filter func dtype
kernel kernel spec kernel kernel mode

rang

imag kernel prepar async call imag arg
filter kernel prepar async call filter arg

bsum zero
memset async bsum zero

kernel prepar async call kernel

unbind
bsum zero
kernel
imag arg
filter arg

fprop winograd xprop winograd

init dtype



relu bsum


ceil

filter func fprop filter tran kernel
filter size dtype items 1152
filter arg

1152

fprop winograd init
dtype relu bsum


fprop winograd kernel

bprop winograd xprop winograd

init dtype



relu bsum


gc32 ceil
gc16 ceil gc32
gk16 ceil

filter func bprop filter tran kernel
filter size dtype items 1152 gc32
filter arg
gk16 gc16
1152

bprop winograd init
dtype relu bsum


bprop winograd kernel

updat winograd kernel group

init dtype




updat winograd init dtype

count

autotun updat
dtype items
autotun file path join cach autotun


init

output size determ size dtype float32

scratch size imag size delta size output size

allow second worth warmup autotun
assum tflop
warmup 5e12 1000

init autotun


items dtype items



shl n

shl n

shl n

gc32 ceil
gk32 ceil
gc16 ceil gc32
gk16 ceil gk32
ceil
ceil

maxim point superblock larg contigu access
shl n
shl y shl x mask y shr y mask x shr x mask n
1x16 xxxx
xxxn
xxnn
xnnn
nnnn
shl n
get smaller point
shl n
shl y shl x mask y shr y mask x shr x mask n
yxxx
yxxn
shl n
smallest dimens make superblock squar

shl y shl x mask y shr y mask x shr x mask n
yyxx
shl n

ceil shl y
ceil shl x
gn16 ceil shl n
gys2
gxs2
group c
group k
group n gn16
shift group c
shift group k
shift group n

x2cn gxs2 group c group n
group k group n
magic x2cn magic64 x2cn
magic magic64

imag size gc32 1152 items
imag arg
group c group n gn16 group n gc16 group c

gys2 x2cn magic x2cn magic x2cn shift shift
shl y shl x mask y shr y mask x shr x shl n mask n
1152 1152 1152

delta size gk32 1152 items
delta arg
group k group n gn16 group n gk16 group k

magic magic shift shift
shl y shl x mask y shr y mask x shr x shl n mask n
1152 1152 1152

closest divisor gc32
closest divisor gk32
gc32
gk32


yxn2 yxn2 ceil

max yxn2 yxn2

autotun
stride yxn autotun

autotun shelv open autotun file
autotun join autotun

autotun autotun
stride yxn autotun autotun
stride yxn autotun
initi

stride yxn max yxn2
initi

autotun close

block ck gc32 gk32
magic s yxn magic64 stride yxn
magic magic64
magic magic32

output grid atom kernel determinist
stride yxn
determ
determ size
determ shape
zero
determinist
determ
determ size stride yxn
determ shape stride yxn
zero

determ
determ size
determ shape
zero

kernel name winograd 32x32 clss determ

stride yxn stride yxn stride yxn yxn2 stride yxn

kernel
kernel name stride yxn


kernel extend flatten
magic magic yxn2 stride yxn magic s yxn
stride yxn 1152 items 1152


autotun

autotun join autotun
autotun autotun

onli need warmup
warmup
warmup
warmup conserv
init autotun max yxn2
bind
execut warmup unbind

start stop event
block slot count
small yxn2
yxn2 yxn2
result
stdout write autotun
progress
threshold
stride yxn rang max yxn2
progress
stdout write
stdout flush
progress
minim occup filter
block block ck stride yxn
gemm count filter
depth yxn2 stride yxn

filter block block slot block block slot depth

filter set though loop
time look set
small threshold filter threshold filter

init autotun stride yxn
bind
start record stream stream
execut unbind
stop record stream stream
stop synchron
msec stop time sinc start
result append msec stride yxn

stride yxn msec block round depth


stride yxn block round depth

result need disabl filter
result

stdout write

result sort
stride yxn result
result


autotun shelv open autotun file
autotun autotun stride yxn

copi layer small stride
determinist determ make speed differ
stride yxn
autotun autotun
autotun join autotun
autotun autotun stride yxn

autotun close

init autotun stride yxn

bind alpha

dtype dtype

initi
initi
autotun

dtype float32 determ size

updat temp scratch buffer output size
imag temp scratch buffer offset imag size
delta temp scratch buffer offset delta size

convert arg updat temp determ shape

updat temp gpudata
imag temp scratch buffer imag size
delta temp scratch buffer offset delta size

convert arg

imag arg stream imag temp gpudata
delta arg stream delta temp gpudata

zero
zero arg updat temp size stream

kernel stream updat temp imag temp delta temp alpha

execut unbind

kernel kernel spec kernel kernel

imag kernel updat imag tran kernel dtype
delta kernel updat delta tran kernel dtype

rang

zero
memset async zero arg

imag kernel prepar async call imag arg
delta kernel prepar async call delta arg

kernel prepar async call kernel

convert arg
convert convert arg

unbind
zero arg convert arg
kernel
imag arg
delta arg



kernel


context depend memoiz
fprop filter tran kernel dtype

code
common

fprop filter tran type4

share share
type4 share share4

thread idx
blk k block idx
block idx
blk k

valid

r0s0
r0s1 r0s0
r0s2 r0s1

r2s0 r0s0
r2s1 r0s1
r2s2 r0s2

r1s0 r0s0
r1s1 r0s1
r1s2 r0s2

r0s0 valid r0s0
r0s1 valid r0s1
r0s2 valid r0s2

r2s0 valid r2s0
r2s1 valid r2s1
r2s2 valid r2s2

r1s0 valid r1s0
r1s1 valid r1s1
r1s2 valid r1s2

temp00 fmul r0s1
temp01 fadd r0s0 r0s2
fmaf temp01 temp00
fmaf temp01 temp00
share r0s0
share
share
share r0s2
temp02 fadd r2s0 r2s2
temp08 fmul r2s1
fmaf temp02 temp08
fmaf temp02 temp08
share r2s0
share
share
share r2s2
temp10 fadd temp01 temp02
temp05 fadd r0s1 r2s1
temp07 fadd r1s0 r1s2
temp09 fmul r1s1
temp11 fadd temp10 temp05
temp14 fadd temp10 temp05
temp13 fmaf temp07 temp09
temp15 fmaf temp07 temp09
fmaf temp11 temp13
fmaf temp11 temp13
fmaf temp14 temp15
fmaf temp14 temp15
share
share
share
share
temp03 fmul r1s0
temp06 fadd r0s0 r2s0
temp04 fmul r1s2
fmaf temp06 temp03
fmaf temp06 temp03
share
share
temp12 fadd r0s2 r2s2
fmaf temp12 temp04
fmaf temp12 temp04
share
share

type4 batch0 share4
type4 batch1 share4
type4 batch2 share4
type4 batch3 share4

offset grid dim blk k

offset batch0
offset batch1
offset batch2
offset batch3


common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type4 type dtype type4
type dtype
type dtype


sourc modul code
kernel fprop filter tran
kernel prepar ppiiii
kernel

context depend memoiz
bprop filter tran kernel dtype

code
common

bprop filter tran

c blk

pad avoid share bank conflict load
share share

thread idx
blk k block idx
blk c block idx




blk c
blk k

valid

miror
r2s2
r2s1 r2s2
r2s0 r2s1

r1s2 r2s2
r1s1 r2s1
r1s0 r2s0

r0s2 r2s2
r0s1 r2s1
r0s0 r2s0

r0s0 valid r0s0
r0s1 valid r0s1
r0s2 valid r0s2

r2s0 valid r2s0
r2s1 valid r2s1
r2s2 valid r2s2

r1s0 valid r1s0
r1s1 valid r1s1
r1s2 valid r1s2

temp00 fmul r0s1
temp01 fadd r0s0 r0s2
fmaf temp01 temp00
fmaf temp01 temp00
share r0s0
share
share
share r0s2
temp02 fadd r2s0 r2s2
temp08 fmul r2s1
fmaf temp02 temp08
fmaf temp02 temp08
share r2s0
share
share
share r2s2
temp10 fadd temp01 temp02
temp05 fadd r0s1 r2s1
temp07 fadd r1s0 r1s2
temp09 fmul r1s1
temp11 fadd temp10 temp05
temp14 fadd temp10 temp05
temp13 fmaf temp07 temp09
temp15 fmaf temp07 temp09
fmaf temp11 temp13
fmaf temp11 temp13
fmaf temp14 temp15
fmaf temp14 temp15
share
share
share
share
temp03 fmul r1s0
temp06 fadd r0s0 r2s0
temp04 fmul r1s2
fmaf temp06 temp03
fmaf temp06 temp03
share
share
temp12 fadd r0s2 r2s2
fmaf temp12 temp04
fmaf temp12 temp04
share
share

syncthread

make contigu



blk k



c blk blk c blk c

share
share
share
share
share
share
share
share
share
share
share
share
share
share
share
share



common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type dtype
type dtype

code

sourc modul code
kernel bprop filter tran
kernel prepar ppiiiiii
kernel


context depend memoiz
updat imag tran kernel dtype

code
stdio

common

devic forceinlin div64 valu magic shift

result
divisor power magic simpl right shift
magic
result valu shift
otherwis multipli magic right shift high bit

res64
lo32 hi32
wide res64
lo32 hi32 res64
hi32
result valu magic shift
result


updat imag tran


gys2
x2cn magic x2cn shift x2cn shift shift
shl y shl x mask y shr y mask x shr x shl n mask n
gygxn512 gxn512 n512

pad avoid share bank conflict load
share share

thread idx
y xcn block idx
block idx
block idx

unpack block idx
div64 y xcn magic x2cn shift x2cn
y xcn x2cn

shift shift shift

shift
shift

shift
shift

blk n shift
blk c shift

implement squar wave block remap
last row


gys2




scan backward row






super block coordin
shl y mask y shr y
shl x mask x shr x
blk n shl n mask n
blk c

valid





x0in valid
x1in valid
x2in valid
x3in valid





y0in
y1in
y2in
y3in

iy0x0
iy0x1 iy0x0
iy0x2 iy0x1
iy0x3 iy0x2

y0x0 y0in x0in iy0x0
y0x1 y0in x1in iy0x1
y0x2 y0in x2in iy0x2
y0x3 y0in x3in iy0x3

iy1x0 iy0x0
iy1x1 iy1x0
iy1x2 iy1x1
iy1x3 iy1x2

y1x0 y1in x0in iy1x0
y1x1 y1in x1in iy1x1
y1x2 y1in x2in iy1x2
y1x3 y1in x3in iy1x3

iy2x0 iy1x0
iy2x1 iy2x0
iy2x2 iy2x1
iy2x3 iy2x2

y2x0 y2in x0in iy2x0
y2x1 y2in x1in iy2x1
y2x2 y2in x2in iy2x2
y2x3 y2in x3in iy2x3

iy3x0 iy2x0
iy3x1 iy3x0
iy3x2 iy3x1
iy3x3 iy3x2

y3x0 y3in x0in iy3x0
y3x1 y3in x1in iy3x1
y3x2 y3in x2in iy3x2
y3x3 y3in x3in iy3x3

y0x0 y2x0
y0x1 y2x1
y0x2 y2x2
y0x3 y2x3
y1x0 y2x0
y1x1 y2x1
y1x2 y2x2
y1x3 y2x3
y2x0 y1x0
y2x1 y1x1
y2x2 y1x2
y2x3 y1x3
y3x0 y1x0
y3x1 y1x1
y3x2 y1x2
y3x3 y1x3

share
share
share
share
share
share
share
share
share
share
share
share
share
share
share
share

syncthread

make contigu



appli block grid coordin time
shl y mask y shr y
shl x mask x shr x
blk n shl n mask n



output
element transform valu
group blk c form transform

blk c gygxn512 gxn512 n512 blk c

pragma unrol

share



common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type dtype
type dtype

code

sourc modul code
kernel updat imag tran
kernel prepar ppiiiiiiiiiiiiiiiiiiiiiiiiiiii
kernel


context depend memoiz
xprop imag tran kernel dtype

code
common

devic forceinlin div64 valu magic shift

result
divisor power magic simpl right shift
magic
result valu shift
otherwis multipli magic right shift high bit

res64
lo32 hi32
wide res64
lo32 hi32 res64
hi32
result valu magic shift
result


xprop imag tran


gys2 gxs2 magic gxs2 shift gxs2
shl y shl x mask y shr y mask x shr x shl n mask n
1152 1152 1152

thread idx
blk n grid dim block idx
blk yx grid dim block idx
grid dim block idx

unpack block idx
div64 blk yx magic gxs2 shift gxs2
blk yx gxs2

implement squar wave block remap
last row


gys2




scan backward row



super block coordin
shl y mask y shr y
shl x mask x shr x
blk n shl n mask n

offset blk n 1152 1152 1152 1152

valid




pragma unrol


valid



offset

pragma unrol


offset

pragma unrol




offset





rcp4
rcp6
rcp12
rcp24
pragma unrol


fmaf rcp6
fmaf rcp6
rcp24
rcp12
fmaf
fmaf
fmaf rcp4




fmaf

pragma unrol


fmaf rcp6
fmaf rcp6
rcp24
rcp12
fmaf
fmaf
offset fmaf rcp4
offset
offset
offset
offset
offset fmaf



pragma unrol


fmaf
fmaf


fmaf
fmaf
fmaf


fmaf
fmaf
fmaf

pragma unrol


fmaf
fmaf


fmaf
fmaf
offset fmaf
offset
offset
offset fmaf
offset fmaf
offset fmaf



common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type4 type dtype type4
type dtype
type dtype

open tran
code
close


sourc modul code
kernel xprop imag tran
kernel prepar ppiiiiiiiiiiiiiiiiiiiiiii
kernel

context depend memoiz
fprop filter tran kernel dtype

code
common

fprop filter tran

c1152

thread idx
blk k grid dim block idx
grid dim block idx
blk k

offset blk k c1152 1152

valid

r0s0
r0s1 r0s0
r0s2 r0s1

r1s0 r0s0
r1s1 r0s1
r1s2 r0s2

r2s0 r0s0
r2s1 r0s1
r2s2 r0s2



valid r0s0
valid r0s1
valid r0s2

valid r1s0
valid r1s1
valid r1s2

valid r2s0
valid r2s1
valid r2s2



pragma unrol



fmaf



fmaf
fmaf


pragma unrol



fmaf
offset
offset
offset
offset fmaf
offset fmaf
offset


rcp4
rcp6
rcp12
rcp24

pragma unrol


rcp6
fmaf rcp6
fmaf rcp24
rcp4
fmaf rcp6
fmaf rcp6
fmaf rcp12
fmaf rcp12


pragma unrol


rcp6
fmaf rcp6
fmaf rcp24
offset rcp4
offset fmaf rcp6
offset fmaf rcp6
offset fmaf rcp12
offset fmaf rcp12
offset




common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type4 type dtype type4
type dtype
type dtype


sourc modul code
kernel fprop filter tran
kernel prepar ppiiiii
kernel

context depend memoiz
bprop filter tran kernel dtype

code
common

bprop filter tran

1152

pad avoid share bank conflict load
share share

thread idx
blk k block idx
blk c block idx




blk c
blk k

valid

miror
r2s2
r2s1 r2s2
r2s0 r2s1

r1s2 r2s2
r1s1 r2s1
r1s0 r2s0

r0s2 r2s2
r0s1 r2s1
r0s0 r2s0


valid r0s0
valid r0s1
valid r0s2

valid r1s0
valid r1s1
valid r1s2

valid r2s0
valid r2s1
valid r2s2



pragma unrol



fmaf



fmaf
fmaf


pragma unrol



fmaf
share
share
share
share fmaf
share fmaf
share


rcp4
rcp6
rcp12
rcp24

pragma unrol


rcp6
fmaf rcp6
fmaf rcp24
rcp4
fmaf rcp6
fmaf rcp6
fmaf rcp12
fmaf rcp12


pragma unrol


rcp6
fmaf rcp6
fmaf rcp24
share rcp4
share fmaf rcp6
share fmaf rcp6
share fmaf rcp12
share fmaf rcp12
share


syncthread

make contigu



blk k



blk c 1152 1152 blk c

pragma unrol

share



common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type dtype
type dtype

code

sourc modul code
kernel bprop filter tran
kernel prepar ppiiiiii
kernel


context depend memoiz
updat imag tran kernel dtype

code

common

devic forceinlin div64 valu magic shift

result
divisor power magic simpl right shift
magic
result valu shift
otherwis multipli magic right shift high bit

res64
lo32 hi32
wide res64
lo32 hi32 res64
hi32
result valu magic shift
result


updat imag tran


gys2
x2cn magic x2cn shift x2cn shift shift
shl y shl x mask y shr y mask x shr x shl n mask n
gygxn1152 gxn1152 n1152

pad avoid share bank conflict load
share share

thread idx
y xcn block idx
block idx
block idx

unpack block idx
div64 y xcn magic x2cn shift x2cn
y xcn x2cn

shift shift shift

shift
shift

shift
shift

blk n shift
blk c shift

implement squar wave block remap
last row


gys2




scan backward row






super block coordin
shl y mask y shr y
shl x mask x shr x
blk n shl n mask n
blk c

valid




pragma unrol


valid



offset

pragma unrol


offset

pragma unrol




offset





rcp4
rcp6
rcp12
rcp24

pragma unrol


fmaf
fmaf


fmaf
fmaf
fmaf


fmaf
fmaf
fmaf

fmaf rcp6
fmaf rcp6
rcp24
rcp12
fmaf
fmaf
fmaf rcp4




fmaf


pragma unrol


fmaf
fmaf


fmaf
fmaf
share fmaf
share
share
share fmaf
share fmaf
share fmaf

fmaf rcp6
fmaf rcp6
rcp24
rcp12
fmaf
fmaf
share fmaf rcp4
share
share
share
share
share fmaf


syncthread

make contigu



appli block grid coordin time
shl y mask y shr y
shl x mask x shr x
blk n shl n mask n



output
1152 element transform valu
group blk c form transform

blk c gygxn1152 gxn1152 n1152 1152 blk c

pragma unrol

share



common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type dtype
type dtype

open tran
code
close

sourc modul code
kernel updat imag tran
kernel prepar ppiiiiiiiiiiiiiiiiiiiiiiiiiiii
kernel


context depend memoiz
updat delta tran kernel dtype

code

common

devic forceinlin div64 valu magic shift

result
divisor power magic simpl right shift
magic
result valu shift
otherwis multipli magic right shift high bit

res64
lo32 hi32
wide res64
lo32 hi32 res64
hi32
result valu magic shift
result


updat delta tran


magic shift shift shift
shl y shl x mask y shr y mask x shr x shl n mask n
gygxn1152 gxn1152 n1152

pad avoid share bank conflict load
share share

thread idx
y xkn block idx
block idx
block idx

unpack block idx
div64 y xkn magic shift
y xkn

shift shift shift

shift
shift

shift
shift

blk n shift
blk k shift




super block coordin
shl y mask y shr y
shl x mask x shr x
blk n shl n mask n
blk k

valid




pragma unrol


valid





pragma unrol















rcp3
rcp4
rcp6

pragma unrol



fmaf

fmaf



fmaf
fmaf


rcp6
fmaf rcp4 rcp6
rcp6
fmaf rcp4 rcp3
rcp4







pragma unrol



fmaf

fmaf
share
share
share
share fmaf
share fmaf
share

rcp6
fmaf rcp4 rcp6
rcp6
fmaf rcp4 rcp3
share rcp4
share
share
share
share
share


syncthread

make contigu



appli block grid coordin time
shl y mask y shr y
shl x mask x shr x
blk n shl n mask n



output
1152 element transform valu
group blk k form transform

blk k gygxn1152 gxn1152 n1152 1152 blk k

pragma unrol

share



common common round nearest dtype
dtype
common common fp16 fp32

code code
common common
type dtype
type dtype
type dtype

code

sourc modul code
kernel updat delta tran
kernel prepar ppiiiiiiiiiiiiiiiiiiiiiiii
kernel
copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


path
pycuda driver
pycuda tool context depend memoiz
math ceil

path dirnam file
path join kernel
sass path join kernel sass
path join kernel
cubin path join kernel cubin
dump path join kernel dump

kernel

hconv bprop thread sass hconv bprop bprop1 share
hconv bprop c128 n128 thread sass hconv xprop x128 n128 bprop share arg prop
hconv bprop c128 thread sass hconv xprop x128 bprop share arg prop
hconv bprop n128 thread sass hconv xprop n128 bprop share arg prop
hconv bprop n128 thread sass hconv xprop n128 bprop share arg prop
hconv bprop thread sass hconv xprop bprop share arg prop
hconv fprop k128 n128 thread sass hconv xprop x128 n128 fprop share arg prop
hconv fprop k128 thread sass hconv xprop x128 fprop share arg prop
hconv fprop n128 thread sass hconv xprop n128 fprop share arg prop
hconv fprop n128 thread sass hconv xprop n128 fprop share arg prop
hconv fprop thread sass hconv xprop fprop share arg prop
hconv updat c128 k128 thread sass hconv updat c128 k128 updat share occup
hconv updat d c128 k128 thread sass hconv updat c128 k128 updat share occup arg determ
hconv updat c128 thread sass hconv updat c128 updat share occup
hconv updat d c128 thread sass hconv updat c128 updat share occup arg determ
hgemm 128x128 thread sass hgemm 128x128 gemm share
hgemm 128x128 thread sass hgemm 128x128 gemm share
hgemm 128x128 thread sass hgemm 128x128 gemm share
hgemm 128x128 thread sass hgemm 128x128 gemm share arg
hgemm 128x128 thread sass hgemm 128x128 gemm share arg
hgemm 128x128 thread sass hgemm 128x128 gemm share arg
hgemm 128x64 thread sass hgemm 128x64 gemm share
hgemm 128x64 thread sass hgemm 128x64 gemm share
hgemm 128x64 thread sass hgemm 128x64 gemm share arg
hgemm 128x64 thread sass hgemm 128x64 gemm share arg
hgemm 128x32 thread sass hgemm 128x32 gemm share
hgemm 128x32 thread sass hgemm 128x32 gemm share
hgemm 128x32 thread sass hgemm 128x32 gemm share arg
hgemm 128x32 thread sass hgemm 128x32 gemm share arg
hgemm 32x128 thread sass hgemm 32x128 gemm share
hgemm 32x128 thread sass hgemm 32x128 gemm share
hgemm 32x128 thread sass hgemm 32x128 gemm share arg
hgemm 32x128 thread sass hgemm 32x128 gemm share arg
sconv bprop thread sass sconv bprop bprop1 share
sconv bprop c128 n128 thread sass sconv xprop x128 n128 bprop share arg prop
sconv bprop c128 thread sass sconv xprop x128 bprop share arg prop
sconv bprop n128 thread sass sconv xprop n128 bprop share arg prop
sconv bprop n128 thread sass sconv xprop n128 bprop share arg prop
sconv bprop thread sass sconv xprop bprop share arg prop
sconv fprop k128 n128 thread sass sconv xprop x128 n128 fprop share arg prop
sconv fprop k128 thread sass sconv xprop x128 fprop share arg prop
sconv fprop n128 thread sass sconv xprop n128 fprop share arg prop
sconv fprop n128 thread sass sconv xprop n128 fprop share arg prop
sconv fprop thread sass sconv xprop fprop share arg prop
sconv updat c128 k128 thread sass sconv updat c128 k128 updat share occup
sconv updat d c128 k128 thread sass sconv updat c128 k128 updat share occup arg determ
sconv updat c128 thread sass sconv updat c128 updat share occup
sconv updat d c128 thread sass sconv updat c128 updat share occup arg determ
sgemm 128x128 thread sass sgemm 128x128 gemm share
sgemm 128x128 thread sass sgemm 128x128 gemm share
sgemm 128x128 thread sass sgemm 128x128 gemm share
sgemm 128x128 thread sass sgemm 128x128 gemm share arg
sgemm 128x128 thread sass sgemm 128x128 gemm share arg
sgemm 128x128 thread sass sgemm 128x128 gemm share arg
sgemm 128x64 thread sass sgemm 128x64 gemm share
sgemm 128x64 thread sass sgemm 128x64 gemm share
sgemm 128x64 thread sass sgemm 128x64 gemm share arg
sgemm 128x64 thread sass sgemm 128x64 gemm share arg
sgemm 128x32 thread sass sgemm 128x32 gemm share
sgemm 128x32 thread sass sgemm 128x32 gemm share
sgemm 128x32 thread sass sgemm 128x32 gemm share arg
sgemm 128x32 thread sass sgemm 128x32 gemm share arg
sgemm 32x128 thread sass sgemm 32x128 gemm share
sgemm 32x128 thread sass sgemm 32x128 gemm share
sgemm 32x128 thread sass sgemm 32x128 gemm share arg
sgemm 32x128 thread sass sgemm 32x128 gemm share arg

sconv winograd 32x32 thread sass xconv winograd 32x32 fpropw share arg prop
hconv winograd 32x32 thread sass xconv winograd 32x32 fpropw share arg prop
sconv winograd 32x32 thread sass xconv winograd 32x32 fpropw share arg prop
hconv winograd 32x32 thread sass xconv winograd 32x32 fpropw share arg prop

sconv winograd 32x32 thread sass xconv winograd 32x32 updatw share arg
hconv winograd 32x32 thread sass xconv winograd 32x32 updatw share arg
sconv winograd d 32x32 thread sass xconv winograd 32x32 updatw share arg determ
hconv winograd d 32x32 thread sass xconv winograd 32x32 updatw share arg determ

sconv winograd 32x32 thread sass xconv winograd 32x32 updatw share arg
hconv winograd 32x32 thread sass xconv winograd 32x32 updatw share arg
sconv winograd d 32x32 thread sass xconv winograd 32x32 updatw share arg determ
hconv winograd d 32x32 thread sass xconv winograd 32x32 updatw share arg determ

sconv winograd 32x32 thread sass xconv winograd 32x32 fpropw4 share arg
hconv winograd 32x32 thread sass xconv winograd 32x32 fpropw4 share arg
sconv winograd 32x32 bsum thread sass xconv winograd 32x32 fpropw4 share arg bsum
hconv winograd 32x32 bsum thread sass xconv winograd 32x32 fpropw4 share arg bsum
sconv winograd 32x32 beta thread sass xconv winograd 32x32 fpropw4 share arg beta
hconv winograd 32x32 beta thread sass xconv winograd 32x32 fpropw4 share arg beta

sconv winograd 32x32 thread sass xconv winograd 32x32 updatw4 share arg
hconv winograd 32x32 thread sass xconv winograd 32x32 updatw4 share arg
sconv winograd d 32x32 thread sass xconv winograd 32x32 updatw4 share arg determ
hconv winograd d 32x32 thread sass xconv winograd 32x32 updatw4 share arg determ




fprop
param
param
param
param
param alpha
param beta
param flag
param offset
param
param
param
param
param
param
param
param dhwn
param
param crst
param
param
param magic
param shift
param
param magic
param shift
param
param
param
param
param
param
param
param
param
param
param mpqn
param magic
param shift
param magic
param shift

bprop1
param
param
param
para alpha
param
param
param
param
param
param
param
param dhwn
param
param crst
param
param magic
param shift
param
param magic
param shift
param
param magic
param shift
param
param
param
param
param
param
param
param
param
param
param mpqn
param magic
param shift
param magic
param shift
param crst8
param mpqn8

updat
param
param
param
param alpha
param offset
param
param
param
param
param
param
param
param dhwn
param
param crst
param
param magic
param shift
param
param magic
param shift
param
param magic
param shift
param
param
param
param
param
param
param
param
param
param
param
param mpqn
param magic
param shift
param magic
param shift
param part
param part
param part
param crstk

pool
param
param
param
param alpha
param beta
param mode
param
param
param
param
param
param
param
param dhwn
param
param
param magic
param shift
param
param
param mpqn
param
param
param
param
param
param
param
param
param
param
param
param jrst
param magic
param shift
param magic
param shift
param magic
param shift
param overlap

pool2
param
param
param
param alpha
param beta
param mode
param
param
param
param
param
param
param
param dhwn
param magic
param shift
param
param
param
param
param
param
param
param
param magic
param shift
param magic
param shift
param magic
param shift
param magic
param shift
param
param
param
param
param
param
param jrst
param magic
param shift
param magic
param shift
param magic
param shift
param
param
param
param
param
param
param mpqn

gemm
param
param
param
param alpha
param beta
param flag
param
param
param
param
param
param
param ldaz
param ldbz
param ldcz
param batch loop

fpropw
param
param
param
param
param alpha
param beta
param flag
param
param
param
param
param
param
param
param
param
param
param
param
param shift y
param shift x
param shift n
param super y
param super x
param grid x
param grid k
param
param yxgk
param x2 gk
param group k
param magic yxgk
param shift yxgk
param magic x2 gk
param shift x2 gk
param magic group k
param shift group k
param 2 x np
param
param 4 yxn n3 x np
param 2 s kp
param
param 4 rsk n s kp
param batch kp
param
param

fpropw4
param
param
param
param
param alpha
param beta
param flag
param
param
param
param
param
param
param magic
param shift
param magic
param shift
param magic
param shift
param 1152
param 1152
param 1152
param
param
param
param
param
param
param qn3p
param pqn1 qn3p
param pqn15 qn3p
param mask n
param shift x
param shift y
param super x
param super y

updatw
param
param
param
param alpha
param
param
param
param
param
param
param
param
param
param
param
param
param
param shift yi
param shift xi
param super yi
param super xi
param super ni
param shift y
param shift x
param super y
param super x
param super n
param loop xi
param loop x
param loop n
param stride y
param stride x
param
param
param
param
param
param
param
param
param 2 x np
param
param cp qkc
param p qkc
param
param
param
param
param magic cp qkc
param shift cp qkc
param magic p qkc
param shift p qkc
param magic
param shift
param magic
param shift
param magic
param shift
param crsk

updatw4
param
param
param
param alpha
param
param
param
param
param
param magic
param shift
param magic
param shift
param yxn2
param s yxn
param magic s yxn
param shift s yxn
param stride yx np
param
param 1152
param
param crsk
param
param
param rsk15 sk2p



bprop fprop
param
param
param magic
param shift
param magic
param shift
param magic
param shift


space compil

share
share align share


kernel
version
target
address size

visibl entri


reqntid






file kernel name arch

kernel spec kernel kernel name
thread spec kernel spec thread
param spec kernel spec

kernel
param spec
ptype pname space split

ptype
ptype
ptype
ptype

ptype

kernel append param ptype pname

kernel join kernel

share kernel spec
share share format kernel spec share

share

kernel text kernel format arch kernel name kernel thread spec share
kernel path join kernel name

current text
path exist kernel
open kernel
current text read
close
write kernel text chang
kernel text current text
open kernel
write kernel text
close

kernel


context depend memoiz
kernel kernel name

ipdb ipdb trace

kernel spec kernel kernel name
kernel spec


ptype pname space split
ptype

ptype




file path join cubin kernel name cubin
func kernel name
func prepar
func thread kernel spec thread
load kernel name
func


partit tile

partit
tile tile
grid tile tile
grid
partit append tile grid
grid tile


partit


xprop conv kernel clss tile tile grid tile arg

kernel
tile grid offset partit tile

kernel name clss tile tile tile

block kernel kernel name thread

grid grid grid

grid grid grid

kernel append kernel name grid block offset arg

kernel


updat grid kernel name block count

thread kernel kernel name thread
occup kernel kernel name occup

warp schedul block
block thread count

grid
rang
rang

occup block block
group occup occup
slot ceil group

thi heurist keep balanc work accross
also maxim work block
heurist slot rang slot group

grid append heurist

grid sort

grid grid thread

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



automat differenti optre
support
elementwis oper
unari
binari

reduct nervanagpu
support
batch
zero operand oper
slice need modifi tensor view
todo
make like
intrins cach


neon backend backend op tree node tensor
numpi
functool wrap

scalar type float16 float32 uint8 int8
uint16 int16 uint32 int32


grad util


util calcul gradient


staticmethod
grad back grad node

left right gradient increment back propag

argument
grad node grad node grad node perform gradient
back propag

grad node

dissembl node
grad node left tree grad node left
grad node right tree grad node right
grad node tree
grad node grad tree
dict
grad node
element wise gradient increment
grad node tree
grad increment grad dict
unbroacat input dimens
left increment grad util unbroadcast grad increment
right increment grad util unbroadcast grad increment

left increment right increment

staticmethod
unbroadcast grad tree

revers broadcast shape grad tree shape

argument
grad tree op tree node tensor op tree node broadcast
op tree node tensor provid dimens broadcast
backend backend use

return
op tree node tensor broadcast result


grad tree
grad tree
scalar type

shape shape
shape grad tree shape

shape shape
grad tree
shape shape
broadcast
shape

grad tree
shape shape shape

grad tree axi
shape shape shape

grad tree axi
reduct
shape shape shape
shape shape shape
todo cleaner broadcast
grad tree

not implement

not implement

staticmethod
invalid grad tree

test result grad tree contain
abnorm larg small number onli debug purpos

argument
grad tree op tree node tensor tensor tree test
backend backend use

return
whether result contain abnorm
larg small number

grad tree grad tree shape
grad tree grad tree
grad tree grad tree reshap
grad tree
50000 50000





appli follow grad function
return gradient oper

argument
tensor op tree node left operand
tensor op tree node right operand
tensor op tree node
tensor op tree node gradient
dict dict dictionari specifi oper
backend backend tensor

return
tupl left increment right increment


deriv
staticmethod
zero grad unari dict


staticmethod
zero grad binari dict


staticmethod
grad dict


staticmethod
grad dict


staticmethod
grad dict


staticmethod
grad dict


staticmethod
grad dict


staticmethod
grad dict
squar

staticmethod
grad dict


staticmethod
grad dict


staticmethod
sqrt grad dict


staticmethod
grad dict


staticmethod
grad dict


staticmethod
exp2 grad dict


staticmethod
grad dict


staticmethod
log2 grad dict


staticmethod
grad dict


staticmethod
sig2 grad dict


staticmethod
tanh grad dict
squar

staticmethod
tanh2 grad dict
squar

staticmethod
grad dict


staticmethod
grad dict


staticmethod
maximum grad dict
greater equal greater equal

staticmethod
minimum grad dict
less equal less equal

staticmethod
grad dict
axi dict dict axi
unbroadcast

staticmethod
transpos grad dict



grad
zero gradient
grad util zero grad binari
grad util zero grad binari
grad util zero grad binari
grad util zero grad binari
grad util zero grad binari
grad util zero grad unari
finit grad util zero grad unari
argmax grad util zero grad unari
argmin grad util zero grad unari
binari oper
grad util grad
grad util grad
grad util grad
grad util grad
grad util grad
grad util grad
unari oper
grad util grad
grad util grad
sqrt grad util sqrt grad
grad util grad
grad util grad
exp2 grad util exp2 grad
grad util grad
log2 grad util log2 grad
grad util grad
sig2 grad util sig2 grad
tanh grad util tanh grad
tanh2 grad util tanh2 grad
grad util grad
grad util grad
maximum grad util maximum grad
minimum grad util minimum grad
reduct oper
grad util grad
transpos
transpos grad util transpos grad



memoiz autodiff func

memoiz avoid rebuild gradient tree

cach

wrap func
memoiz tree error

cach result directli othewis cach
result

tree error
cach
cach func tree error
creat grad tree cach
cach
memoiz


memoiz autodiff
autodiff


automat differenti given tree

argument
tree op tree node tree take gradient
backend comput backend use
error tensor op tree node option layer error usual
delta layer
automat
valu tensor
one output shape


slot tree dtype error tensor grad node
tensor grad tree grad node

init tree error
check
tree scalar type tree op tree node
isinst tree tensor tree support


attribut
tree tree

dtype dtype
error
error shape tree shape
error shape must consist tree shape
error shape tree shape
error error

error one tree shape

tensor grad node build grad tree
tensor grad tree quick access grad tree

build grad
grad node grad node tree
error
grad node grad tree error

grad node grad tree one tree shape
grad node build grad


cleanup

cleanup
grad node
grad node cleanup
grad node
dtype
error
tree


back prop grad tensor gradient

back propag gradient tensor gradient

argument
tensor list tensor comput gradient
gradient list tensor output buffer
gradient

avoid tensor reus grad buffer
grad buffer gradient
grad buffer origin tensor grad tree

skip tensor
tensor grad buffer tensor gradient
grad buffer error
error reus grad buffer
skip tensor tensor

grad buffer tensor grad tree
tensor origin grad buffer

skip tensor
error tensor grad tree
skip tensor origin error

grad tree tensor

gradient tree tensor tensor
use gradient zero

argument
tensor list tensor comput gradient

return
tree gradent input
tensor

grad tree
tensor tensor
grad tree append
tensor grad tree tensor origin tensor
grad tree

grad tensor tensor

gradient valu tensor tensor
tensor use gradient zero

argument
tensor list tensor comput gradient

return
tensor gradent input
tensor

grad tree grad tree tensor
grad val
grad tree grad tree
grad grad tree shape
grad grad tree
grad val append grad
grad val

grad asnumpyarray tensor

gradient valu numpi tensor
tensor use gradient zero

argument
tensor list tensor comput gradient

return
numpi ndarray gradient
input tensor

grad val grad tensor tensor
rang grad val
grad val grad val astyp dtype
grad val


grad node


node grad tree grad node contain optre grad tree
locat grad tree also pointer left
right child grad tree


slot tree grad tree left right

init tree

tree tree grad node
autodiff tree error dict

check tree
tree

attribut
tree tree forward tree
grad tree backward gradient tree
info autodiff
left
right

build grad node recurs
isinst tree tensor
save tensor grad node
tree origin tensor grad node
tensor grad node tree origin
tree op tree node
init recurs
tree
isinst tree tensor
tree origin tensor grad node
seen tensor
left tensor grad node tree origin

build recurs
left grad node tree
tree
isinst tree tensor
tree origin tensor grad node
seen tensor
right tensor grad node tree origin

build recurs
right grad node tree


cleanup

cleanup
tree
grad tree


left
left cleanup
left

right
right cleanup
right

build grad

actual back propag gradient

grad tree shall parent grad node
grad tree

tree op tree node
increment
left increment right increment grad util grad back

left increment
left grad tree
left grad tree left increment

left grad tree left grad tree
left increment

left recurs
left build grad

check right increment
right increment


right increment
right grad tree
right grad tree right increment

right grad tree right grad tree
right increment

right recurs
right build grad

isinst tree tensor
tensor grad tree tree origin grad tree

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin tensor backend


numpi
log
math ceil

logger log get logger name


op collect

collect oper string

zero operand rand onehot
unari finit sqrt
exp2 log2 sig2 tanh tanh2 transpos
safelog
binari assign
minimum maximum
reduct argmax argmin
zero operand unari binari
transpos


tensor

dimension structur gpu tensor tensor inherit
tensor depend backend addit keyword
keyword shall exact order tensor

argument
backend backend backend tensor
shape tupl option shape tensor
dtype numpi ndtype option underli element
name option name indentifi tensor use print
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need maintain
across call

also
gpu tensor tensor

note
unlik numpi implement never collaps dimens
minim dimens dim current
wrap scalar dimens

init
backend
shape
dtype float32
name
persist valu

backend backend
shape shape
dtype dtype
name name
persist valu persist valu
dim




return represent tensor

return
represent

rais
not implement error instanti directli

not implement error

repr

return unambigu represent tensor

return
represent

rais
not implement error instanti directli

not implement error



return size lead dimens

return
size lead dimens

rais
not implement error instanti directli

not implement error

setitem index valu

assign specifi valu subset element found slice
style index along dimens
each slice consist start stop step size triplet
step size specifi default start
specifi default stop specifi default
total element along dimens slice
valu allow select element along dimens

argument
index slice tupl indic dimens slice
valu numer tensor valu assign
extract element subset
shape
index
broadcast

rais
not implement error instanti directli

not implement error

getitem index

extract subset view item slice style index
along dimens each slice consist
start stop step size triplet step size specifi
default start specifi default
stop specifi default total element
along dimens slice valu allow
select element along dimens

argument
index slice tupl indic dimens slice

return
tensor view correspond subset item

rais
not implement error instanti directli

not implement error

assign valu

assign input valu tensor nervana cpu clip
type overflow happen

argument
valu tensor op tre node numer valu assign


not implement error



copi host tensor

argument
numpi ndarray host need contigu

return
tensor

not implement error



copi tensor host numpi

return
numpi ndarray host numpi

not implement error

asnumpyarray

convert tensor host memori numpi ndarray copi
made depend tensor normal resid

return
numpi ndarray view copi tensor

rais
not implement error instanti directli

not implement error

take indic axi

select subset element across axi

argument
indic tensor numpi ndarray indici element select
axi axi across select valu
tensor numpi ndarray option place result valu

specifi

return
tensor tensor select valu

rais
not implement error instanti directli

not implement error

fill valu

assign specifi valu element tensor

argument
valu numer valu assign element

return
tensor updat view

rais
not implement error instanti directli

not implement error

copi

construct deep copi tensor pass

argument
tensor copi

return
tensor valu

rais
not implement error instanti directli

not implement error

copi

copi content

argument
numpi ndarray host resid copi

rais
not implement error instanti directli

not implement error

reshap shape

adjust dimens specifi shape
element repres shape must

argument
shape length dimens

rais
not implement error instanti directli

not implement error

properti


return transpos view

return
tensor transpos view

rais
not implement error instanti directli

not implement error

transpos

return transpos view alia properti need
compat

argument
tensor numpi ndarray option place result valu

specifi

return
tensor transpos view

rais
not implement error instanti directli

not implement error

hist

comput histogram current tensor valu

argument
identifi current state tensor
use disambigu multipl histogram
tensor differ point time

return
tensor contain histogram

rais
not implement error instanti directli

not implement error

properti
origin

return origin tensor view view
origin


origin
origin
origin origin
origin



perform oper

argument
right hand side operand

return
op tree node result tree

op tree node build


op tree node build


op tree node build


op tree node build

truediv
op tree node build


op tree node build

radd
op tree node build

rsub
op tree node build

rmul
op tree node build

rdiv
op tree node build

rtruediv
op tree node build

rpow
op tree node build


op tree node build


op tree node build


op tree node build


op tree node build


op tree node build


op tree node build


op tree node build


op tree node build


backend

backend use manipul tensor thi
defin oper concret backend must support
nervana gpu nervana cpu inherit backend

argument
seed option random gener seed valu
dtype numpi ndtype option element
creat tensor
otherwis specifi default
float32
compat mode option flag match implement
librari current caff
support default
determinist option flag determinist kernel
applic thi
caus small increas memori
usag slow onli relev
backend

init seed dtype float32
compat mode determinist
dtype
dtype dtype

random state instead seed
seed seed
seed

batch size

dim

compat mode
compat mode caff
caff compat

valu error mode support current compat mode

compat mode

determinist
logger warn determinist deprec favor specifi random seed

determinist seed

output pad stride pool

comput along dimens size output dimens

argument
input dimens
filter dimens
pad pad side
stride stride
pool flag set pool layer size


check caff compat pool
size ceil pad stride
pad size stride pad
decrement size last pool complet pad
size

normal neon output size determin
size pad stride

pool pad
valu error pad incompat filter size pad

size

caff compat

flag make layer compat caff term conv pool
layer output size determin dropout layer implement

compat mode caff

check caff compat
compat mode caff

iobuf dim0 dtype name persist valu
share parallel

alloc input output buffer layer base batch size thi
use layer know batch size

argument
dim0 tupl buffer dimens layer without
axi specifi batch size
option present
return directli
buffer alreadi alloc
dtype option present specifi underli
employ element
name option name indentifi tensor use print
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need maintain
across call
share buffer option present attempt reus memori
share alloc buffer
parallel option indic parallel data
model employ buffer
ignor backend
default parallel
return
tensor



isinst dim0 tupl
dim0
bufshap dim0 dim0

bufshap prod dim0

bufshap dim0

share
share shape bufshap
share

share share bufshap

zero bufshap dtype dtype name name
persist valu persist valu

share iobuf size shape parallel

comput backend specif size need iobuf specifi
shape meant share layer

argument
shape tupl request iobuf shape
parallel parallel layer request iobuf

return
size requir iobuf

parallel data model getattr
prod shape

distribut tensor layer parallel

backend support distribut train distribut
gather error activ tensor depend
parallel use distribut layer comput current
support multi nervana cloud

argument
tensor tensor contain either activ error
layer parallel type parallel expect layer

return
tensor alter call



revert tensor tensor

revert tensor origin state distribut
distribut

argument
tensor tensor revert



seed

setup random gener store state
init state

argument
seed seed seed
seed randomli chosen

return
random random state numpi

not implement error

state state

random gener state specif state

return tupl sinc backend multipl state
host devic

return
tupl numpi ndarray defin current
state rn gs

not implement error

reset

reset random state state backend first
initi

not implement error

state state

random gener state specif state

argument
state use defin
state

not implement error

execut node

execut optre there must assign
optre execut call

argument
node op tree node tree execut



block identifi

signal start block repeat comput start
thi oper use help compil optim
instruct perform direct effect calcul
must book end correspond backend call
note multipl call appear adjac nest loop

argument
block block attr identifi comput work
base block attribut specifi
identifi uniqu identifi particular iter
block will typic someth like
epoch mini batch forth

also
func neon backend backend backend



block identifi

signal correspond block repeat comput
thi oper use help
compil optim perform direct effect
calcul must preced correspond backend
call

argument
block block attr identifi comput work
base block attribut specifi
identifi uniqu identifi particular iter
block will typic someth like
epoch mini batch forth

also
func neon backend backend backend



shape dtype name persist valu
parallel distribut

instanti backend tensor without
initi element valu thi slightli faster
func neon backend backend
func neon backend backend one
func neon backend backend zero valu
random

argument
shape length dimens tensor
dtype option present specifi underli
employ element
name option name indentifi tensor use print
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call
parallel option multi backend
replic copi tensor across
devic default
effect singl backend
distribut option multi backend
tensor fragment
partit across devic default
effect
singl backend

return
tensor

rais
not implement error instanti directli

also
func neon backend backend
func neon backend backend zero
func neon backend backend one

not implement error

dtype name persist valu
parallel distribut

instanti backend tensor popul
element base valu

argument
like input construct
built python scalar list
numpi ndarray
dtype option present specifi underli
employ element
name option name indentifi tensor use print
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call
parallel option multi backend
replic copi tensor across
devic default
effect singl backend
distribut option multi backend
tensor fragment
partit across devic default
effect
singl backend

return
tensor

rais
not implement error instanti directli

also
func neon backend backend
func neon backend backend zero
func neon backend backend one

not implement error

zero shape dtype name persist valu
parallel distribut

instanti backend tensor popul
each element valu

argument
shape length dimens tensor
dtype option present specifi underli
employ element
name option name indentifi tensor use print
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call
parallel option multi backend
replic copi tensor across
devic default
effect singl backend
distribut option multi backend
tensor fragment
partit across devic default
effect
singl backend

return
tensor

rais
not implement error instanti directli

also
func neon backend backend
func neon backend backend one
func neon backend backend

not implement error

one shape dtype name persist valu
parallel distribut

instanti backend tensor popul
each element valu

argument
shape length dimens tensor
dtype option present specifi underli
employ element
name option name indentifi tensor use print
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call
parallel option multi backend
replic copi tensor across
devic default
effect singl backend
distribut option multi backend
tensor fragment
partit across devic default
effect
singl backend

return
tensor

rais
not implement error instanti directli

also
func neon backend backend backend
func neon backend backend backend zero
func neon backend backend backend

not implement error

like name persist valu

instanti backend tensor
shape taken

argument
tensor tensor inherit dimens
name option name indentifi tensor use print
dtype option present specifi underli
employ element
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call

return
tensor

rais
not implement error instanti directli

also
func neon backend backend
func neon backend backend one
func neon backend backend

not implement error

zero like name persist valu

instanti backend tensor
shape taken popul element valu

argument
tensor tensor inherit dimens
name option name indentifi tensor use print
dtype option present specifi underli
employ element
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call
return
tensor

rais
not implement error instanti directli

also
func neon backend backend
func neon backend backend one
func neon backend backend

not implement error



product tensor

argument
tensor left hand side operand
tensor right hand side operand
tensor option result store
tree return
note differ
left right

return
op tree node result tree oper

op tree node build

compound alpha beta relu

perform follow oper product
alpha beta
alpha beta
alpha beta

relu appli output prior beta addit

oper circuit alpha left right
beta valu

argument
tensor left hand side operand
tensor right hand side operand
tensor output operand
alpha option scale term
beta option scale term
relu option appli re lu linear
output default

not implement error

batch alpha beta relu

perform follow oper
fprop call batch
bprop call batch
updat call batch

argument
tensor left hand input operand
tensor right hand input operand
tensor output operand
alpha option scale term
beta option scale term
relu option appli re lu linear
output default

not implement error

make binari mask keepthresh

creat binari mask dropout layer

argument
tensor output tensor
keepthresh option fraction one default

not implement error



perform element wise addit operand store result
valu tensor each operand must ident
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

subtract

perform element wise subtract operand store result
valu tensor each operand must ident
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

multipli

perform element wise multipl operand store
result valu tensor each operand must
ident shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

divid

perform element wise divis operand store
result valu tensor each operand must
ident shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

divid

here divid
instead python tradit floor divis return
divis

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

power

perform element wise valu specifi power
store result tensor both tensor ident
shape

argument
tensor input transform
tensor numer exponenti valu appli
element exampl squar
sqaur root
tensor option result store
tree return

return
op tree node result tree

op tree node build

reciproc

perform element wise reciproc tensor store result
tensor both tensor ident shape

argument
tensor input transform
power tensor numer exponenti valu appli
element exampl squar
sqaur root
tensor option result store
tree return

return
op tree node result tree

op tree node build

neg

perform element wise negat tensor store result
tensor both tensor ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build



perform element wise indic sign tensor store
result tensor both tensor ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build

absolut

perform element wise absolut valu tensor store result
tensor both tensor ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build

fab

perform element wise absolut valu tensor store result
tensor both tensor ident shape implement
absolut

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build

sqrt

perform element wise squar root tensor store result
tensor both tensor ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build sqrt

squar

perform element wise squar tensor store result tensor
both tensor ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build



perform element wise exponenti transform tensor store
result tensor both tensor ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build

exp2

perform element wise base exponenti transform tensor
store result tensor both tensor ident
shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build exp2

safelog

perform element wise natur logarithm transform tensor
store result tensor both tensor ident
shape thi built safeti underflow

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build safelog



perform element wise natur logarithm transform tensor
store result tensor both tensor ident
shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build

log2

perform element wise base logarithm transform tensor
store result tensor both tensor ident
shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build log2



perform element wise sigmoid transform tensor
store result tensor both tensor ident
shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build

sig2

perform element wise base sigmoid logarithm transform
tensor store result tensor both tensor
ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build sig2

tanh

perform element wise hyperbol tangent transform tensor
store result tensor both tensor ident
shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build tanh

tanh2

perform element wise base hyperbol tangent transform tensor
store result tensor both tensor
ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build tanh2

finit

perform element wise test finit infin
number tensor store result tensor both tensor
ident shape

argument
tensor input transform
tensor option result store
tree return

return
op tree node result tree

op tree node build finit

equal

perform element wise equal test element left
right store result each operand assum
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

equal

perform element wise equal test element left
right store result each operand assum
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

less

perform element wise less test element left
right store result each operand assum
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

less equal

perform element wise less equal test element
left right store result each operand assum
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

greater

perform element wise greater test element left
right store result each operand assum
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
theshap tree return

return
op tree node result tree

op tree node build

greater equal

perform element wise greater equal test element
left right store result each operand assum
shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build

maximum

perform element wise maximum valu assign base correspond
element left right store result each operand
assum shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build maximum

minimum

perform element wise minimum valu assign base correspond
element left right store result each operand
assum shape broadcast

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

op tree node build minimum

clip

perform element wise clip tensor store result
clip valu

argument
tensor numer left hand side operand
tensor numer right hand side operand
tensor option result store
tree return

return
op tree node result tree

minimum maximum

axi keepdim

calcul summat element along specifi axi

argument
tensor tensor perform
axi option dimens along comput

dimens
tensor option result store
tree return
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

axi
op tree node build op tree node build axi
axi
op tree node build axi axi

axi keepdim

calcul maxim element valu along specifi axe

argument
tensor tensor perform oper
axi option dimens along comput
take
dimens
tensor option result store
tree return
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

axi
op tree node build op tree node build axi
axi
op tree node build axi axi

axi keepdim

calcul minim element valu along specifi axe

argument
tensor tensor perform oper
axi option dimens along comput
take
dimens
tensor option result store
tree return
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

axi
op tree node build op tree node build axi
axi
op tree node build axi axi

argmax axi keepdim

calcul indic maxim element valu along specifi
axi multipl element contain maximum indic
first return

argument
tensor tensor perform oper
axi option dimens along comput
take argmax
dimens default
tensor option result store
tree return
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

op tree node build argmax axi axi

argmin axi keepdim

calcul indic minim element valu along specifi
axi multipl element contain minimum indic
first return

argument
tensor tensor perform oper
axi option dimens along comput
take argmin
dimens default
tensor option result store
tree return
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

op tree node build argmin axi axi

mean axi partial keepdim

calcul arithmet mean element along specifi
axe

argument
tensor tensor perform oper
axi option dimens along comput
take mean
dimens default
partial option current use
tensor option result store
tree return
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

shape shape
axi
multipli shape shape
multipli axi axi shape axi

axi partial keepdim

calcul varianc element along specifi
axe

argument
tensor tensor perform oper
axi option dimens along comput
take
dimens default
partial option current use
tensor option result store
tree return
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

axi
mean squar mean
mean squar mean axi axi axi axi

axi partial keepdim

calcul standard deviat element along specifi
axe

argument
tensor tensor perform oper
axi option dimens along comput
take
dimens
tensor option result store
tree return
partial option current use
keepdim option keep axe comput
output size instead
collaps default

return
op tree node result tree

sqrt axi axi partial partial

take indic axi

extract element base indic along given axi

argument
tensor tensor perform oper
indic tensor numpi ndarray indici element select
axi option dimens along comput
extract
dimens flatten first
tensor option result store
tree return

take indic axi

onehot indic axi

gener optre convert indic onehot represent

argument
indic tensor element must numpi integ
onehot work
axi axi along featur length dimens
tensor option result store
tree return

return
op tree node result tree

axi
valu error axi onehot
op tree node build onehot indic axi axi

updat bia

comput updat bia gradient fulli connect network layer

argument
tensor backpropag error
tensor where store updat gradient valu

axi

bia input bia

bia fulli connect network layer

argument
input tensor input updat
bia tensor amount increment

input bia input

conv layer dtype





relu bsum

creat conv layer paramet
thi pass argument convolut oper

argument
dtype option present specifi underli
employ element

number imag mini batch
number input featur map
number output featur map

option depth input imag default
option height input imag default
option width input imag default

option depth filter kernel default
option height filter kernel default
option width filter kernel default

option amount zero pad around depth edg
default
option amount zero pad around height edg
default
option amount zero pad around width edg
default

option factor step filter depth
direct default
option factor step filter depth
direct default
option factor step filter depth
direct default

relu option appli relu transform output
fprop bprop default

bsum option calcul along batchnorm axi
fprop bprop output fp32 tensor
size default

not implement error

fprop conv layer alpha relu

forward propag input convolut network layer
produc output

argument
layer conv layer paramet
tensor input
tensor weight filter
tensor output
alpha option linear scale default
relu option appli re lu output default
option repeat oper specifi
time default

not implement error

bprop conv layer grad alpha

backward propag error convolut network layer

argument
layer conv layer paramet
tensor weight filter
tensor error
grad tensor gradient input output delta
alpha option linear scale default
option repeat oper specifi
time default

not implement error

updat conv layer grad alpha

comput updat gradient convolut network layer

argument
layer conv layer paramet
tensor input
tensor error
grad tensor filter gradient weight updat
alpha option linear scale default
option repeat oper specifi
time default

not implement error

deconv layer dtype






creat deconvolut paramet
thi pass argument deconvolut kernel

argument
dtype option present specifi underli
employ element

number imag mini batch
number input featur map
number output featur map

height output
width output

option height filter kernel default
option width filter kernel default

option amount zero pad around depth edg
default
option amount zero pad around height edg
default
option amount zero pad around width edg
default

option factor step filter depth
direct default
option factor step filter depth
direct default
option factor step filter depth
direct default

leav spatial dimens allow featur pool layer

not implement error

pool layer dtype






creat pool layer paramet
thi pass argument pool kernel

argument
pool current bprop support

number imag mini batch

number input featur map
option depth input imag default
option height input imag default
option width input imag default

option size featur pool window
maxout piec default
option depth pool window default
option height pool window default
option width pool window default

option amount zero pad around pool
window edg default
option amount zero pad around depth edg
default
option amount zero pad around height edg
default
option amount zero pad around width edg
default

option factor step filter
pool window direct default
option factor step filter depth
direct default
option factor step filter depth
direct default
option factor step filter depth
direct default

leav spatial dimens allow featur pool layer

not implement error

fprop pool layer

forward propag pool layer

argument
layer pool layer pool layer differ backend
differ pool layer
tensor input tensor
tensor output tensor

not implement error

bprop pool layer grad

backward propag pool layer

argument
layer pool layer pool layer differ backend
differ pool layer
tensor input tensor
tensor error tensor
grad tensor gradient tensor delta

not implement error

compound bprop input error error alpha beta

backward propag lookup tabl layer

argument
integ number input word
input tensor input tensor
error tensor error tensor
error tensor transpos error tensor
tensor gradient tensor delta
integ
alpha
beta

not implement error


construct tree use lazi evalu
op tree node tupl

op tree node tupl length first element dict
specifi oper second third element specifi
operand from tree tree perspect think
element node second third element left right
child first element

arg
tupl arg




isinst tensor
name name
name

tensor



isinst tensor
name name
name

tensor





repr




return identifi optre depend
tensor sinc overload need manag
hash op tree node manual

return
tupl optre

stack travers
rang stack
stack dict
axi stack
stack stack stack axi

stack stack

tupl stack

intrins map

return intrins tensor index index tensor
purpos identifi optre depend
tensor dimens relaion among tensor

intrins
shape

tensor index index tensor tensor
map indic index tensor depend first
occur tensor post order travers optre

return
intrins tensor index index tensor


stack travers
tensor index
tensor index
index tensor
rang stack
stack dict
axi stack
stack stack stack axi

stack stack
isinst stack tensor
interg replac tensor
stack tensor index
stack tensor index stack stack shape

tensor dict
tensor index stack tensor index
index tensor tensor index stack
stack tensor index stack shape
tensor index

tupl stack tensor index index tensor

staticmethod
build kwarg

build op tree node

argument
op tree node tensor numer left hand side operand
op tree node tensor numer right hand side operand
tensor option result store
tree execut
kwarg option argument axi reducion

check

isinst tensor op tree node
not implement
shape
shape
isinst op tree node tensor
shape shape
isinst
shape

shape
isinst op tree node tensor
shape shape
isinst
shape

shape

todo shape smarter
shape
shape shape
shape
shape shape

op collect
rang
shape shape shape
op collect reduct
axi kwarg
shape shape
shape kwarg axi


assign
shape shape

shape shape shape
shape shape
shape shape shape
transpos

shape tupl revers shape

type error valid oper
shape tupl shape

build dict
dict shape shape
dict updat kwarg

node op tree node dict

execut assign
assign
node execut

pass valu count assign

op tree node assign node execut

delay execut assign
node

execut

execut optre when call execut must
assign oper tree correspond
backend execut call


assign

backend backend

isinst backend backend
backend execut

not implement error

travers stack

post order walk tree produc postfix stack

argument
stack user shall give like
use recurs construct post order stack

left
isinst op tree node
travers stack

stack append

right
isinst op tree node
travers stack

stack append

stack append

stack

properti

op tree node build transpos

transpos

return transpos view


op tree node build assign


staticmethod
optre optre

convert optre list recurs

isinst optre op tree node
op tree node optre optre

optre

staticmethod
optre

convert optre recurs

isinst
op tree node op tree node optre



properti
shape

shape op tree node


isinst op tree node
shape

isinst tensor
shape

scalar


staticmethod
pretti node
oper





isinst node tensor
node name
node name

tensor node
isinst node op tree node
node
op tree node pretti node
node oper
oper node

node
op tree node pretti node

node op tree node pretti node


node todo





pretti optre

argument
node op tree node node tree

return
represent tree

op tree node pretti

asnumpyarray

return evalu valu optre host numpi ndarray
alloc memori usual use debug

return
numpi ndarray evalu valu

astensor

astensor

return evalu valu optre tensor
alloc memori usual use debug

return
tensor evalu valu

stack travers


stack
isinst tensor
backend


valu error tensor tree

shape




build


build


build


build

truediv
build


build

radd
build

rsub
build

rmul
build

rdiv
build

rtruediv
build

rpow
build


build


build


build


build


build


build


build


build


block

simpl identifi differ element comput requir
train infer neural network

attribut
epoch start particular train epoch
minibatch start process particular mini batch partit
fprop start forward propag call particular minibatch
bprop start backward propag call particular minibatch
updat start paramet updat call particular minibatch

epoch minibatch fprop bprop updat rang

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


defin backend


atexit
log


numpi
math ceil

neon nervana object
neon backend autodiff autodiff
neon backend util check devic count


backend backend seed datatyp float32
batch size stochast round devic
devic devic count compat mode
determinist updat determinist
cach path join path expandus nervana cach

construct backend appropri base
given with paramet singl core float32
backend return

argument
backend option
seed numer option numer valu use seed
random gener instanti backend
default explicitli seed
differ
datatyp dtype default tensor backend support float64 float32
float16 backend support float32 float16
batch size size batch
stochast round option integ implent
stochast round round
nearest perform stochast
round width
integ round bit
onli affect backend
devic numer option numer valu use select
devic process
devic option multi backend
control maximum gp us

compat mode option caff conv pool
layer output size match caff
dropout layer implement
determinist option oper done determinist
cach option locat backend cach tune paramet

return
backend newli construct backend specif

note
attempt construct without cuda capabl card without nervanagpu
instal caus program display error messag

logger log get logger name

nervana object
backend alreadi gener clean first
cleanup backend

python forc cleanup backend
nervana object instead
atexit cleanup backend

determinist updat determinist
logger warn determinist updat determinist arg deprec favor
specifi random seed
determinist

backend backend
neon backend nervanacpu nervana cpu
nervana cpu seed seed dtype datatyp compat mode compat mode
backend backend mgpu
gpuflag
check nvcc
neon backend util check
gpuflag check comput capabl devic
gpuflag
runtim error devic devic cuda comput
capabl greater
backend
neon backend nervanagpu nervana gpu
init
nervana gpu seed seed dtype datatyp
stochast round stochast round
devic devic
compat mode compat mode
determinist determinist
cach cach


mgpu nervanamgpu nervana mgpu
init multipl
nervana mgpu seed seed
dtype datatyp
stochast round stochast round
devic devic
compat mode compat mode
determinist determinist
cach cach
import error
logger error multi support premium featur
avail exclus nervana cloud
pleas contact info nervanasi detail

backend argon
argon neon backend backend ar backend
ar backend seed seed dtype datatyp

valu error backend must mgpu

logger info backend seed format backend seed

nervana object
batch size



cleanup backend
nervana object

nervana object
neon backend nervanacpu nervana cpu
nervana cpu
neon backend nervanagpu nervana gpu

nervana gpu

detach

mgpu nervanamgpu nervana mgpu
nervana mgpu
ctx

detach



nervana object

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


base backend tensor structur implement
wrap numpi ndarray relat oper


numpi
log
time
neon backend backend tensor backend op tree node op collect
neon backend layer conv layer deconv layer pool layer

none slice slice

logger log get logger name

todo enabl flag find numer problem
seterr


cpu tensor tensor


dimension structur resid host memori
meant manipul wrap numpi ndarray tensor

argument
dtype numpi ndtype option underli element
option option instanti

persist valu option
valu assign tensor
persist across multipl
call set provid
perform increas valu
need maintain across
call

also
nervana cpu

tensor

init
backend
shape
dtype float32

name
persist valu


cpu tensor init backend shape dtype name
persist valu

support dtype
dtype float16 float32 float64 uint8 int8
uint16 int16 uint32 int32

dtype dtype dtype

ndarray
tensor dtype
dtype dtype
tensor astyp dtype

tensor
tensor ndim dim
tensor tensor reshap tensor shape

shape shape dim
shape shape

shape tensor shape


size
shape
size
type error
isinst shape integ
size shape
shape shape

size size




return represent tensor

return
represent

tensor
tensor

tensor
cpu tensor name shape dtype stride
contigu name shape
dtype tensor stride
tensor flag contigu

repr

return unambigu represent tensor

return
represent





return size lead dimens

shape
shape



setitem valu

assign specifi valu subset element found slice
style index along dimens
each slice consist start stop step size triplet
step size specifi default start
specifi default stop specifi default
total element along dimens slice
valu allow select element along dimens

argument
slice tupl indic dimens slice
valu numer cpu tensor valu assign
extract element subset
shape
index
broadcast


getitem assign valu


getitem

extract subset view item slice style index
along dimens each slice consist
start stop step size triplet step size specifi
default start specifi default
stop specifi default total element
along dimens slice valu allow
select element along dimens consist
tensor tensor remov axi size need
maintain

argument
slice tupl indic dimens slice

return
cpu tensor view correspond subset item


speed common
isinst tupl
none slice



view
exact behavior
shape
numpi
tensor numpi

enumer

shape
slice
tupl

shape tensor shape
enumer shape
shape
shape remov

view tensor

backend backend
tensor reshap shape
dtype tensor dtype


assign valu

assign input valu tensor nervana cpu clip
type overflow happen

argument
valu gpu tensor op tree node numer valu assign


isinst valu cpu tensor op tree node
op tree node build assign valu
isinst valu ndarray
valu

type error invalid assign valu



valu

wrap valu nervana cpu tensor

argument
valu array singl input check convert
dtype shape singl valu broadcast
memori

return


isinst valu ndarray
valu dtype dtype
valu valu astyp dtype
valu size size
valu ndim dim
valu valu reshap shape

tensor valu






tensor copi

asnumpyarray

deprec
schedul remov
instead

tensor

take indic axi

select subset element across axi

argument
indic tensor numpi ndarray indici element select
axi axi across select valu

return
tensor tensor select valu


indic
indic indic tensor
indic much code assum dim
collaps henc squeez call
indic ndarray
indic indic squeez
shape shape
shape axi indic size

backend backend
tensor take indic axi reshap shape
dtype tensor dtype


fill valu

assign specifi valu element cpu tensor

argument
valu numer valu assign element

return
cpu tensor updat view

tensor fill valu


copi

construct deep copi tensor pass

argument
tensor copi

return
tensor valu input tensor

assign

copi
copi
assign

reshap shape

reshap view

isinst shape tupl
shape tupl shape

shape shape



backend backend
tensor reshap shape
dtype tensor dtype


properti


return transpos view

tensor normal transpos
tensor keep swap dimens


shape
tensor transpos

support batch
perserv outer dimens revers inner dim
shape concaten shape shape
tensor swapax


backend backend

dtype tensor dtype


transpos

return transpos view alia properti


op tree node build assign


share shape dtype name

view size size
allow easi share temporari memori
thi mostli provid compat dtype ignor

size prod shape
size size
valu error total size must size parent

tensor ravel size reshap shape


backend backend

dtype tensor dtype


hist

comput histogram current tensor valu

argument
identifi current state tensor
use disambigu multipl histogram
tensor differ point time

return
tensor contain histogram


nbin backend hist bin
offset backend hist offset
bin arang nbin offset
bin
rint
log2 tensor astyp float32
hist edg histogram densiti bin bin
hist backend hist tensor assign hist
hist

repeat axi

backend backend
tensor repeat axi


custom numpi

staticmethod
argmax axi keepdim

call numpi argmax keepdim

shape shape
shape axi
shape tupl shape
argmax axi axi reshap shape

staticmethod
argmin axi keepdim

call numpi argmin keepdim

shape shape
shape axi
shape tupl shape
argmin axi axi reshap shape


assign right left left right
left right

numpi call dict
assign
assign assign right left
zero operand
unari
left left
left left
left sign left
sqrt left sqrt left
left squar left
left left
left left
safelog left maximum left
exp2 left exp2 left
log2 left log2 left
left left
sig2 left exp2 left
tanh left tanh left
tanh2 left exp2 left exp2 left
transpos left transpos left
binari
left right left right
left right left right
left right left right
left right left right
left right left right
left right left right
left right left right
left right left right
left right left right
left right left right
left right power left right
minimum left right minimum left right
maximum left right maximum left right
left right left right
reduct
dict left left axi dict axi keepdim
dict left left axi dict axi keepdim
dict left left axi dict axi keepdim
argmax dict left custom numpi argmax left axi dict axi keepdim
argmin dict left custom numpi argmin left axi dict axi keepdim



nervana cpu backend


set numpi base backend matrix
element type array construct

attribut
dtype dtype element
tensor underli tensor backend tensor

also
cpu tensor


init
seed
dtype float32
hist bin
hist offset
compat mode

dtype float16 float32 float64
logger error default nervanagpu
backend must float16
valu error

nervana cpu init seed dtype compat mode compat mode

optim bla present warn

config bla info librari lower
openbla atla acceler
logger warn acceler bla librari found
perform suffer consid instal
openbla atla vec lib
attribut error key error
logger warn problem infer bla info perform
suboptim

devic
devic
tensor cpu tensor

logger info initi nervana cpu

hist bin hist bin
hist offset hist offset
hist 4096
hist hist hist bin dtype int32
hist
hist dict

seed
random random state seed
init state state


state state
state state

state
state

reset

reset random state state backend first
initi

state init state

fill normal mean stdv

fill normal distribut random number

argument
tensor tensor fill random valu
mean mean valu default
stdv standard deviat valu default

random standard normal shape stdv mean

execut optre

argument
optre op tree node op tree node repres
oper

deal onehot special
optre isinst optre op tree node
optre onehot
optre assign
isinst optre tensor
output buffer
output optre tensor

output shape onehot represent length
axi
numpi axi optre axi
numpi ind0 optre tensor squeez

numpi numpi ind0 size
numpi ind1 rang numpi

index
numpi zero numpi dtype int32
numpi numpi axi numpi ind0
numpi numpi axi numpi ind1
output
output numpi tolist

output

post order stack
postfix stack optre travers

init comput stack
comput stack

iter postfix stack comput result
postfix stack
isinst dict
todo rand onehot
op collect unari
left comput stack
comput stack append numpi call dict left
op collect binari
right comput stack
left comput stack
comput stack append numpi call dict left right
op collect reduct
left comput stack
comput stack append numpi call dict left
op collect zero operand
comput stack append numpi call dict

not implement error
isinst cpu tensor
comput stack append tensor

comput stack append

comput stack
postfix stack

shape dtype name persist valu
parallel distribut

instanti cpu tensor without initi
individu element valu

argument
shape size dimens tensor

dtype dtype option element specifi
dtype valu

persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call

return
cpu tensor newli creat structur refer

dtype dtype dtype dtype
tensor
backend
zero shape dtype
dtype dtype
name name
persist valu persist valu

dtype name persist valu
parallel distribut

instanti cpu tensor set element
valu specifi

argument
numpi ndarray structur contain element valu
spread across dimens python
built type like int list
support
dtype dtype option element specifi
dtype valu float32
overridden
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call

return
cpu tensor newli creat structur refer

dtype dtype dtype dtype
tensor
backend
dtype
dtype dtype
name name
persist valu persist valu

zero shape dtype name persist valu
parallel distribut

instanti cpu tensor set element
valu

argument
shape int size dimens tensor
dtype dtype option element specifi
dtype valu float32
overridden
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call

return
cpu tensor newli creat structur refer

dtype dtype dtype dtype
tensor
backend
zero shape dtype
dtype dtype
name name
persist valu persist valu

one shape dtype name persist valu
parallel distribut

instanti cpu tensor set element
valu

argument
shape int size dimens tensor
dtype dtype option element specifi
dtype valu float32
overridden
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call

return
cpu tensor newli creat structur refer

dtype dtype dtype dtype
tensor
backend
one shape dtype
dtype dtype
name name
persist valu persist valu

like dtype name persist valu

instanti backend tensor
shape taken

argument
tensor tensor inherit dimens
dtype option present specifi underli
employ element
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call
return
tensor

dtype dtype dtype dtype
tensor
backend
zero shape dtype
dtype dtype
name name
persist valu persist valu

zero like dtype name persist valu

instanti backend tensor
shape taken popul element valu

argument
tensor tensor inherit dimens
dtype option present specifi underli
employ element
persist valu option
valu assign tensor
persist across multipl
call set
provid perform increas
valu need
maintain across call
return
tensor

dtype dtype dtype dtype
tensor
backend
zero shape dtype
dtype dtype
name name
persist valu persist valu

compound alpha beta relu bsum

do follow oper product
alpha beta
alpha beta
alpha beta

relu appli output prior beta addit

oper circuit alpha left right
beta valu

argument
cpu tensor input operand
cpu tensor output
alpha scale term
beta scale term
relu whether appli re lu output


check shape
dtype dtype dtype

shape shape
shape shape
shape shape

cleaner implement shall equival
relu
alpha beta

alpha beta

beta
tensor flag contigu
shape dtype dtype
tensor tensor
tensor copi

tensor tensor tensor

relu
relu tensor tensor

multipli tensor beta tensor
shape dtype dtype
tensor tensor
multipli alpha
relu
relu
tensor tensor
bsum
bsum



batch alpha beta relu

do follow oper
fprop call batch
bprop call batch
updat call batch

argument
cpu tensor input operand
cpu tensor output
alpha beta relu usag

dtype dtype dtype

dima dimb dimc
ldaz ldbz ldcz comment stylecheck
batch grid batch loop

shape
dima

shape
dimb

dima dimb tensor must dim batch

shape
dimc
batch grid shape
dima shape batch grid
dimb shape batch grid

dima
batch loop shape
dimb shape batch loop

dimb
batch loop shape
dima shape batch loop

shape dima shape dimc
shape dimb shape dimc
shape dima shape dimb

zero shape

rang batch loop
dima
tensor tensor

tensor tensor

multipli alpha
relu
relu
tensor beta tensor



copi transpos axe

function perform fast copi transpos dimshuffl oper
work like numpi transpos requir output tensor argument

tensor transpos tensor axe copi

make binari mask keepthresh

creat binari mask dropout layer

argument
cpu tensor output tensor
keepthresh fraction one

tensor
uniform size tensor shape keepthresh
dtype tensor dtype

conv layer dtype





bsum

creat conv layer paramet
thi pass argument convolut oper

number imag mini batch
number input featur map
number output featur map

depth input imag
height input imag
width input imag

depth filter kernel
height filter kernel
width filter kernel

pad amount zero pad around given edg
stride factor step filter given direct

dtype need know dtype setup proper kernel

bsum calcul along batchnorm axi fprop bprop
output fp32 tensor size


conv layer dtype


fprop conv layer alpha relu bsum beta

forward propag input convolut network layer
produc output

argument
layer conv layer paramet
cpu tensor input
cpu tensor weight filter
cpu tensor output
alpha linear scale
relu appli re lu output
current implement
beta accumul valu

layer size i size
layer size f size
layer size o size

layer
layer dim i
layer dim f
layer dim o

layer pad
layer stride

tensor reshap layer dim i
tensor reshap layer dim f
tensor reshap layer dim o

rang
slice t slice d layer m slice

rang
slice r slice h layer p slice

rang
slice s slice w layer q slice

slice f slice t slice r slice s reshap
slice i slice d slice h slice w reshap

beta alpha
slice f slice i

bsum
bsum

bprop conv layer grad alpha relu bsum beta

backward propag error convolut network layer

argument
layer conv layer paramet
cpu tensor weight filter
cpu tensor error
grad cpu tensor gradient input output delta
alpha linear scale
beta accumul valu grad
relu appli re lu output
current implement

layer size f size
layer size o size
layer size i grad size

layer
layer dim i
layer dim f
layer dim o

layer pad
layer stride

tensor reshap layer dim f
tensor reshap layer dim o
grad grad tensor reshap layer dim i

transpos copi

rang
slice t slice m layer d slice

rang
slice r slice p layer h slice

rang
slice s slice q layer w slice

slice tr

slice t
slice r
slice s dtype intp

slice mpq

slice m
slice p
slice q dtype intp

slice f reshap
slice tr reshap
slice e reshap
slice mpq reshap

grad beta grad alpha
slice f slice e
forward deconv comput bsum
bsum
bsum grad reshap

updat conv layer alpha

comput updat gradient convolut network layer

argument
layer conv layer paramet
cpu tensor input
cpu tensor error
cpu tensor updat
alpha linear scale

layer size i size
layer size o size
layer size f size

layer dim i
layer dim f
layer dim o

layer pad
layer stride

tensor reshap layer dim i
tensor reshap layer dim o
tensor reshap layer dim f
fill

rang
slice t slice d tlen layer m slice

rang
slice r slice h rlen layer p slice

rang
slice s slice w slen layer q slice

slice i slice d slice h slice w reshap
slice e
slice t slice r slice s alpha
slice i slice e reshap tlen rlen slen

deconv layer dtype





bsum

creat pool layer paramet
thi pass argument pool kernel

pool
number imag mini batch

number input featur map
depth input imag
height input imag
width input imag

size featur pool window maxout piec
depth pool window
height pool window
width pool window

pad amount zero pad around given imag featur edg
stride factor step window given direct overlap allow

leav spatial dimens allow featur pool layer


deconv layer dtype


layer dtype

creat pool layer paramet
thi pass argument pool kernel

number imag mini batch

number input featur map
height input imag
width input imag

size featur pool window maxout piec

pad amount zero pad around given imag featur edg
stride factor step window given direct overlap allow

leav spatial dimens allow featur pool layer

onli support window size


bunch default sinc interest axi
opt dict




pool layer dtype opt

fprop layer denom alpha beta ascal bpower

forward propag pool layer

argument
layer pool layer pool layer differ backend
differ pool layer
tensor input tensor
tensor output tensor
denom tensor denomin tensor store result squar pool contrast
ascal scale paramet alpha multipli pool
bpower exponenti paramet beta denomin


layer size i size
layer size o size

layer jtr
layer dim i
layer dim o
layer pad
layer stride

tensor reshap layer dim i
tensor reshap layer dim o tensor write
although calcul directli keep denom around use bprop
denom tensor reshap layer dim o tensor write

rang
slice c layer k slice
ascal ascal
rang
slice d layer m slice
rang
slice h layer p slice
rang
slice w layer q slice
slice i slice c slice d slice h slice w reshap
ascal squar slice i axi

power bpower elementwis divid denomin

bprop layer delta denom alpha beta ascal bpower

backward propag pool layer

argument
layer pool layer pool layer differ backend
differ pool layer
tensor input tensor
tensor error tensor
delta tensor gradient tensor delta
denom tensor denomin tensor comput bprop
ascal scale paramet alpha multipli pool
bpower exponenti paramet beta denomin


layer size i size
layer size o size
layer size i delta size

layer jtr
layer dim i
layer dim o
layer pad
layer stride

tensor reshap layer dim i
tensor reshap layer dim o
tensor reshap layer dim o
delta delta tensor reshap layer dim i write
denom denom tensor reshap layer dim o

rang
slice c layer k slice
rang
slice d layer m slice
rang
slice h layer p slice
rang
slice w layer q slice

slice c slice d slice h slice w reshap
slice c slice d slice h slice w reshap
denom slice c slice d slice h slice w reshap
temporarili store part deriv
delta axi

delta bpower ascal delta
power denom bpower

pool layer dtype






creat pool layer paramet
thi pass argument pool kernel

pool current bprop support
number imag mini batch

number input featur map
depth input imag
height input imag
width input imag

size featur pool window maxout piec
depth pool window
height pool window
width pool window

pad amount zero pad around given imag featur edg
stride factor step window given direct overlap allow

leav spatial dimens allow featur pool layer

overlap









pool layer dtype


fprop pool layer argmax beta

forward propag pool layer

argument
layer pool layer pool layer differ backend
differ pool layer
tensor input tensor
tensor output tensor
argmax tensor tensor store locat maximum


layer size i size
layer size o size
layer
layer size o argmax size
layer

layer jtr
layer dim i
layer dim o
layer pad
layer stride

tensor reshap layer dim i
tensor reshap layer dim o

argmax argmax tensor reshap layer dim o

rang
slice c layer k slice

rang
slice d layer m slice

rang
slice h layer p slice

rang
slice w layer q slice

slice i slice c slice d slice h slice w reshap

argmax argmax slice i axi
beta
slice i axi

beta
mean slice i axi

beta
sqrt squar slice i axi

bprop pool layer argmax alpha beta

backward propag pool layer

argument
layer pool layer pool layer differ backend
differ pool layer
tensor input error tensor
tensor output delta tensor
argmax tensor tensor store locat maximum
alpha linear scale work pool
beta accumul valu grad


layer size i size
layer size o size
layer
layer size o argmax size
layer

layer jtr
layer dim i
layer dim o
layer pad
layer stride

tensor reshap layer dim o
alpha
delta tensor reshap layer dim i
delta delta beta

argmax argmax tensor reshap layer dim o

rang
slice c clen layer k slice

rang
slice d dlen layer m slice

rang
slice h hlen layer p slice

rang
slice w wlen layer q slice

patch slice c slice d slice h slice w slice
patch slice
slice b delta patch reshap

argmax patch
slice b rang patch

slice b patch slice b shape

not implement error
delta patch slice b reshap clen dlen hlen wlen

roipool slice stride offset

slice roi pool along dimens
index pool output index
stride
input
offset hstart

hstart floor stride
hend ceil stride

hstart hstart offset
hend hend offset

slice hstart hend hend hstart

roipool fprop roi argmax count
pool height pool width spatial scale

function perform fprop roi pool

argument
tensor
roi tensor ro is
tensor pool height pool width count
argmax tensor pool height pool width count

size
roi pool input featur size match
size argmax size pool height pool width count
roi pool output shape match

roi shape ro is dimens
roi shape count ro is match count

tensor reshap
roi roi tensor
tensor reshap pool height pool width count

argmax argmax tensor reshap pool height pool width count

argmax

combin featur ro is
xrang count
xmin ymin xmax ymax roi
xmin round xmin spatial scale
xmax round xmax spatial scale
ymin round ymin spatial scale
ymax round ymax spatial scale
width xmax xmin
height ymax ymin

stride height pool height
stride width pool width

xrang pool height
sliceh lenh roipool slice stride ymin
sliceh stop sliceh start

xrang pool width
slicew lenw roipool slice stride xmin
slicew stop slicew start


sliceh slicew reshap
axi

respect featur map coordin
slice unravel index argmax axi lenh lenw
slice slice sliceh start
slice slice slicew start
slice slice slice
argmax slice

roipool bprop roi argmax count
pool height pool width spatial scale

function perform bprop roi pool

argument
tensor input error pool height pool width count
argmax tensor arg fprp pool height pool width count
roi tensor ro is
tensor output delta

size argmax size pool height pool width count
roi pool bprop input size match
size
roi pool bprop output size match

roi shape ro is dimens
roi shape count ro is match count

tensor reshap pool height pool width count
roi roi tensor
delta tensor reshap
argmax argmax tensor reshap pool height pool width count
delta

xrang count
xmin ymin xmax ymax roi
xmin round xmin spatial scale
xmax round xmax spatial scale
ymin round ymin spatial scale
ymax round ymax spatial scale
width xmax xmin
height ymax ymin

stride height pool height
stride width pool width

iter featur fall ro is
rang xmin xmax
rang ymin ymax
phstart floor ymin stride
phend ceil ymin stride
pwstart floor xmin stride
pwend ceil xmin stride

phstart phstart pool height
phend phend pool height
pwstart pwstart pool width
pwend pwend pool width

rang phstart phend
rang pwstart pwend
argmax
rang

delta

compound fprop xsum xvar gmean gvar gamma beta
accumbeta relu

function perform batch normal forward includ
compat compound kernel call

argument
tensor input previou layer
xsum tensor precomput batch dimens
xvar tensor buffer varianc comput kernel
gmean tensor mean
gvar tensor varianc
gamma tensor scale paramet
beta tensor locat paramt
tensor normal output
constant numer stabil
exponenti window averag constant

xvar axi
xsum xsum shape reus xsum instead comput xmean
xhat xsum sqrt xvar

gmean gmean xsum
gvar gvar xvar

output reshap xhat shape
output xhat gamma beta

compound bprop delta grad gamma grad beta delta xsum xvar
gamma

function perform batch normal backward includ
compat compound kernel call

argument
delta tensor delta buffer write
grad gamma tensor gradient gamma
grad beta tensor gradient beta
delta tensor delta buffer read incom error
tensor feedforward input
xsum tensor batch dimens
xvar tensor batch varianc
gamma tensor scale paramet
constant numer stabil

xhat xsum sqrt xvar
grad gamma xhat delta axi
grad beta delta axi
xtmp xhat grad gamma grad beta shape
delta reshap delta shape gamma delta xtmp sqrt xvar

compound bprop input error error alpha beta

backward propag lookup tabl layer

argument
integ number input word
input tensor input tensor
error tensor error tensor
error tensor transpos error tensor
tensor gradient tensor delta
integ
alpha
beta

input tensor
unqidx uniqu invers
group rang unqidx

group unqidx group

error take group axi axi

altern bprop
enumer
error


hist tensor

creat tensor right size histogram memori alloc
contigu histogram buffer track later refer

hist hist
hist hist
hist hist hist
hist
hist

dump hist

hist hist
hist hist
hist dict
hist
hist
hist hist bin dtype int32
hist hist

relu

calcul re lu transform input

argument
numpi
refer output


maximum

maximum

init mark

gener time mark

return
time mark dict

time

record mark marker

mark current time

argument
marker time mark time mark gener init mark

marker time time time

synchron mark marker

synchron given marker

argument
marker time mark time mark gener init mark




time start

return time start mark

argument
start time maker start time mark

time marker time mark

return
time elaps start time mark millisecond

time start time 1000
copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

definit layer
these layer mainli use benchmark code
also cach comput complex layer
todo clean merg layer
todo remov param cach code neon layer replac benchmark code

log
numpi
pycuda driver
neon backend kernel spec
neon backend convolut
pycuda tool context depend memoiz

math ceil



logger log get logger name


version info
functool reduc


layer


layer


init dtype dtype u

hasattr dtype
dtype dtype

dtype dtype dtype


dtype u dtype dtype u dtype u

flop
size i
size o
size f
weight
fprop
fprop
bprop
bprop

learn rate

init activ fprop

fprop
fprop fprop

fprop dim o dtype dtype

stat dim o2 dtype float32

init delta share

share
bprop dim i dtype dtype

bprop share share dim i
share revers

delta stat dim i2 dtype float32

init weight scale share zero

size f
zero
weight zero dim f dtype dtype

weight random normal scale dim f
weight weight dtype dtype

share
updat dim f dtype dtype u

updat share share dim f dtype dtype u

weight stat dim f2 dtype float32

scale weight scale

mean activ mean
weight scale mean

fprop fprop scale weight
fprop fprop
fprop fprop reshap dim i
fprop

bprop bprop beta
bprop

fprop relu happen insid conv gemm kernel
bprop relu bprop

bprop bprop fprop
bprop

grad descent

weight updat learn rate

activ mean
mean fprop stat dim o2

activ
fprop stat dim o2

delta mean
mean bprop delta stat dim i2

delta
bprop delta stat dim i2

updat mean
size f
mean updat weight stat dim f2


updat
size f
updat weight stat dim f2


weight mean
size f
mean weight weight stat dim f2


weight
size f
weight weight stat dim f2


mean shape

buf1
reshap shape axi
buf1 axi size
buf1

shape

buf1
reshap shape axi
buf1 axi
buf1

fprop stat
fprop mean
activ mean activ

bprop stat
bprop
bprop mean
delta mean delta

weight
mean updat mean updat
mean weight mean weight
mean 0001 mean mean 0001
updat mean mean
weigh mean mean
ratio mean mean

staticmethod
creat conf prev layer dtype

config dict conf
layer config layer

merg dtype specif set
config dtype dtype

merg share
config updat config common

propag calcul dimens
prev layer
config prev layer

layer full layer
config prev layer n out
layer pool layer prev layer full layer
config prev layer n out
layer batch norm prev layer full layer
config prev layer n out

config prev layer
config prev layer
config prev layer
config prev layer

layer incept
partit config partit
config

config partit
part partit
layer sequenc
part prev layer prev layer
layer conf part
part prev layer layer creat layer conf part prev layer dtype
layer sequenc append part prev layer

last layer sequenc
config partit append layer sequenc
config last
config
config last config last

config last
config last
config last

instanti layer
layer config


data layer layer


input layer


init dtype

data layer init dtype







dim i
dim o
dim i2
dim o2
size o reduc dim o
size i size o

init

fprop fill

fprop

init delta share


init weight scale share zero


fprop fprop scale weight
fprop


data layer


full layer layer


fulli connnect layer


init dtype n out relu

full layer init dtype


n out n out
flop n out
dim i
dim i2
dim o n out
dim o2 n out
dim f n out
dim f2 n out
size i
size o n out
size f n out
relu relu

fprop fprop scale weight

fprop full layer fprop fprop
compound weight fprop fprop relu

scale weight
scale weight scale weight
fprop fprop

fprop

bprop bprop beta

relu
bprop relu bprop
compound weight bprop bprop

compound bprop fprop updat
grad descent

bprop


full layer n out n out


conv layer layer


conv layer paramet
thi pass argument convolut oper

number imag mini batch
number input featur map
number output featur map

depth input imag
height input imag
width input imag

depth filter kernel
height filter kernel
width filter kernel

pad amount zero pad around given edg
stride factor step filter given direct


init dtype





relu bsum

conv layer init dtype float32

comput output spatial dimens
output
output
output










pad
stride
relu relu
bsum bsum



dim i
dim f
dim fb
dim o
dim i2
dim f2
dim f2t
dim o2
dim s
size i reduc dim i
size f reduc dim f
size o reduc dim o
n out reduc

flop count benchmark
flop

cuda
cudac kernel

conv support

valu error convolut support cuda kernel

relu
valu error compound relu support cuda kernel

fprop kernel convolut fprop cuda dtype
bsum bsum
todo small bprop
bprop kernel convolut bprop cuda dtype
bsum bsum
updat kernel convolut updat cuda dtype


winograd
enabl winograd
winograd conv fprop winograd bprop winograd updat winograd
fprop winograd bprop winograd updat winograd

temp till autotun
safer fp16 without batchnorm
dtype float32 enabl winograd enabl winograd
winograd

winograd


fprop kernel convolut fprop direct
dtype
relu bsum
winograd
fprop kernel fprop winograd
dtype relu bsum

fprop kernel fprop winograd
dtype relu bsum

winograd
bprop kernel bprop winograd
dtype relu bsum

bprop kernel bprop winograd
dtype relu bsum


updat kernel convolut updat direct
dtype

winograd
updat kernel updat winograd
dtype

updat kernel updat winograd
dtype

direct

size dtype items

fprop kernel convolut fprop direct
dtype
relu bsum

size
bprop kernel convolut bprop direct
dtype
relu bsum

special kernel deconv first layer
relu bsum
logger warn small bprop kernel support compound relu bsum

bprop kernel convolut bprop direct small c
dtype


updat kernel convolut updat direct
dtype


logger debug fprop kernel bprop kernel updat kernel


init activ fprop

conv layer init activ fprop

bsum
batch dim s dtype float32

batch

fprop fprop scale weight

conv layer forward propag

argument
fprop tensor input
scale weight scale weight scale mean nonzero

return
fprop tensor output activ

fprop batch tupl tupl batch
ad second entri

fprop conv layer fprop fprop
fprop conv fprop weight fprop bsum batch

scale weight
scale weight scale weight
fprop fprop

bsum
fprop batch
fprop

bprop bprop beta

relu
bprop relu bprop
bprop
bprop conv weight bprop bprop beta beta

updat conv fprop bprop updat
grad descent

bprop


conv layer


deconv
deconv layer conv layer


deconv layer paramet
thi pass argument convolut oper

number imag mini batch
number output featur map
number input featur map

height input
width input

depth output imag
height output imag
width output imag

depth filter kernel
height filter kernel
width filter kernel

pad amount zero pad around given edg
stride factor step filter given direct


init dtype





relu bsum

const


cannot exact uniqu



deconv layer init
dtype





relu bsum

n out reduc




deconv layer



pool layer layer


pool layer paramet
thi pass argument pool kernel

pool
number imag mini batch

number input featur map
depth input imag
height input imag
width input imag

size featur pool window maxout piec
depth pool window
height pool window
width pool window

pad amount zero pad around given imag featur edg
stride factor step window given direct overlap allow

leav spatial dimens allow featur pool layer



init dtype






pool layer init dtype

dtype float16
clss hpool
dtype float32
clss spool

type error type support

overlap










overlap ceil
ceil
ceil
ceil

overlap

todo detect form gap

gap

gap

bprop zero overlap gap

comput output dimens
output pool
output pool
output pool
output pool







jtr


pad
stride

dim i
dim o
dim f2
dim i2
dim o2
size i reduc dim i
size o reduc dim o
n out reduc

precomput multipl fast constant memori access


dhwn



jrst


mpqn

jrst integ divis faster 16bit numer

larg
shl p mask p shr p shl q mask q shr q mask n shr n
0x00 0x00 0xfff nnnnn
0x00 0x10 0x00f xnnnn
0x00 0x18 0x007 xxnnn
0x00 0x1c 0x003 xxxnn
0x00 0x1e 0x001 1x16 xxxxn
0x00 0x1f 0x000 1x32 xxxxx

medium
shl p mask p shr p shl q mask q shr q mask n shr n
0x10 0x0c 0x003 yxxnn
0x10 0x0e 0x001 yxxxn
0x10 0x0f 0x000 2x16 yxxxx

small
shl p mask p shr p shl q mask q shr q mask n shr n
0x18 0x06 0x001 yyxxn
0x18 0x07 0x000 yyxxx



block

block

block
block block

minim zero overlap superblock
maxim superblock contigu memori access
block
larg block
block
medium block

small block

sup p ceil
sup q ceil

precomput magic number shift amount integ divis
magic magic32 jrst
magic magic32
magic magic32
magic magic32 sup p sup p

fprop name fprop
bprop name bprop

thread block

fprop kernel fprop name sup q sup p thread flatten
dhwn
magic mpqn


jrst magic magic magic
sup p sup q

size jrst
size
size size

bprop size fprop size block size

overlap

special kernel handl overlap pool
bprop name overlap

magic magic32
magic magic32
magic magic32
magic magic32

block

bprop name small n

block
larg block
block
medium block

small block

sup h ceil
sup w ceil

magic magic32 sup h sup h

max lut size
ceil
ceil
ceil
ceil

sup w sup h max lut size

bprop kernel bprop name sup w sup h thread flatten
dhwn magic


magic magic magic magic
jrst magic magic magic
mpqn
sup h sup w max lut size

size max lut size
size
size size

bprop size block size



overlap kernel much effici superblock
magic magic32

bprop kernel bprop name thread flatten
dhwn magic


magic magic magic magic
jrst magic magic magic
mpqn

bprop size size

bprop kernel bprop name sup q sup p thread flatten
dhwn
magic mpqn


jrst magic magic magic
sup p sup q

init activ fprop

pool layer init activ fprop

argmax dim o dtype uint8

fprop fprop scale weight
use benchmark
fprop pool layer fprop fprop
fprop pool fprop fprop argmax argmax
fprop

bprop bprop beta
bprop pool bprop bprop argmax argmax
bprop


pool layer jtr
jtr


incept layer


goog le net incept assembl layer



init dtype partit




incept init dtype

partit partit










dim i
dim o
dim i2
dim o2
size i reduc dim i
size o reduc dim o
n out reduc

size f
flop
part partit
layer part
flop layer flop
size f size f layer size f
size f layer size f
dim f layer dim f


incept

part enumer partit
part
layer part
layer
rstrip

init activ fprop

incept init activ fprop

part partit
layer part
layer part
layer init activ fprop layer
layer

layer init activ

init delta share

incept init delta share

share delta share share

part partit
layer part
layer part
layer bprop bprop
layer delta stat delta stat

layer init delta share share delta

init weight scale share zero

part partit
layer part
layer init weight scale share zero

fprop fprop scale weight

fprop incept fprop fprop

part partit
part fprop fprop
layer part
part fprop layer fprop part fprop scale weight

fprop

bprop bprop


part partit
part bprop bprop part
part
layer part
part partit layer part
beta

beta

part bprop layer bprop part bprop beta

bprop

fprop stat
part partit
layer part
layer fprop stat

bprop stat
part partit
layer part
layer bprop stat


batch norm layer


batch normal layer


init dtype
relu bsum

batch normal layer

argument
class nervana gpu
dtype dtype data
batch size
number input featur map
depth input featur map
height input featur map
width input featur map
number input fulli connect layer
exponenti window averag factor
constant ad numer stabil
relu flag rectifi linear activ
bsum precomput conv kernel

batch norm init dtype



relu relu
bsum bsum








dim i
dim o
dim o2
dim2
n out



n out

dim i
dim o
dim o2
dim2


valu error miss

depth dim2


batch norm dim2

init activ fprop

fprop
fprop fprop reshap dim2

fprop dim2 dtype dtype

xvar dtype dtype
bsum
xsum dtype float32

init delta share


init weight scale share zero



beta zero dtype dtype
gamma one dtype dtype

gmean zero dtype dtype
gvar zero dtype dtype

grad beta zero dtype dtype
grad gamma zero dtype dtype

fprop fprop scale weight

batch normal forward use compound kernel call

fprop tupl
fprop bsum fprop

bsum

fprop
fprop fprop reshap dim2

bsum
xsum fprop axi

xsum bsum

compound fprop
fprop xsum xvar gmean gvar
gamma beta fprop relu

fprop

bprop bprop beta

bprop
bprop bprop reshap dim2

relu
bprop relu bprop

compound bprop
bprop grad gamma grad beta fprop
xsum xvar gamma

bprop

fprop stat


bprop stat




magic number shift amount integ divis
suitabl nmax magic fit bit
shamelessli pull directli
http hackersdelight hdcodetxt magicgu
magic32 nmax
nmax
nbit nmax
rang nbit



valu error find magic divis

magic number shift amount integ divis
suitabl nmax magic fit bit shift
lop lower bit
magic64
special end high bit
nmax 0xffffffff
0xffffffff case
magic
nmax 0xffffffff 0x7fffffff
magic shift magic32 nmax
magic
shift
magic shift

flatten nest list valu
flatten
isinst tupl
flatten

ceil


context depend memoiz
count
attribut context devic attribut
attribut devic attribut multiprocessor count
copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

python code wrap convolut kernel


numpi
pycuda driver
pycuda compil sourc modul
pycuda tool context depend memoiz
neon backend kernel spec
neon backend cuda templat common round type
math ceil



version info
functool reduc


kernel group
init dtype


dtype dtype
dtype dtype
size dtype items

dtype float16
clss hconv
dtype float32
clss sconv
dtype int16
clss fconv
dtype int8
clss bconv

type error dtype support


type error pleas implement describ kernel log

bind arg
type error bind implement

execut unbind
type error execut implement

init bsum bsum flag
flag flag
bsum
bsum gpudata bsum gpudata
bsum zero bsum gpudata bsum size stream
flag

bsum gpudata
bsum zero
flag
bsum gpudata flag

partit tile

partit
tile tile
grid tile tile
grid
partit append tile grid
grid tile


partit

xprop kernel tile tile grid tile arg

kernel
tile grid offset partit tile

kernel name clss tile tile tile

block kernel spec kernel kernel name thread

grid grid grid

grid grid grid


kernel name grid block
offset
extend arg

kernel append


fprop direct kernel group

init dtype






relu bsum

fprop direct init dtype

must multipl
size must multipl size

tile
grid ceil tile
tile tile

magic magic64
magic magic64
magic magic32
magic magic32

xprop kernel
fprop tile grid tile
flatten
magic magic

magic magic

share
flag relu bsum

bind alpha beta bsum flag

dtype dtype dtype

bsum gpudata flag init bsum bsum flag

kernel kernel
kernel stream bsum gpudata gpudata gpudata gpudata
alpha beta flag

execut unbind

rang

bsum zero
memset async bsum zero

kernel kernel
kernel kernel spec kernel kernel
kernel prepar async call kernel share size share

unbind
bsum zero
kernel kernel
kernel


fprop direct kernel


fprop cuda kernel group

init dtype






bsum

fprop cuda init dtype

must multipl
size must multipl size

magic magic64
magic magic64
magic magic32


krst


neon backend kernel cuda convolut conv kernel
kernel conv kernel dtype dtype filter size
bsum bsum oper fprop
grid
block
kernel arg flatten

krst

magic magic magic
launch arg grid block kernel arg

share
flag bsum

bind alpha beta bsum flag

dtype dtype dtype

bsum gpudata flag init bsum bsum flag

launch arg stream alpha beta
gpudata gpudata gpudata bsum gpudata

execut unbind

rang

bsum zero
memset async bsum zero

kernel prepar async call launch arg share size share

unbind
bsum zero
launch arg


fprop cuda


bprop cuda kernel group

init dtype






bsum

bprop cuda init dtype

must multipl
size must multipl size

magic magic64
magic magic64
magic magic32
magic magic32



crst



bsum bsum
neon backend kernel cuda convolut conv kernel
kernel conv kernel dtype dtype filter size
bsum bsum oper bprop
grid
block
kernel arg flatten

crst

magic magic magic
launch arg grid block kernel arg

share
flag bsum

gener kernel arg shuffl ctrsk ktrsc
shuffl grid ceil ceil
shuffl size dtype items
shuffl arg shuffl grid
shuffl arg extend flatten


magic magic

scratch size shuffl size

bind alpha beta bsum flag

dtype dtype dtype
bsum
bsum must initi bsum config

bsum gpudata flag init bsum bsum flag

filter temp scratch buffer shuffl size

shuffl arg stream filter temp gpudata
launch arg stream alpha beta
gpudata filter temp gpudata bsum gpudata

execut unbind

shuffl kernel shuffl kernel dtype

rang

bsum zero
memset async bsum zero

shuffl kernel prepar async call shuffl arg
kernel prepar async call launch arg share size share

unbind
bsum zero
shuffl arg
launch arg


bprop cuda


updat cuda kernel group

init dtype







updat cuda init dtype

must multipl




krst
crstk krst


magic magic32

determinist
grid
grid
determ crstk

grid
grid
determ

block grid grid
magic magic64 block
magic magic64 grid

neon backend kernel cuda convolut conv kernel
kernel conv kernel dtype dtype filter size
bsum oper updat
grid block
block
kernel arg flatten

krst
grid grid
magic magic magic
launch arg grid block kernel arg

scratch size determ

updat grid kernel name block count

thread kernel spec kernel kernel name thread
occup kernel spec kernel kernel name occup

warp schedul block
block thread count

grid
rang
rang

occup block block
group occup occup
slot ceil group

thi heurist keep balanc work accross
also maxim work block
heurist slot rang slot group

grid append heurist

grid sort

grid grid thread

bind alpha

dtype dtype

dtype float32

updat temp scratch buffer determ size

convert arg updat temp

updat temp gpudata
convert arg

zero arg updat temp size stream

beta
bsum gpudata
launch arg stream alpha beta
gpudata gpudata gpudata bsum gpudata

execut unbind

rang

memset async zero arg

kernel prepar async call launch arg

convert arg
convert convert arg

unbind
zero arg convert arg
launch arg


updat cuda


bprop direct kernel group

init dtype






relu bsum

bprop direct init dtype

must multipl
size must multipl size

tile
grid ceil tile
tile tile

magic magic64
magic magic64
magic magic32
magic magic32
magic magic32
magic magic32
magic magic32

xprop kernel
bprop tile grid tile
flatten
magic magic

magic magic
magic magic magic

share
flag relu bsum

gener kernel arg shuffl ctrsk ktrsc
shuffl grid ceil ceil
shuffl size dtype items
shuffl arg shuffl grid
shuffl arg extend flatten


magic magic

scratch size shuffl size

bind alpha beta bsum flag

dtype dtype dtype

bsum gpudata flag init bsum bsum flag

filter temp scratch buffer shuffl size

shuffl arg stream filter temp gpudata

kernel kernel
kernel stream bsum gpudata gpudata gpudata filter temp
alpha beta flag

execut unbind

shuffl kernel shuffl kernel dtype

rang

bsum zero
memset async bsum zero

shuffl kernel prepar async call shuffl arg

kernel kernel
kernel kernel spec kernel kernel
kernel prepar async call kernel share size share

unbind
bsum zero
shuffl arg
kernel kernel
kernel


bprop direct kernel


bprop direct small c kernel group

init dtype







bprop direct small c init dtype

must multipl

magic magic64
magic magic64
magic magic32
magic magic32
magic magic32

special kernel deconv first layer
kernel name bprop clss

grid ceil ceil
block

kernel kernel name grid block
kernel extend flatten

magic magic magic

magic magic
dtype items dtype items

gener kernel arg transpos crst crst
shuffl grid ceil ceil
shuffl size dtype items
shuffl arg shuffl grid

zero dtype items

scratch size shuffl size

bind alpha beta bsum flag

dtype dtype dtype

beta beta
beta appli beta

beta beta

zero arg gpudata zero stream

filter temp scratch buffer shuffl size

shuffl arg stream filter temp gpudata

kernel stream gpudata gpudata filter temp alpha

execut unbind

shuffl kernel transpos kernel dtype

kernel kernel spec kernel kernel
rang

atom add accumul
beta
memset async zero arg

shuffl kernel prepar async call shuffl arg

kernel prepar async call kernel

unbind
zero arg
shuffl arg
kernel


bprop direct small c kernel


updat direct kernel group

init dtype







updat direct init dtype

must multipl

magic magic32
magic magic32
magic magic32

grid ceil
count count

float32 featur layer smaller tile actual faster
restrict tile select
dtype float32
tile

tile

determinist
determ

tile

tile tile
determ

determ
determ

kernel
tile grid offset partit tile

kernel name updat c128 clss determ tile
block grid grid

grid grid thread updat grid kernel name block count
grid grid

grid grid grid
magic magic64 grid
magic magic64 grid

block thread

grid grid grid grid

grid grid grid grid

determ grid
determ shape grid

kernel kernel name grid block
kernel extend flatten
offset
magic magic magic

magic magic
grid grid grid

kernel append kernel

scratch size determ

updat grid kernel name block count

thread kernel spec kernel kernel name thread
occup kernel spec kernel kernel name occup

warp schedul block
block thread count

grid
rang
rang

occup block block
group occup occup
slot ceil group

thi heurist keep balanc work accross
also maxim work block
heurist slot rang slot group

grid append heurist

grid sort

grid grid thread

bind alpha

dtype dtype

dtype float32 determ

updat temp scratch buffer determ size

convert arg updat temp
determ
convert arg determ shape

updat temp gpudata
convert arg

zero arg updat temp size stream

kernel kernel
kernel stream updat temp gpudata gpudata alpha

execut unbind

rang

determ
memset async zero arg

kernel kernel
kernel kernel spec kernel kernel
kernel prepar async call kernel

convert arg
convert convert arg

unbind
zero arg convert arg
kernel kernel
kernel


updat direct kernel


magic number shift amount integ divis
suitabl nmax magic fit bit
shamelessli pull directli
http hackersdelight hdcodetxt magicgu
magic32 nmax
nmax
nbit nmax
rang nbit



valu error find magic divis


magic number shift amount integ divis
suitabl nmax magic fit bit shift
lop lower bit
magic64
special end high bit
nmax 0xffffffff
0xffffffff case
magic
nmax 0xffffffff 0x7fffffff
magic shift magic32 nmax
magic
shift
magic shift


flatten nest list valu
flatten
isinst tupl
flatten


ceil



closest divisor maxdiv
sort rang maxdiv


context depend memoiz
count
attribut context devic attribut
attribut devic attribut multiprocessor count


convert dest tensor reduc shape

reduc shape

kernel reduc kernel dest tensor dtype
block ceil reduc shape
kernel prepar async call block
dest tensor backend stream
dest tensor gpudata

reduc shape
reduc shape reduc shape


neon backend nervanagpu gpu tensor
neon backend compound kernel fast dim

quick wrapper convert fp32 scratch destin tensor
shape stride fast dim dest tensor size
kernel arg
dest tensor gpudata stride stride
stride stride
shape

kernel compound kernel
gpu tensor dest tensor dtype
gpu tensor
assign
dest tensor backend comput capabl
kernel prepar async call shape

dest tensor backend stream
kernel arg


fast axi reduct kernel use determinist updat
context depend memoiz
reduc kernel dtype

reduc kernel
common

reduc crstk pqcrstk

offset block idx thread idx

offset crstk


offset pqcrstk crstk



offset



val
common common round nearest dtype
type dtype

dtype
val fp32 fp16
dtype
val
dtype
val fp32 int16

type error miss reduct

code reduc kernel val
sourc modul code
kernel reduc
kernel prepar ppii
kernel


context depend memoiz
transpos kernel dtype

transpos kernel
transpos row col

share tile

thread idx
thread idx
block idx
block idx






row col
tile col

syncthread







col row
row tile



code transpos kernel type dtype
sourc modul code
kernel transpos
kernel prepar ppii
kernel


context depend memoiz
shuffl kernel dtype

shuffl kernel
dim shuffl

trsk
trsc

magic shift
magic shift

share tile

thread idx
thread idx
block idx
block idx
block idx




magic shift


magic shift






tile trsk

syncthread




mirror








trsc tile



code shuffl kernel type dtype
sourc modul code
kernel dim shuffl
kernel prepar ppiiiiiiiiiiiiiiii
kernel


context depend memoiz
copi transpos kernel dtype shape axe

rang shape
axe




inner need share memori tile
then outer sourc thread idx valu


share tile

share tile

offset
offset

valu
magic

dim bound check

append
valu append shape

collaps shape
grid shape shape
grid shape ceil shape
grid shape ceil shape

without
src2

name first compound index
blkx name compound join src2

gener magic math extract indec
src2

idx1 src2
src2
idx2 join src2
reduc grid shape src2

extend idx2 magic shift
valu extend magic64
valu append

magic
div64 magic shift

format compound idx1 idx2

compound idx2

stride gener offset
param valu ad extern

append
offset append

stride gener offset

append
offset append

div64
devic forceinlin div64 valu magic shift

divisor power magic simpl right shift
otherwis multipli magic right shift high bit
result

pred
res64
lo32 hi32
setp
wide res64
lo32 hi32 res64
selp hi32 hi32
hi32
result valu magic shift
result


share tile
copi transpos
common

copi transpos

share tile

thread idx
thread idx
block idx
block idx

magic




in00 offset
in08 in00
in16 in08
in24 in16



tile in00
tile in08
tile in16
tile in24

syncthread

val00 tile
val08 tile
val16 tile
val24 tile






out00 offset
out08 out00
out16 out08
out24 out16

out00 val00
out08 val08
out16 val16
out24 val24



copi transpos
common

copi transpos

thread idx
thread idx
block idx
block idx

magic










val00
val08
val16
val24

in00 offset
in08 in00
in16 in08
in24 in16

val00 in00
val08 in08
val16 in16
val24 in24

out00 offset
out08 out00
out16 out08
out24 out16

out00 val00
out08 val08
out16 val16
out24 val24


code copi transpos dict
common div64
type dtype
join
blkx name


magic magic
offset join offset
offset join offset

code
sourc modul code
kernel copi transpos
kernel prepar

grid grid shape
grid grid shape


grid grid shape

kernel grid grid grid
kernel block
kernel arg tupl valu

kernel
python

copyright 2015 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi
ipdb trace
pack unpack

ceil


pad stride
ceil pad stride

strip mantissa
unpack pack 0x7f800000
unpack pack


quantiz bit
maxval absolut
scale strip mantissa maxval bit
around scale astyp int64
float32 scale

direct convolut

fconv slice pad stride


stride pad








slice slice

bconv slice pad stride
pad
first f
rang todo remov logic

stride
stride

first f
first f
first e
last f
last e
slice first f last f stride slice first e last e stride

xprop direct pad stride backward

shape
shape
backward
cx hwn kx hwn
reshap reshap reshap shape

kx hwn cx hwn
reshap reshap reshap shape


backward
mirror
transpos copi
xconv slice bconv slice

xconv slice fconv slice

shape
shape
shape

q slice xconv slice pad stride rang

rang
slice r slice y xconv slice pad stride

rang
slice s slice x q slice

slice f slice r slice s reshap
slice i slice y slice x reshap

slice f slice i

updat direct pad stride

shape
shape
shape


cx hwn kx hwn
reshap reshap reshap shape


fill

q slice fconv slice pad stride rang

rang
slice r slice y rlen fconv slice pad stride

rang
slice s slice x slen q slice

slice i slice y slice x reshap
slice e

slice r slice s slice i slice e reshap rlen slen

winograd convolut













dtype float32

half
quarter

tran minim
minim



































tran minim
minim
half


half



quarter


quarter
quarter
half
half


half
half



half
half

quarter
quarter
quarter
quarter
half
half
half
half



tran minim
minim
dtype dtype
































tran minim
minim



































tran minim
minim
half
half
half
half
half
half
half
half

half
half


half
half


half
half


half
half




tran minim

minim
dtype dtype

























imag slice
start
stop start

start
start
start
stop
stop
start stop



xprop winograd pad minim backward

backward
mirror
transpos copi
invert pad
pad pad

shape
shape



ceil
ceil



dtype float32

transform filter
rang
rang
tran minim

iter imag transform dimens slice tile imag
rang
start stop imag slice pad

rang
start stop imag slice pad

slice i start stop start stop

zero pad need

slice i slice i constant

appli imag transform
rang
rang
tran slice i minim

scale f quantiz
scale i quantiz

astyp float32
astyp float32

batch gemm pointwis multipl step
rang
rang
yw xw n
reshap reshap

astyp float32 scale f scale i

astyp float32

iter convovl result pointwis space appli invers transform
rang

plen
rang

qlen
rang
rang
toss point
plen qlen tran minim plen qlen



updat winograd pad minim inner

shape
shape



ceil
ceil



inner

fill

zero

rang
start stop imag slice pad
start stop imag slice

rang
start stop imag slice pad
start stop imag slice

slice i start stop start stop
slice e start stop start stop


slice i slice i constant


slice e slice e constant

rang
rang
tran slice i minim


reshap


rang
rang
tran slice e minim

reshap

rang
rang

inner




transform appli inner outer
inner
rang
rang
tran minim

outer transform
inner
rang
rang
tran minim



test code

printopt threshold 8192 linewidth formatt

minim
one

1024

fix winograd
stride fix winograd
pad

pad stride
pad stride

dim i
dim f
dim o

one
one dim i
one dim f
one dim o

rang
rang
arang reshap

rang
rang
arang reshap


maximum random uniform dim i
random normal dim f
random uniform dim f
random uniform dim o

dim o
dim o dtype float32

dim i
dim i dtype float32

dim f
dim f


xprop direct pad stride
xprop winograd pad minim minim

xprop direct pad stride backward
xprop winograd pad minim minim backward

updat direct pad stride
updat winograd pad minim minim inner

dif o
dif b
dif u

dif o
dif b
dif u






dif u
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file


comput capabl devic verbos

queri comput capabl py cuda check maxwel
greater
gtx750 fp32 support
gtx9xx seri requir fp16
check devic highest comput capabl

argument
devic cuda devic default iter
devic
verbos print verbos log

return
zero found otherwis highest comput capabl


pycuda
pycuda driver
import error
verbos
py cuda found


init
pycuda driver runtim error
py cuda runtim error format


major pycuda driver devic attribut comput capabl major
minor pycuda driver devic attribut comput capabl minor
full version
devic
devic rang devic count
isinst devic
devic devic

devic
major devic attribut major
minor devic attribut minor
full version major minor

verbos
found comput capabl full version

full version


devic count verbos

queri devic count py cuda

argument
verbos print verbos log

return
number gp us avail


pycuda
pycuda driver
import error
verbos
py cuda found


init
pycuda driver runtim error
py cuda runtim error format


count devic count

verbos
found count

count

name main
comput capabl verbos

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file

itertool
numpi

neon nervana object
neon backend test util call func backend tensor
neon backend test util tensor allclos


test func


collect function test

staticmethod
func reduct axi
mean axi keepdim
axi keepdim axi keepdim
keepdim

argmax axi reshap shape

argmax axi keepdim
shape






staticmethod
func reduct axi
mean axi keepdim
axi keepdim axi keepdim
axi keepdim

argmax axi reshap shape

argmax axi keepdim


hstack

shape







pytest gener test metafunc

test gener

test
test indic rang

test
test func
test func func reduct axi
test func func reduct axi

test tensor flag rand rand rand
test tensor dim

gener test
custom arg metafunc fixturenam
farg itertool product test indic
test func
test tensor flag
test tensor dim
parameter test call
metafunc parametr custom arg farg


test numpi backend test custom arg
test flag custom arg

backend
nervana object
dtype dtype

tensor
tensor backend tensor flag dtype dtype

compar valu
numpi func call func tensor
backend func call func tensor

tensor allclos numpi func backend func rtol atol

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file


test batch behavior nervana cpu nervana gpu backend
numpi
nervana gpu support insid dimens outer dimens
nervana cpu support insid dimens sinc

numpi

neon backend nervanagpu nervana gpu
neon backend nervanacpu nervana cpu
neon backend test util tensor allclos

size size input


setup test dtype
dim w
dim i
dim o

cpu i random uniform dim i astyp dtype
cpu e random uniform dim o astyp dtype
cpu w random uniform dim w astyp dtype

trace

cpu i cpu e cpu w


batch dtype

dev i dtype dtype
dev e dtype dtype
dev w dtype dtype

dev o zero shape dtype dtype
dev b zero shape dtype dtype
dev u zero shape dtype dtype

isinst nervana cpu
batch dev w dev i dev o fprop
batch dev w dev e dev b bprop
batch dev e dev i dev u updat
isinst nervana gpu
batch dev w dev i dev o size size fprop
batch dev w dev e dev b size size bprop
batch dev e dev i dev u size size updat

trace
rang
dev o fprop
dev b bprop
dev u updat

dev o dev b dev u


test batch devic
printopt threshold 8192 linewidth
formatt

nervana gpu stochast round bench devic devic
nervana cpu

dtype float32 float16 float32

batch size
minibatch size
1536 input featur
output featur

cpu i cpu e cpu w setup test dtype

batch cpu i cpu e cpu w dtype
batch cpu i cpu e cpu w dtype
batch cpu i cpu e cpu w dtype

trace
tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol

tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol



copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file

itertool
numpi

neon nervana object
neon backend test util call func backend tensor
neon backend test util tensor allclos


test func


collect function test

staticmethod
func reduct
axi keepdim axi keepdim
axi keepdim
axi keepdim
keepdim





staticmethod
func reduct transpos
axi keepdim axi keepdim
axi keepdim
axi keepdim
keepdim






pytest gener test metafunc

test gener

test
test indic rang

test
test func
test func func reduct
test func func reduct transpos

test tensor flag rand rand rand
test tensor dim

gener test
custom arg metafunc fixturenam
farg itertool product test indic
test func
test tensor flag
test tensor dim
parameter test call
metafunc parametr custom arg farg


test numpi backend test custom arg
test flag custom arg

backend
nervana object
dtype dtype

tensor
tensor backend tensor flag dtype dtype

compar valu gradient
numpi func call func tensor
backend func call func tensor

tensor allclos numpi func backend func rtol atol

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file


test conv layer oper nervana gpu nervana cpu numpi
numpi implement differ done underneath nervana cpu
valid check requir extern input nervana cpu


itertool
numpi


neon backend nervanagpu nervana gpu
neon backend nervanacpu nervana cpu
test util allclos
timeit timer


slicabl

colaps outer dimens preserv inner dimens
allow easi convolut numpi

argument
tupl dimens tupl
mani pixel pad

dim0 reduc
dim0


pixel indic conv

conv
conv
conv


imax


rang


rang




rang




rang




imax bound

append



backend conv layer dtype

dtype dtype
dtype dtype
dtype dtype

zero layer dim o dtype dtype
fprop conv layer

zero layer dim i dtype dtype
bprop conv layer

zero layer dim f dtype dtype
updat conv layer




pytest gener test metafunc

build test




























farg test metafunc fixturenam
farg product
metafunc parametr farg test farg


test conv layer farg test devic

dtype float32

nervana gpu stochast round bench devic devic

farg test
farg test
farg test
pad pad pad farg test
stride stride stride farg test

conv conv layer
dtype



pad pad pad
stride stride stride

nervana cpu
conv conv layer
dtype



pad pad pad
stride stride stride

conv dim i conv dim i
conv dim f conv dim f
conv dim o conv dim o
conv conv

dim i conv dim i
dim f conv dim f
dim o conv dim o

input array
cpu i random uniform slicabl dim i astyp float32
cpu f random uniform slicabl dim f astyp float32
cpu e random uniform dim o astyp float32

zero last input sake numpi
cpu i


cpu i reshap dim i
cpu f reshap dim f
cpu e

start timer
backend conv conv dtype
timer

start timer
backend conv conv dtype
timer

gputim cputim
start start

numpi
output array
cpu o zero dim o dtype dtype
cpu b zero slicabl dim i dtype dtype
cpu u zero slicabl dim f dtype dtype

conv
conv
conv

conv pad
conv stride

rang


rang


rang


pixel indic conv

cpu o cpu f cpu i

cpu b cpu f cpu e

cpu u cpu i cpu e

cpu a
fprop cpu o
bprop reshap dim i cpu b reshap dim i
updat reshap dim f cpu u reshap dim f


nc anp astyp float32
ng anp astyp float32
ncdif cpu a nc anp
ngdif cpu a ng anp
maxval cpu a
ncmaxdif ncdif
ngmaxdif ngdif
nc ratio ncmaxdif maxval
ng ratio ngmaxdif maxval

nc ratio
ng ratio
allclos cpu a rtol atol
allclos cpu a rtol atol




name main

farg 1280





test conv layer farg

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file

neon backend backend tensor
test util allclos
numpi


call func backend tensor

call evalu correspond tensor return numpi

argument
usag backend tensor
backend backend numpi nervana gpu nervana cpu
tensor tensor

return
numpi ndarray evalu result

backend
backend tensor

tree backend tensor
tree backend tree shape
tree tree
tree


tensor allclos tensor tensor rtol atol

backend call tensor return result
allclos

argument
tensor tensor tensor
tensor anoth tensor tensor
rtol option rel toler
atol option absolut toler
return
tensor close

deal individu tensor
tensor tensor
tensor tensor
tensor tensor
result
tensor tensor tensor tensor
isinst tensor tensor
tensor tensor
isinst tensor tensor
tensor tensor
result append allclos tensor astyp tensor dtype
tensor
rtol rtol atol atol

result


func allclos backend backend tensor rtol atol

backend call tensor result
close

argument
usag backend tensor
backend backend numpi nervana gpu nervana cpu
tensor tensor
rtol option rel toler
atol option absolut toler

return
result close

call func result
result
backend tensor backend backend tensor
result append call func backend tensor

result equal
tensor allclos result rtol rtol atol atol


backend tensor backend tensor dim flag dtype float32

gener random backend

argument
backend list backend nervana gpu nervana cpu
tensor dim list dimens tensor exampl

dtype float16 float32 must
backend dtype backend nervana
backend
flag provid specifi flag
tensor provid appli
tensor flag follow
zero one one rand
rand rand

return
list list tensor correspond backend
exampl
ndarray ndarray ndarray
gpu tensor gpu tensor gpu tensor
cpu tensor cpu tensor cpu tensor


tensor tensor dim
flag
flag tensor

init
backend tensor rang tensor

gener

tensor flag tensor dim flag
flag zero one one rand rand
rand

numpi standard valu
flag zero
tensor zero tensor
flag one
tensor one tensor
flag one
tensor one tensor
flag rand
tensor random rand tensor
flag rand
tensor random rand tensor
flag rand flag
tensor random randn tensor

not implement error
tensor tensor astyp dtype

copi differ backend
backend tensor backend backend tensor
backend
tensor append tensor

backend dtype dtype
tensor append backend tensor name


backend tensor


backend pool

cach reus backend test use test multipl express
backend backend identifi backend dtype

pool

staticmethod
backend backend dtype

argument
backend nervana gpu nervana cpu
dtype float32 float16

return
backend correspond backend certain dtype

backend backend pool pool
backend pool pool backend dict
pool backend pool pool backend

dtype pool
pool dtype backend dtype dtype

pool dtype


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file

numpi
pprint
pytest

neon nervana object
neon backend autodiff autodiff


custom func

staticmethod



staticmethod
sig2
exp2

staticmethod
tanh2
exp2 exp2

staticmethod
argmax axi keepdim

call numpi argmax keepdim

shape shape
shape axi
shape tupl shape
argmax axi axi reshap shape

staticmethod
argmin axi keepdim

call numpi argmin keepdim

shape shape
shape axi
shape tupl shape
argmin axi axi reshap shape


pytest mark usefixtur backend
test autodiff

setup

column
nervana object
dtype dtype
test epoch
delta numer gradient

rand flag

flag scalar


dimens


scalar flag


flag

flag

integ
flag
flag
random randint size astyp

random randint size astyp

flag
absolut random randn

random randn
avoid blow




staticmethod
numpi call tensor

evalu tensro

name varialb form
tensor numpi tensor val

convert numpi
replac
replac custom func
replac sig2 custom func sig2
replac tanh2 custom func tanh2
replac argmax custom func argmax
replac argmin custom func argmin
todo debug
replac axi axi keepdim
todo debug
replac axi axi keepdim

give variabl name tensor
count
tensor tensor
exec tensor count global local
count

execut
result
exec result

result

autodiff grad tensor val tree
error

autodiff grad optre express
express execut
tensor numpi tensor val

backend
use
init tensor
count
tensor
tensor tensor val
exec tensor name dtype dtype
count count
exec tensor append count
count
build tree

exec
evalu tree
shape

init error
error
error error
gradient
autodiff error error

tree
gradient grad tree tensor

gradient grad asnumpyarray tensor

gradient

numer grad tensor error

autodiff grad numpi express
tensor numpi tensor val

buffer gradient
gradient
tensor tensor
gradient append zero tensor shape
valu
test autodiff numpi call tensor
init error
error
error one like
numer gradient
tensor gradient tensor gradient
gradient flat copi gradient reshap

nditer tensor flag readwrit
backup
backup copi
increment
delta
test autodiff numpi call tensor error
backup
decrement
delta
test autodiff numpi call tensor error
backup
gradient
gradient flat delta

write gradient
gradient gradient flat reshap gradient shape

gradient

grad equal tensor rtol atol error

debug count

error tensor count
pprint pformat tensor
grad tree autodiff grad tensor
tree
grad tree grad tree count
grad tree


gradient
autodiff grad autodiff grad
tensor error error
numer grad numer grad
tensor error error

assert
autodiff grad numer grad

check valu
numer grad numer grad
reshap autodiff grad shape
allclos autodiff grad astyp dtype
numer grad astyp dtype
rtol rtol atol atol

check gradient
count
autodiff grad numer grad autodiff grad
numer grad
count
count
allclos autodiff grad astyp dtype numer grad astyp dtype
rtol rtol atol atol
valu error debug count


actual test case

test reduct shape

name

axi
shape

axi
shape


shape

test reduct
todo reduct allow along axi kernel
rang test epoch
tensor
rand rang
functioncal
axi
mean axi
axi

axi
axi
argmax axi
argmin axi
gradient
grad equal rtol

test batchnorm
rang test epoch
tensor
random randn
random randn gamma
random randn beta
error random randn
mean axi sqrt axi
gradient
grad equal rtol atol
error error

test posit
todo potenti problemat
rang test epoch
tensor
rand rang


sqrt

exp2

log2
gradient
grad equal rtol

test real
rang test epoch
tensor
rand rang

absolut
squar

sig2
tanh
tanh2
maximum
gradient
grad equal rtol

test unbroadcast
rang test epoch
scaler matrix
rand scalar
rand


gradient
grad equal rtol

vector matrix
rand
rand


gradient
grad equal rtol

vector matrix
rand
rand


gradient
grad equal rtol

scalar matrix
rand scalar
rand
rand
rand

tanh
gradient
grad equal rtol

test hard code

basic test


one name dtype dtype
one name dtype dtype
one name dtype dtype
one name dtype dtype


autodiff

grad one dtype dtype
grad one dtype dtype
grad one dtype dtype
grad one dtype dtype

allclos grad asnumpyarray grad atol
allclos grad asnumpyarray grad atol
allclos grad asnumpyarray grad atol
allclos grad asnumpyarray grad atol

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test pool layer oper nervana gpu nervana cpu numpi

itertool
numpi


neon backend nervanagpu nervana gpu
neon backend nervanacpu nervana cpu
test util allclos

mani time fprop bprop



sliceabl

colaps outer dimens preserv inner dimens
allow easi oper numpi

dim0 reduc
dim0


pixel indic pool

pool
pool jtr
pool




rang




rang




rang




rang



append



backend pool layer dtype

dtype dtype
dtype dtype
zero layer dim o dtype dtype
zero layer dim o dtype int8
zero layer dim i dtype dtype

rang
fprop pool layer
bprop pool layer




numpi pool cpu i cpu e dytp layer
backend layer paramet

dim i layer dim i
dim o layer dim o
layer
layer
layer
layer
layer pad
layer stride

output array
cpu o dim o dtype dytp
cpu b zero sliceabl dim i dtype dytp

rang
cpu b fill
rang


rang


rang


rang


pixel indic layer


cpu o cpu i axi
argmax cpu i axi
rang
cpu b cpu e

cpu o mean cpu i axi
cpu b cpu e

cpu o sqrt
cpu i axi

cpu o cpu b


pytest gener test metafunc
poolarg metafunc fixturenam
farg


farg product
metafunc parametr poolarg farg


test pool layer poolarg devic

poolarg

dtype float32

nervana gpu stochast round bench devic devic
nervana cpu




pad pad pad pad
stride stride stride stride


pool pool layer
dtype




pad pad pad pad
stride stride stride stride

pool pool layer
dtype




pad pad pad pad
stride stride stride stride

pool dim i pool dim i
pool dim o pool dim o

dim i pool dim i
dim o pool dim o

gener input array input error
cpu i random uniform sliceabl dim i astyp
float16 astyp dtype
cpu e random uniform dim o astyp dtype

zero last input sake numpi

cpu i finfo dtype

cpu i

numpi
cpu i reshap dim i
cpu e

backend pool pool dtype
backend pool pool dtype
cpu o cpu b numpi pool cpu i cpu e dtype pool

cpu a
fprop cpu o
bprop reshap dim i cpu b reshap dim i


allclos rtol atol
allclos cpu a rtol atol



name main
farg
test pool layer farg

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file

numpi

neon backend backend
neon backend test util tensor allclos


test randomst devic

backend backend seed devic devic


rand rand

rand host rand
rand rand

make binari mask keepthresh rand


context rand state context rand state aliv
context rand state aliv
context rand state aliv

reset
reset

rand

rand
rand

make binari mask keepthresh rand


context rand state context rand state aliv
context rand state aliv
context rand state aliv



backend
backend backend seed devic devic


rand rand

rand host rand
rand rand

make binari mask keepthresh rand


check equal
tensor allclos rtol atol
tensor allclos rtol atol




test randomst

backend backend seed


make binari mask keepthresh rand

make binari mask keepthresh rand


reset
reset
make binari mask keepthresh rand

make binari mask keepthresh rand




backend
backend backend seed


make binari mask keepthresh rand

make binari mask keepthresh rand


check equal
tensor allclos rtol atol
tensor allclos rtol atol



test func backend
like test also test state state func
backend

keep batch size 2048 nervana gpu pool size

zero

binari mask test reset

make binari mask
copi
state

make binari mask
copi

infinitesmi chanc equal
make sure someth


reset
make binari mask
copi



reset
state
make binari mask
copi


copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi
itertool
neon backend nervanacpu nervana cpu
neon backend nervanagpu nervana gpu
neon backend test util tensor allclos
neon backend util check


hist nbin offset

implement log2 histogram gear toward visual neural paramet

bin comput log2 magnitud tensor valu bin
round nearest

smallest valu enabl visual zero

log2 comput alway done fp32 regardless input dtype give
round consist behavior

bin arang nbin offset
bin
rint log2 astyp float32
hist edg histogram densiti bin bin
hist ndim
hist hist reshap hist size
hist


test edg case devic

test sever edg case relat round

also test backend dump hist function

gpuflag check comput capabl
gpuflag
runtim error devic cuda comput capabl greater
nervana gpu devic devic
nervana cpu
edg test
dict
input
edg dtype float32
round 99998856
11262291 22483826 dtype float32
fp16 round 21875 dtype float16

input
hist


hist hist
tensor allclos hist

dump hist test

hist hist dump hist
input
hist hist
tensor allclos





test hist nbin offset dtype devic

compar nervanagpu nervanacpu hist implement refer
implement

parameter test use pytest gener test enumer dtype
tupl drive test


nbin offset dtype name nbin offset dtype

gpuflag check comput capabl
gpuflag
runtim error devic cuda comput capabl greater

nervana gpu hist bin nbin hist offset offset devic devic
nervana cpu hist bin nbin hist offset offset

astyp dtype
hist hist nbin nbin offset offset

dtype dtype
hist hist name
tensor allclos hist hist




pytest gener test metafunc

build test test hist

full slow specifi test
saniti test otherwis

saniti test
off

dim 32768

dtype float32 uint8
input
normal dist random normal reshap


thorough test coverag
metafunc config option

off extend


dim extend
387200





dtype extend
float16
int8


disabl less test
cuda driver init destroy issu prevent memori freed
run certain test fail
input extend
one one


nbin offset dtype metafunc fixturenam
farg product off dim dtype input
metafunc parametr nbin offset dtype farg
python
copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi
pycuda driver
pytest
neon backend nervanagpu nervana gpu

neon backend test util tensor allclos


printopt threshold 8193 linewidth
formatt

devic pytest config getopt devic
nervana gpu stochast round bench devic devic

context current devic name


test pool
config
config overlap
pad
stride
config nooverlap
pad
stridesx
one


alpha
beta
dtype float32 float16

nooverlap overlap
config nooverlap overlap
pool pool layer dtype



config config

pool helper
dtype one alpha beta pool config


pool helper dtype one alpha beta pool config

error dtype config
dtype config

dim i pool dim i
dim o pool dim o

colaps pool dimens
allow easi pool numpi
slicabl
dim0 reduc
dim0

input array
note trunct bit agre
index
one
cpu i one slicabl dim i dtype float32
cpu b one slicabl dim i dtype float32
cpu e one dim o dtype float32
cpu o one dim o dtype float32


astyp float16
cpu i random uniform slicabl dim i
astyp float16 astyp float32
cpu b random uniform slicabl dim i
astyp float16 astyp float32
cpu e random uniform
dim o astyp float16 astyp float32
cpu o random uniform
dim o astyp float16 astyp float32

cpu a dim o dtype int32

give input without zero pad need
dev i cpu i reshap dim i dtype dtype
dev b cpu b reshap dim i dtype dtype
dev e cpu e dtype dtype
dev o cpu o dtype dtype
dev a dim o dtype uint8

fprop pool
pool dev i dev o dev a alpha alpha beta beta

bprop pool
pool dev e dev b dev a alpha alpha beta beta

cpu o beta
cpu b beta

pixel indic

pool
pool jtr
pool




rang




rang




rang




rang



append


numpi pool implement


pool
pool
pool
pool
pool pad
pool stride

rang


rang


rang


rang


pixel indic





trace
cpu o
cpu i axi alpha

argmax cpu i axi
cpu a astyp int32

there probabl eleg numpi

rang
cpu b
cpu e alpha


cpu o
mean cpu i axi alpha

cpu b cpu e
alpha

bprop implement

cpu o sqrt
cpu i axi

drop zero pad
cpu i cpu i reshap dim i
cpu b cpu b reshap dim i

dev a dev a astyp int32
dev o dev o astyp float32
dev b dev b astyp float32

dif a absolut cpu a dev a

savetxt cpu b cpu b reshap pool
savetxt dev b dev b reshap pool

dif o absolut cpu o dev o
max d dif o
max o absolut cpu o
dif o cpu o ratio
max d max o max d max o
tensor allclos cpu o dev o rtol atol fprop

dif b absolut cpu b dev b
max d dif b
max b absolut cpu b
dif b cpu b ratio
max d max b max d max b
tensor allclos cpu b dev b rtol atol bprop


name main
test pool

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file


test basic math oper tensor compar numpi result
tensor type includ tensor


numpi
itertool
neon backend nervanagpu nervana gpu
neon backend nervanacpu nervana cpu
neon backend test util tensor allclos


init helper dtype
dtype dtype
dtype dtype
shape dtype dtype



math helper dtype
init helper dtype




















compar helper dtype devic
numpi result math helper dtype float32

dtype dtype kind dtype dtype kind
numpi result around numpi result
numpi result numpi result clip
iinfo dtype iinfo dtype
numpi result numpi result astyp dtype

dtype float32 float16
nervana gpu dtype dtype devic devic
nervana gpu result math helper dtype dtype
nervana gpu result nervana gpu result
allclos numpi result nervana gpu result rtol atol

nervana cpu dtype dtype
nervana cpu result math helper dtype dtype
nervana cpu result nervana cpu result
allclos numpi result nervana cpu result rtol atol


rand unif dtype dim
dtype dtype kind
random uniform dim astyp dtype

iinfo iinfo dtype
around random uniform iinfo iinfo dim clip iinfo iinfo


pytest gener test metafunc

build test


dim

1023


dtype float32 float16

farg test metafunc fixturenam
farg product dim dtype
metafunc parametr farg test farg


test math farg test devic

dim dtype farg test

rand a rand unif dtype dim
rand b rand unif dtype dim

compar helper rand a rand b dtype devic devic
compar helper rand a rand b dtype devic devic
compar helper rand a rand b dtype devic devic
compar helper rand a rand b dtype devic devic
compar helper rand a rand b dtype devic devic
compar helper rand a rand b dtype devic devic
compar helper rand a rand b dtype devic devic


test slice farg test devic
dim dtype farg test

nervana gpu dtype dtype devic devic
nervana cpu dtype dtype

random uniform dim astyp dtype
dtype dtype
dtype dtype

tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol
tensor allclos rtol atol




tensor allclos rtol atol


numpi
neon backend backend


test devic

perform stochast round mantissa addit oper
check result round correctli

backend backend stochast round devic devic

one dtype float16
one dtype float16
multipli
one dtype float16
round

host
make sure everyth either round round
host
host flatten rang
host flatten rang
host flatten rang

name main
test

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pylint skip file

itertool
numpi

neon nervana object
neon backend autodiff autodiff
neon backend test util call func backend tensor
neon backend test util tensor allclos


audiff gradient tensor

autodiff gradient tensor

tree tensor
autodiff tree



numer gradient tensor delta

element make last layer error

buffer gradient
gradient
rang tensor
tensor tensor astyp float64
gradient append zero tensor shape

iter throuth tensor
tensor gradient tensor gradient

tensor flat tensor reshap
gradient flat gradient reshap

iter throuth element
rang tensor flat
backup
backup tensor flat
increment
tensor flat tensor flat delta
tensor
decrement
tensor flat backup delta
tensor
recov
tensor flat backup
gradient
gradient flat delta

gradient


func


collect function test

staticmethod
func basic


staticmethod
func real
absolut squar

staticmethod
func


staticmethod
func reduct
axi keepdim
axi keepdim

axi keepdim


staticmethod
func scalar broadcast


staticmethod
func transpos





pytest gener test metafunc
test
test indic rang

test
test func
func func basic
func func real
func func
func func reduct
func func scalar broadcast
func func transpos

test tensor flag rand rand rand
test tensor dim

gener test
custom arg metafunc fixturenam
farg itertool product test indic
test func
test tensor flag
test tensor dim
parameter test call
metafunc parametr custom arg farg


test gradient backend test custom arg
test flag custom arg

backend test fixtur parameter
backend well float16 float32
pull dtype action fixtur
nervana object
dtype dtype

tensor
tensor backend tensor flag dtype dtype

compar valu gradient
numpi func call func tensor
backend func call func tensor
numer gradient numer gradient tensor
audiff gradient tensor
autodiff gradient grad asnumpyarray tensor

todo stricter test numer issu
tensor allclos numpi func backend func rtol atol
tensor allclos numer gradient autodiff gradient rtol atol

cleanup diff tree
cleanup
dtype

copyright 2014 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi
neon backend nervanagpu nervana gpu
neon backend nervanacpu nervana cpu


slicabl
dim0 prod
dim0


test pool devic
nervana gpu stochast round bench devic devic
nervana cpu
layer arg dict dtype float32
pool test arg dict one
alpha support
ascal
beta support
bpower
layer layer layer arg return pool layer
layer layer layer arg
layer arg

helper pool test arg


helper dtype one alpha beta ascal bpower
layer layer

dim i layer dim i
dim o layer dim o

input array
note trunct bit
agre index
one
cpu i one slicabl dim i dtype float32
cpu b one slicabl dim i dtype float32
cpu e one dim o dtype float32
cpu o one dim o dtype float32

cpu i random uniform slicabl dim i astyp float16 astyp float32
cpu b random uniform slicabl dim i astyp float16 astyp float32
cpu e random uniform dim o astyp float16 astyp float32
cpu o random uniform dim o astyp float16 astyp float32

give input without zero pad need
dev i cpu i reshap dim i dtype dtype
dev b cpu b reshap dim i dtype dtype delta backprop
dev e cpu e dtype dtype
dev o cpu o dtype dtype
dev d dim o dtype dtype denom

ccc i cpu i reshap dim i dtype dtype
ccc b cpu b reshap dim i dtype dtype delta backprop
ccc e cpu e dtype dtype
ccc o cpu o dtype dtype
ccc d dim o dtype dtype denom

layer denom ascal bpower
fprop layer dev i dev o dev d alpha beta ascal bpower denom
fprop layer ccc i ccc o ccc d ascal bpower alpha beta

denom
fprop
ccc d reshap
fprop
dev d reshap

output
fprop
ccc o reshap
fprop
dev o reshap

delta denom
bprop layer dev i dev o dev e dev b dev d alpha beta ascal bpower
bprop layer ccc i ccc o ccc e ccc b ccc d ascal bpower

bprop
bprop
ccc b reshap
bprop
dev b reshap


name main
test pool
copyright 2016 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi
itertool
neon backend nervanacpu nervana cpu
neon backend nervanagpu nervana gpu
neon backend test util tensor allclos


test copi transpos shape dtype devic

parameter test use pytest gener test enumer dtype
tupl drive test


shape dtype name shape dtype
nervana gpu dtype dtype devic devic
nervana cpu dtype dtype
shape astyp dtype
ndim shape

axe permut rang ndim ndim
axe remov tupl rang ndim
product axe
dtype dtype
tran transpos axe
tran zero tran shape
copi transpos tran axe
tensor allclos tran tran




pytest gener test metafunc

build test test copi transpos

full slow specifi test
saniti test otherwis

saniti test
shape





dtype float32 float16
input
normal dist shape random uniform shape


shape dtype metafunc fixturenam
farg product shape dtype input
metafunc parametr shape dtype farg
copyright 2015 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

copyright 2016 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

pycuda compil sourc modul
pycuda tool context depend memoiz

neon backend cuda templat type


cuda kernel lookup tabl layer kernel given bprop sinc
fprop take oper there determinist kernel
determinist kernel atom provid sort kernel also
provid help determinist version



context depend memoiz
bprop kernel dtype determinist

build bprop kernel lookup tabl layer base templat code
determinist version request index buffer must pass
argument thi index buffer order item input tensor
word sort thi requir sinc need sure
thread updat weight word

argument
dtype dtype kernel oper
determinist build determinist kernel


determinist
code
bprop
input error
embed vocab size

thread idx
block idx

word input
error embed
output word embed

word

embed block dim

atom add output error error





code code
type dtype


sourc modul code option fast math
kernel bprop
kernel prepar pppii ii

code
bprop
input index buffer error
embed vocab size


thread idx
block idx

index posit
index index buffer index posit
word input index

word input index buffer word

output word embed


error index embed

embed block dim

output error error


index posit
index posit grid dim



index index buffer index posit
input index word




code code
type dtype


sourc modul code option fast math
kernel bprop
kernel prepar ppppii ii

kernel name bprop
kernel


sort kernel kernel block size

build kernel use sort input there sever kernel
correspond step algorithm algorithm work
determin sort posit input item thi done
bucket sort algorithm word bucket first step
determin size bucket occur word
next prefix comput bucket size find
bucket place output buffer final thread
place index correct sort posit base bucket
start index comput prefix thread offset
bucket taken output atom done
first step

argument
kernel integ which step build kernel
block size integ number thread block prefix
kernel

code
defin thread thread
defin store blocksum store blocksum
sort inputs0
input index buffer offset buffer word count vocab size
input length

thread idx block dim block idx
word

input length

word input
offset buffer atom add word count word



devic scan buffer blocksum length

thread idx
thread idx block idx block dim

share local count thread
local count buffer
local count buffer

pragma unrol
skip skip thread skip

mask skip
mask mask

local count local count skip


syncthread


thread

store blocksum
blocksum block idx local count

local count


pragma unrol
skip thread skip skip

mask skip
mask mask

temp local count skip
local count skip local count
local count temp


syncthread


length

buffer local count
buffer local count



sort inputs1
input index buffer offset buffer word count vocab size
input length

scan word count word count vocab size vocab size


sort inputs2
input index buffer offset buffer word count vocab size
input length

scan word count vocab size block dim


sort inputs3
input index buffer offset buffer word count vocab size
input length

thread idx block idx block dim

vocab size

word count word count vocab size block idx
word count word count vocab size block idx



sort inputs4
input index buffer offset buffer word count vocab size
input length

thread idx block dim block idx
word

input length

word input
sort posit word count word offset buffer
index buffer sort posit



code code
thread block size
store blocksum kernel

sourc modul code option fast math

name sort input kernel
kernel name
kernel prepar ppppii
kernel name sort input
kernel

pycuda compil sourc modul
pycuda tool context depend memoiz
neon backend cuda templat

neon backend cuda templat common fp16 fp32
common round fp32 fp16 convert
common
common kepler
type


cuda kernel pool layer support pool averag pool
pool fprop bprop bprop
overlap kernel each kernel use templat perform dtype
convers work type current fp32 fp16 support
addit templat statist collect current support
output tensor pass addit kernel
argument



string2func funcnam clss comput capabl

helper convert name call

funcnam global
attribut error kernel funcnam understood
global funcnam clss comput capabl


use hide variabl defin condit
atom
atom max maxab intermedi


common divmod
devic forceinlin div16 numer magic shift


vmad numer magic
shift

devic forceinlin mod16 numer maxdiv


vmad maxdiv numer


devic forceinlin mad16


vmad


devic forceinlin msub16


vmad




prepar val dtype comput capabl round

code snippet reus across multipl kernel
most convers statist collect relat

val dict
init finish stat arg scale atom
val

val common common divmod

round
val common common urand
val common common round nearest dtype
val init init rand func init rand round func
val finish finish rand func
mode random

mode nearest

val common common round mode dtype
val common common

comput capabl comput capabl comput capabl
val common common kepler

val type dtype
val type dtype

dtype
val common common fp16 fp32
val fp32 fp16
dtype
val stat arg maxab scale0
val
val fp32 int16
val scale scale0
val atom atom
dtype


valu error understand clss dtype dtype

val


thi section code contain templat cuda code kernel
context depend memoiz
fprop clss comput capabl

code
defin 402823466 e

common

spool fprop

alpha beta flag

dhwn
magic shift mpqn


jrst
magic shift
magic shift magic shift
sup p sup q shl p mask p shr p
shl q mask q shr q mask n shr n
stat arg


share
thread idx

block idx
block idx
block idx

magic shift
sup p

zigzag back forth improv cach perf

sup q

superblock
shl p mask p shr p
shl q mask q shr q
mask n

shr n

offset mpqn mad16

offset
offset

beta








mask n

jrst
jrst jrst

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16






bound
bound
bound
bound
bound bound bound bound bound

slice i dhwn

offset mad16 jrst jrst

offset bound slice i
jrst


syncthread

intermedi



jrst
argmax

jrst jrst

offset mad16 jrst jrst

slice0 offset
slice1 offset
slice2 offset
slice3 offset

need stay fp32
val0 jrst jrst slice0 slice0
val1 jrst jrst slice1 slice1
val2 jrst jrst slice2 slice2
val3 jrst jrst slice3 slice3

val0
val0
argmax jrst

val1
val1
argmax jrst

val2
val2
argmax jrst

val3
val3
argmax jrst


jrst

convert back write
temp scale alpha beta
flag
temp
argmax


intermedi temp comput

intermedi
atom



val prepar val clss comput capabl
code code val
sourc modul code
kernel spool fprop
clss
kernel prepar
kernel


context depend memoiz
fprop clss comput capabl

code
common

spool fprop

alpha beta flag

dhwn
magic shift mpqn


jrst
magic shift
magic shift magic shift
sup p sup q shl p mask p shr p
shl q mask q shr q mask n shr n
stat arg


share rcp window size
share

thread idx

block idx
block idx
block idx

magic shift
sup p

zigzag back forth improv cach perf

sup q

superblock
shl p mask p shr p
shl q mask q shr q
mask n

shr n


mpqn mad16

beta








mask n
sb bit shr n
sb mask sb bit mad16 sb bit

window size
jrst
jrst jrst

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16






bound
bound
bound
bound
bound bound bound bound bound

count total valid slice
window size popc sb mask ballot bound

slice i dhwn

offset mad16 jrst jrst

offset bound slice i
jrst


todo confirm kepler
shr n mask shr n shr n 0xffffffff
shr n mask
rcp window size window size

syncthread

window size rcp window size

intermedi



jrst

jrst jrst

offset mad16 jrst jrst

slice0 offset
slice1 offset
slice2 offset
slice3 offset

jrst jrst slice0 slice0
jrst jrst slice1 slice1
jrst jrst slice2 slice2
jrst jrst slice3 slice3

jrst


convert back write
temp scale window size alpha beta
flag
temp

collect stat
intermedi temp comput

intermedi
atom



val prepar val clss comput capabl
code code val
sourc modul code option fast math
kernel spool fprop
kernel prepar clss
kernel


context depend memoiz
fprop clss comput capabl

local respons normal layer
implement base fprop kernel

implement follow oper
output pixel
respons
respons
respons alpha neighbor neighbor beta
comput pool output

code
common

spool fprop

alpha beta ascal bpower flag

dhwn
magic shift mpqn


jrst
magic shift
magic shift magic shift
sup p sup q shl p mask p shr p
shl q mask q shr q mask n shr n
stat arg


share rcp window size
share

thread idx

paralel qmpk dimens output pixel

block idx
block idx
block idx

magic shift


zigzag back forth improv cach perf



ion o input pixel output locat

ion o mpqn
mpqn
mpqn

beta








window size
jrst
gener pool normal
jrst jrst

jrst magic shift
jrst

magic shift


magic shift







bound
bound
bound
bound
bound bound bound bound bound

count total valid slice
window size popc ballot bound

slice i dhwn

jrst bound slice i
jrst




rcp window size window size
rcp window size jrst


syncthread


denom
sumsquar
input
jrst
jrst jrst

slice0 jrst
slice1 jrst
slice2 jrst
slice3 jrst

todo need load slice use
input jrst jrst slice0 slice0
sumsquar jrst jrst slice0 input input
input jrst jrst slice1 slice1
sumsquar jrst jrst slice1 input input
input jrst jrst slice2 slice2
sumsquar jrst jrst slice2 input input
input jrst jrst slice3 slice3
sumsquar jrst jrst slice3 input input

jrst


denom ascal sumsquar rcp window size
ion o powf denom bpower


convert back write
temp scale alpha beta

predic write flag
flag
temp
scale denom write denomiantor address


collect stat
intermedi temp comput
atom



val prepar val clss comput capabl
code code val
sourc modul code
kernel spool fprop
kernel prepar clss superblock paramet
kernel


context depend memoiz
bprop overlap clss comput capabl

code
common

lut entri

slice
argmax

int2 data2


spool bprop overlap
delta
alpha beta ascal bpower flag

dhwn
magic shift


magic shift
magic shift
magic shift
magic shift
jrst
magic shift magic shift
magic shift
mpqn
stat arg maxab scale0


share int2
share rcp window size

thread idx


block idx
block idx
block idx

magic shift


zigzag back forth improv cach perf



use insid jrst
output
error
denom

use output


delta dhwn
dhwn
dhwn
dhwn

delta beta delta

build lookup tabl







jrst
jrst jrst

jrst magic shift
jrst

magic shift


magic shift


prime
prime
prime
prime

prime magic shift
prime
bound

prime magic shift
prime
bound

prime magic shift
prime
bound

prime magic shift
prime
bound

bound bound bound bound bound

prime prime
prime prime
prime prime
prime prime

slice i mpqn
argmax i prime prime prime prime

lut entri entri
entri slice slice i
entri argmax bound argmax i

jrst entri data2
jrst




rcp window size jrst


syncthread

jrst

delta
intermedi

jrst jrst

lut entri entry0
lut entri entry1
lut entri entry2
lut entri entry3

entry0 data2 jrst
entry1 data2 jrst
entry2 data2 jrst
entry3 data2 jrst

delta jrst jrst entry0 argmax entry0 slice entry0 slice entry0 slice
delta jrst jrst entry1 argmax entry1 slice entry1 slice entry1 slice
delta jrst jrst entry2 argmax entry2 slice entry2 slice entry2 slice
delta jrst jrst entry3 argmax entry3 slice entry3 slice entry3 slice

jrst


delta bpower ascal delta rcp window size powf bpower

temp scale delta alpha delta beta
flag
delta temp


comput
intermedi intermedi temp use
atom



val prepar val clss comput capabl
code code val
sourc modul code
kernel spool bprop overlap
kernel prepar clss
kernel

context depend memoiz
bprop clss comput capabl

code

common

spool bprop

alpha beta flag

dhwn
magic shift mpqn


jrst
magic shift
magic shift magic shift
sup p sup q shl p mask p shr p
shl q mask q shr q mask n shr n
stat arg


share

thread idx

block idx
block idx
block idx

magic shift
sup p

zigzag back forth improv cach perf

sup q

superblock
shl p mask p shr p
shl q mask q shr q
mask n

shr n

offset mpqn mad16

offset
offset

delta
argmax


delta
argmax









mask n

jrst
jrst jrst

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16






bound
bound
bound
bound
bound bound bound bound bound

slice i dhwn

offset mad16 jrst jrst

offset bound slice i
jrst


syncthread

intermedi



delta alpha
load beta beta
jrst

jrst jrst

offset mad16 jrst jrst

offset0 offset
offset1 offset
offset2 offset
offset3 offset

need figur write output write fp16
load fp16 fp16 pointer
out0 offset0
out1 offset1
out2 offset2
out3 offset3

valid0 jrst jrst offset0
valid1 jrst jrst offset1
valid2 jrst jrst offset2
valid3 jrst jrst offset3

load input dtype convert float32
beta0 valid0 load beta out0 beta
beta1 valid1 load beta out1 beta
beta2 valid2 load beta out2 beta
beta3 valid3 load beta out3 beta

convert float32 back input format write
temp out0 valid0 scale jrst argmax delta beta0 beta0
temp out1 valid1 scale jrst argmax delta beta1 beta1
temp out2 valid2 scale jrst argmax delta beta2 beta2
temp out3 valid3 scale jrst argmax delta beta3 beta3

predic write flag
flag
valid0 out0 temp out0
valid1 out1 temp out1
valid2 out2 temp out2
valid3 out3 temp out3

intermedi intermedi temp out0
intermedi intermedi temp out1
intermedi intermedi temp out2
intermedi intermedi temp out3

jrst


intermedi
atom


val prepar val clss comput capabl
code code val
sourc modul code
kernel spool bprop
open spool bprop
code
close
kernel prepar clss
kernel


context depend memoiz
bprop clss comput capabl

code

common

spool bprop

alpha beta flag

dhwn
magic shift mpqn


jrst
magic shift
magic shift magic shift
sup p sup q shl p mask p shr p
shl q mask q shr q mask n shr n
stat arg


share rcp window size
share

thread idx

block idx
block idx
block idx

magic shift
sup p

zigzag back forth improv cach perf

sup q

superblock
shl p mask p shr p
shl q mask q shr q
mask n

shr n


mpqn mad16

delta

delta








mask n
sb bit shr n
sb mask sb bit mad16 sb bit

window size
jrst
jrst jrst

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16






bound
bound
bound
bound
bound bound bound bound bound

count total valid slice
window size popc sb mask ballot bound

slice i dhwn

offset mad16 jrst jrst

offset bound slice i
jrst

todo confirm kepler
shr n mask shr n shr n 0xffffffff
shr n mask
rcp window size window size

syncthread

intermedi



delta alpha rcp window size
load beta beta
jrst

jrst jrst

offset mad16 jrst jrst

offset0 offset
offset1 offset
offset2 offset
offset3 offset

out0 offset0
out1 offset1
out2 offset2
out3 offset3

valid0 jrst jrst offset0
valid1 jrst jrst offset1
valid2 jrst jrst offset2
valid3 jrst jrst offset3

beta0 valid0 load beta out0 beta
beta1 valid1 load beta out1 beta
beta2 valid2 load beta out2 beta
beta3 valid3 load beta out3 beta

temp out0 valid0 scale delta beta0
temp out1 valid1 scale delta beta1
temp out2 valid2 scale delta beta2
temp out3 valid3 scale delta beta3

predic write flag
flag
valid0 out0 temp out0
valid1 out1 temp out1
valid2 out2 temp out2
valid3 out3 temp out3

intermedi intermedi temp out0
intermedi intermedi temp out1
intermedi intermedi temp out2
intermedi intermedi temp out3

jrst


intermedi
atom


val prepar val clss comput capabl
code code val
sourc modul code option fast math
kernel spool bprop
kernel prepar clss
kernel


context depend memoiz
bprop overlap clss comput capabl

code
common

lut entri

slice
argmax

int2 data2


spool bprop overlap

alpha beta flag

dhwn
magic shift


magic shift
magic shift
magic shift
magic shift
jrst
magic shift magic shift
magic shift
mpqn
stat arg maxab scale0


share lut size
share int2

thread idx


block idx
block idx
block idx

magic shift


zigzag back forth improv cach perf





dhwn

beta

size







mask 0xffffffff
mask

size

jrst
jrst jrst

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16

prime
prime
prime
prime

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

bound bound bound bound bound

mask valid slice warp
ballot ballot bound

count total valid slice
warp slice popc ballot

bound

count valid slice threadid
popc mask ballot

prime prime
prime prime
prime prime
prime prime

lut entri entri
entri slice mpqn mad16
entri argmax prime mad16 prime mad16 prime prime

size entri data2

size warp slice
jrst


lut size size

syncthread

size lut size

jrst

intermedi

jrst size

lut entri entry0
lut entri entry1
lut entri entry2
lut entri entry3

entry0 data2 jrst
entry1 data2 jrst
entry2 data2 jrst
entry3 data2 jrst

argmax
fprop argmax0 jrst size entry0 slice
fprop argmax1 jrst size entry1 slice
fprop argmax2 jrst size entry2 slice
fprop argmax3 jrst size entry3 slice

jrst size fprop argmax0 entry0 argmax entry0 slice
jrst size fprop argmax1 entry1 argmax entry1 slice
jrst size fprop argmax2 entry2 argmax entry2 slice
jrst size fprop argmax3 entry3 argmax entry3 slice

jrst

temp scale alpha beta
flag
temp

comput
intermedi intermedi temp use
atom


val prepar val clss comput capabl
code code val
sourc modul code
kernel spool bprop overlap
kernel prepar clss
kernel

context depend memoiz
bprop overlap clss comput capabl

code

common

lut entri

slice


int2 data2


devic forceinlin imin val1 val2


val1 val2



spool bprop overlap

alpha beta flag

dhwn
magic shift


magic shift
magic shift
magic shift
magic shift
jrst
magic shift magic shift
magic shift
mpqn
stat arg maxab scale0


share lut size
share int2

thread idx


block idx
block idx
block idx

magic shift


zigzag back forth improv cach perf




dhwn

beta
size








mask 0xffffffff
mask

size

jrst
jrst jrst

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16

prime
prime
prime
prime

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

bound bound bound bound bound

mask valid slice warp
ballot ballot bound

count total valid slice
warp slice popc ballot

bound

count valid slice threadid
popc mask ballot

left msub16
left msub16
left msub16
left msub16

imin imin left imin left
imin imin left imin left
imin imin left imin left
imin imin left imin left

total

total total

lut entri entri
entri slice mpqn mad16
entri

size entri data2

size warp slice
jrst


lut size size

syncthread

size lut size

jrst

intermedi

jrst size

lut entri entry0
lut entri entry1
lut entri entry2
lut entri entry3

entry0 data2 jrst
entry1 data2 jrst
entry2 data2 jrst
entry3 data2 jrst

jrst size entry0 slice entry0
jrst size entry1 slice entry1
jrst size entry2 slice entry2
jrst size entry3 slice entry3

jrst


temp scale alpha beta
flag
temp


unrol
intermedi intermedi temp use

atom



val prepar val clss comput capabl
code code val
sourc modul code option fast math
kernel spool bprop overlap
kernel prepar clss
kernel


context depend memoiz
bprop overlap small n clss

code
common

lut entri

slice
argmax

int2 data2


spool bprop overlap small n

alpha beta flag

dhwn
magic shift


magic shift
magic shift
magic shift
magic shift
jrst
magic shift magic shift
magic shift
mpqn
sup h sup w shl h mask h shr h
shl w mask w shr w mask n shr n max lut size
stat arg maxab scale0


share int2

thread idx

block idx
block idx
block idx

magic shift
sup h

zigzag back forth improv cach perf

sup w

superblock
shl h mask h shr h
shl w mask w shr w
mask n

shr n



dhwn mad16

beta






sb size mask n
sb bit mad16 sb size
sb mask 0xffffffff sb size sb bit
mask 0xffffffff sb bit

offset mad16 max lut size
size
jrst
jr tend jrst
jr tend mask n
jr tend sb size jr tend mask n

jrst jr tend

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16

prime
prime
prime
prime

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

bound jrst jrst bound bound bound bound

mask valid slice warp
ballot ballot bound

count total valid slice superblock
slice popc sb mask ballot

bound

count valid slice threadid
popc mask ballot

prime prime
prime prime
prime prime
prime prime

slice i mpqn mad16
argmax i prime mad16 prime mad16 prime prime

lut entri entri
entri slice slice i
entri argmax argmax i

offset size entri data2

size slice
jrst sb size


intermedi



jrst


jrst max lut size

lut entri entry0
lut entri entry1
lut entri entry2
lut entri entry3

offset mad16 max lut size jrst

entry0 data2 offset
entry1 data2 offset
entry2 data2 offset
entry3 data2 offset

argmax
fprop argmax0 jrst size entry0 slice
fprop argmax1 jrst size entry1 slice
fprop argmax2 jrst size entry2 slice
fprop argmax3 jrst size entry3 slice

jrst size fprop argmax0 entry0 argmax entry0 slice
jrst size fprop argmax1 entry1 argmax entry1 slice
jrst size fprop argmax2 entry2 argmax entry2 slice
jrst size fprop argmax3 entry3 argmax entry3 slice

jrst

temp scale alpha beta
flag
temp

comput
intermedi intermedi temp use

intermedi
atom


val prepar val clss
code code val
sourc modul code
kernel spool bprop overlap small n
kernel prepar clss
kernel


context depend memoiz
bprop overlap small n clss

code

common

lut entri

slice


int2 data2


devic forceinlin imin val1 val2


val1 val2



spool bprop overlap small n

alpha beta flag

dhwn
magic shift


magic shift
magic shift
magic shift
magic shift
jrst
magic shift magic shift
magic shift
mpqn
sup h sup w shl h mask h shr h
shl w mask w shr w mask n shr n max lut size
stat arg maxab scale0


share int2

thread idx

block idx
block idx
block idx

magic shift
sup h

zigzag back forth improv cach perf

sup w

superblock
shl h mask h shr h
shl w mask w shr w
mask n

shr n


dhwn mad16

beta






sb size mask n
sb bit mad16 sb size
sb mask 0xffffffff sb size sb bit
mask 0xffffffff sb bit

offset mad16 max lut size
size
jrst
jr tend jrst
jr tend mask n
jr tend sb size jr tend mask n

jrst jr tend

div16 jrst magic shift
mod16 jrst

div16 magic shift
mod16

div16 magic shift
mod16

prime
prime
prime
prime

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

div16 prime magic shift
mod16 prime
bound

bound jrst jrst bound bound bound bound

mask valid slice warp
ballot ballot bound

count total valid slice superblock
slice popc sb mask ballot

bound

count valid slice threadid
popc mask ballot

left msub16
left msub16
left msub16
left msub16

imin imin left imin left
imin imin left imin left
imin imin left imin left
imin imin left imin left

total

lut entri entri
entri slice mpqn mad16
entri total total

offset size entri data2

size slice
jrst sb size


intermedi



jrst


jrst max lut size

lut entri entry0
lut entri entry1
lut entri entry2
lut entri entry3

offset mad16 max lut size jrst

entry0 data2 offset
entry1 data2 offset
entry2 data2 offset
entry3 data2 offset

jrst size entry0 slice entry0
jrst size entry1 slice entry1
jrst size entry2 slice entry2
jrst size entry3 slice entry3

jrst

temp scale alpha beta
flag
temp

unrol
intermedi intermedi temp use

intermedi
atom



val prepar val clss
code code val
open pool
code
close
sourc modul code option fast math
kernel spool bprop overlap small n
kernel prepar clss
kernel

copyright 2016 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


fast
copyright 2015 microsoft
licens licens fast rcnn licens detail
written ross girshick

pycuda compil sourc modul
pycuda tool context depend memoiz


cuda kernel pool layer
there fprop bprop
fprop bprop cuda code adapt fast model
each kernel use templat perform
convers work type current fp32 fp16 support



string2func funcnam clss

helper convert name call

funcnam fprop roipool
fprop roipool clss
funcnam bprop roipool
bprop roipool clss
attribut error kernel funcnam understood


thi section code contain templat cuda code kernel
context depend memoiz
fprop roipool clss

code
defin 402823466 e

fprop roipool nthread
roi count
channel height width
pool height pool width
bottom bottom roi
argmax spatial scale
index block idx block dim thread idx
index nthread index block dim grid dim
element pool output
index roi
index roi pool width
index roi pool width pool height
index roi pool width pool height

bottom roi
batch bottom roi
start round bottom roi spatial scale
start round bottom roi spatial scale
round bottom roi spatial scale
round bottom roi spatial scale

forc malform ro is
width start
height start
size cast height
cast pool height
size cast width
cast pool width

hstart cast floor cast
size
wstart cast floor cast
size
hend cast ceil cast
size
wend cast ceil cast
size

offset clip input boundari
hstart hstart start height
hend hend start height
wstart wstart start width
wend wend start width
hend hstart wend wstart

defin pool region zero
maxval
noth pool argmax caus noth backprop
maxidx

bottom height width count

hstart hend
wstart wend
bottom index width count count batch
bottom bottom index maxval
maxval bottom bottom index
maxidx bottom index



index maxval
argmax index maxidx
notic maxidx bottom index rel dimens
count featur valu





sourc modul code
kernel fprop roipool

kernel prepar
kernel


thi section code contain templat cuda code kernel
context depend memoiz
bprop roipool clss

code
bprop roipool nthread
roi count
channel height width
pool height pool width
diff bottom roi bottom diff
argmax spatial scale
index block idx block dim thread idx
index nthread index block dim grid dim
coord bottom featur
index count
index count width
index count width height
index count width height

gradient
accumul gradient ro is pool element
roi
offset bottom roi bottom roi
batch offset bottom roi
skip batch index match
batch



start round offset bottom roi spatial scale
start round offset bottom roi spatial scale
round offset bottom roi spatial scale
round offset bottom roi spatial scale

skip
start
start




offset pool height pool width roi
offset diff diff offset
offset argmax argmax offset

comput feasibl pool unit could pool
bottom unit

forc malform ro is
width start
height start

size cast height
cast pool height
size cast width
cast pool width

phstart floor cast start size
phend ceil cast start size
pwstart floor cast start size
pwend ceil cast start size

phstart phstart pool height
phend phend pool height
pwstart pwstart pool width
pwend pwend pool width

phstart phend
pwstart pwend
index pool width roi roi
bottom index width count count batch
offset argmax index bottom index
gradient offset diff index




bottom diff index gradient





sourc modul code
kernel bprop roipool

kernel prepar
kernel
copyright 2015 nervana system right reserv

licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens
pycuda compil sourc modul
pycuda tool context depend memoiz
neon backend cuda templat type
neon backend layer magic64


cuda kernel convolut layer thi code kernel
fprop bprop updat data format expect least
contigu dimens

input activ
filter
output activ

where
batch size
input featur map channel
output featur map
height width input featur
height width filter
height width output featur

current convolut support expect



context depend memoiz
conv kernel dtype filter size bsum oper filter bound check debug

build convolut kernel specifi filter size

argument
dtype dtype kernel oper
filter size total element filter
bsum kernel code comput
batch fprop
oper determin kernel build option follow
fprop forward propag activ
bprop backward propag error
updat comput gradient filter weight base error input
filter bound check check filter weight bound
multipl
debug when kernel compil debug symbol

oper fprop bprop updat
oper fprop oper updat
code





output pixel stride pad
output pixel stride pad

mask

filter size

filter filter
idiv magic32 magic shift filter filter

index filter
index filter

check index valid
bound index index index index
thread bound ballot bound

store lookup tabl entri
bound

int2 entri
entri index index
entri

index size local popc thread bound mask
lookup tabl index entri


size local popc thread bound





oper bprop
code





output pixel pad
output pixel pad

mask

filter size

filter filter
idiv magic32 magic shift filter filter

index filter
index filter

check index valid
bound index stride index stride
index stride
index stride
bound bound index index
index index
thread bound ballot bound

store lookup tabl entri
bound

int2 entri
entri index index
entri

index size local popc thread bound mask
lookup tabl index entri


size local popc thread bound





bsum
bsum code
local bsum result offset result offset
result offset result offset
atom add bsum filter local bsum


bsum code

oper updat
name imag
name error

oper fprop
name imag
name filter
oper bprop
name error
name filter

filter bound check
filter load cond filter load bound filter thread idx
check filter cond filter load bound make float4

filter load cond
check filter cond

header code
defin tile
defin item thread
defin thread

defin tile
defin tile
defin thread
defin thread
defin tile tile thread
defin tile tile thread

defin row
defin filter size filter size
defin magic filter size magic filter size
defin shift filter size shift filter size

matrix


matrix

devic idiv fast numer denomin
result remaind

result numer
remaind numer result denomin
result remaind denomin result result
remaind remaind denomin remaind denomin remaind


devic idiv magic numer magic shift
denomin result remaind

magic

result numer shift



res64 numer magic
result res64 shift

remaind numer result denomin


devic idiv magic32 numer magic shift
denomin result remaind

magic

result numer shift



result numer magic shift

remaind numer result denomin


note must multipl
block idx gemm tile dimens output pixel
block idx gemm tile dimens
thread idx gemm tile offset dimens
thread idx gemm tile offset dimens
conv oper
alpha beta
matrix matrix matrix bsum



stride stride pad pad
input channel size filter channel size
output filter size
output pixel grid grid
magic shift
magic shift
magic shift


code

share int2 lookup tabl filter size
share size
share matrix name row thread
share matrix name row thread

size local

todo squar access pattern imag increas cach hit
output pixel imag
idiv magic block idx magic shift output pixel imag output pixel
imag imag block dim

along axi increas cach hit
temp temp
idiv magic output pixel magic shift temp temp
output pixel temp temp temp
output pixel temp
output pixel output pixel output pixel

filter block idx block dim
thread idx thread idx block dim

offset buffer base thread
imag thread idx
filter thread idx

filter load cond

comput lookup tabl filter imag
code



size size local


syncthread

size local size
matrix result tile
output pixel output pixel
size local

evalu gemm outer product dimens inner product
size local

comput magic number divis size
reciproc size local

initi share first block
row



idiv fast thread idx size local reciproc

int2 entri thread idx make int2 lookup tabl
name thread idx thread idx
thread idx make float4
input channel size entri
name thread idx thread idx check filter cond
thread idx make float4
filter channel size entri

iter entir filter
row

syncthread

pragma unrol
row

matrix load
matrix load

load name thread idx
load name thread idx

accumul product
pragma unrol
offset offset tile offset

pragma unrol
offset offset tile offset

result offset offset load offset
load offset




syncthread

load imag filter weight
idiv fast thread idx size local reciproc

entri lookup tabl
name thread idx thread idx
input channel size entri
name thread idx thread idx
check filter cond filter channel size entri


syncthread

accumul product last iter
pragma unrol
row

matrix load
matrix load

load name thread idx
load name thread idx

accumul product
pragma unrol
offset offset tile offset

pragma unrol
offset offset tile offset

result offset offset load offset load offset





store result
filter filter thread idx
filter

imag thread idx

pragma unrol
offset offset offset

filter

index filter output filter size output pixel imag
bsum code

matrix valu
beta

valu index


result offset result offset alpha valu beta
result offset result offset alpha valu beta
result offset result offset alpha valu beta
result offset result offset alpha valu beta

index result offset

filter





updat code

share matrix name tile thread
share matrix name tile thread

todo squar access pattern imag increas cach hit
output pixel filter
idiv magic block idx magic shift output pixel filter output pixel
filter filter tile
load filter filter thread idx

filter pixel block idx tile

todo along axi increas cach hit
output pixel output pixel
idiv magic output pixel magic shift grid output pixel output pixel

comput input imag filter offset pixel

filter pixel thread idx
idiv magic magic filter size shift filter size filter size

filter filter
idiv magic32 magic shift filter filter

output pixel save output pixel
output pixel output pixel grid

output pixel output pixel save output pixel output pixel grid

output pixel stride pad filter
output pixel stride pad filter
bound

input pixel
output pixel output pixel output pixel

multipli offset simplifi index
input pixel input pixel
output pixel output pixel

evalu gemm outer product dimens inner product
matrix result item thread

load imag transpos share
todo share memori avoid bank conflict
matrix buffer
buffer bound
input channel size input pixel thread idx
make float4
name thread idx thread idx thread idx buffer
name thread idx thread idx thread idx buffer
name thread idx thread idx thread idx buffer
name thread idx thread idx thread idx buffer

load error transpos share
buffer load filter
load filter output filter size output pixel thread idx
make float4
name thread idx thread idx thread idx buffer
name thread idx thread idx thread idx buffer
name thread idx thread idx thread idx buffer
name thread idx thread idx thread idx buffer

iter entir minibatch
thread idx tile tile

syncthread

pragma unrol
tile

matrix imag
matrix error

imag
name thread idx thread idx
error
name thread idx thread idx

accumul product
pragma unrol
offset offset item thread offset

pragma unrol
offset offset item thread offset

result offset offset
imag offset error offset




syncthread

load imag transpos share
buffer bound
input channel size input pixel
make float4
name thread idx thread idx thread idx
buffer
name thread idx thread idx thread idx
buffer
name thread idx thread idx thread idx
buffer
name thread idx thread idx thread idx
buffer

load error transpos share
buffer load filter
load filter output filter size output pixel
make float4
name thread idx thread idx thread idx
buffer
name thread idx thread idx thread idx
buffer
name thread idx thread idx thread idx
buffer
name thread idx thread idx thread idx
buffer


syncthread

accumul product last iter
pragma unrol
tile

matrix imag
matrix error

imag name thread idx thread idx
error name thread idx thread idx

accumul product
pragma unrol
offset offset item thread offset

pragma unrol
offset offset item thread offset

result offset offset
imag offset error offset




reduc result thread warp
matrix outbound
warp thread idx
warp thread idx thread idx
buffer warp result
warp result
warp result
result

outbound warp result
warp result
warp result
result
buffer shfl outbound warp
buffer shfl outbound warp
buffer shfl outbound warp
buffer shfl outbound warp

outbound warp result
warp result
warp result
result
buffer shfl outbound warp
buffer shfl outbound warp
buffer shfl outbound warp
buffer shfl outbound warp

outbound warp result
warp result
warp result
result
buffer shfl outbound warp
buffer shfl outbound warp
buffer shfl outbound warp
buffer shfl outbound warp

store result
filter filter thread idx
filter bound

index filter channel size filter

atom add index buffer
atom add index buffer
atom add index buffer
atom add index buffer





oper updat
code header code updat code

code header code code

magic magic64 filter size

code code
filter size filter size
magic filter size magic
shift filter size magic
type dtype
code code
bsum code bsum code
oper oper
name name
name name
filter load cond filter load cond
check filter cond check filter cond


option fast math
debug oper bprop
option option
sourc modul code option option

kernel conv oper
kernel prepar ff ppppiiiiiiiiiiiiiiiiiiiiiiiiiiii
kernel name conv oper
kernel

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon nervana object


transform nervana object


base activ cost function deriv

init name
transform init name

call

comput
arg
tensor op tree input

return
func op tree comput output func

func

bprop

comput deriv
arg
tensor op tree input

return
funcgrad op tree comput deriv func

funcgrad

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon nervana object
numpi


cost nervana object


base cost function


call

appli cost

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
op tree return cost

func

bprop

comput deriv cost

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
op tree return deriv cost

funcgrad


metric cost


base metric

meant smooth cost want check valid


call

implement deriv class

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
return metric

not implement error

bprop

relev metric




cross entropi binari cost


appli binari cross entropi

note
bprop assum shortcut use calcul deriv


init scale

initi binari cross entropi

arg
scale amount scale backpropag error

scale scale

call

appli binari cross entropi cost

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
op tree return binari cross entropi cost

safelog
safelog
axi

bprop

comput shortcut deriv binari cross entropi cost

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
op tree return mean shortcut deriv binari entropi
cost shape

scale


cross entropi multi cost


appli multiclass cross entropi

note
bprop assum shortcut use calcul deriv


init scale usebit

initi multiclass cross entropi

arg
scale amount scale backpropag error
usebit whether display cost bit nat

cross entropi multi init
usebit usebit
scale scale
logscal usebit

call

appli multiclass cross entropi cost

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
op tree return multiclass cross entropi cost

logscal safelog axi

bprop

comput shortcut deriv multiclass cross entropi cost


arg
tensor op tree output previou layer model
tensor op tree target correspond

return
op tree return mean shortcut deriv multiclass
entropi cost shape

scale


sum squar cost


appli squar error cost


init

initi squar error cost function

func
squar axi
funcgrad


mean squar cost


appli mean squar error cost


init

initi mean squar error cost

func mean
squar axi
funcgrad shape


smooth l1 loss cost


smooth loss cost fast rcnn
http arxiv 1504 08083v2
loss less sensit outlier loss use rcnn


smooth l1
squar absolut
absolut absolut

smooth l1grad
absolut
absolut

init

initi smooth loss cost

func smooth l1 axi
funcgrad smooth l1grad


log loss metric


comput logloss


init
correct prob iobuf
metric name log loss

call calcrang slice

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
numpi return loss metric numpi
log loss

correct prob axi
correct prob safelog correct prob
correct prob calcrang mean


top k misclassif metric


comput logloss top1 topk misclassif error metric


init
correct prob iobuf
top1 iobuf
topk iobuf


metric name log loss top1 misclass misclass

call calcrang slice

comput misclassif error metric

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
numpi return metric numpi
log loss misclass misclass


correct prob axi
n slot correct prob axi
correct prob axi
topk n slot n slot n slot n slot
top1 axi correct prob
correct prob safelog correct prob
correct prob calcrang mean
top1 calcrang mean
topk calcrang mean


misclassif metric


comput misclassif error metric


init
pred iobuf
hyp iobuf
output pred contain record metric
metric name top1 misclass

call calcrang slice

comput misclassif error metric

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
return metric

convert back onehot compar
pred argmax axi
hyp argmax axi
output equal pred hyp

output calcrang mean


accuraci metric


comput accuraci metric


init
pred iobuf
hyp iobuf
output pred contain record metric
metric name accuraci

call calcrang slice

comput accuraci metric

arg
tensor op tree output previou layer model
tensor op tree target correspond

return
return metric

convert back onehot compar
pred argmax axi
hyp argmax axi
output equal pred hyp

output calcrang mean


precis recal metric

comput precis recal metric

argument
class number differ output class
binar option attempt convert model
output encod place
default
epsilon option smooth appli avoid divsion zero
default

init class binar epsilon
output class
token stat class
metric name precis recal
binar
iobuf dtype int32


epsilon

call

comput precis recal multi classif model

arg
tensor op tree output previou layer model assum
alreadi binar need
binar construct
tensor op tree target correspond assum
alreadi binar

return
ndarray return averag precis item recal item
valu statist remain output


argmax axi
onehot axi
posit
token stat axi

predict
token stat axi

target
token stat axi

precis
output token stat token stat


recal
output token stat token stat


output mean axi


object detect metric


comput deteciton metric includ label accuraci
bound regress


init
metric name accuraci smooth l1 loss
label
bbox

smooth l1
squar absolut
absolut absolut

call calcrang slice

comput detect metric

arg
tensor op tree output model like fast rcnn model element
label class batchsiz ro is
bound class bacthsiz ro is
tensor op tree target correspond element
label class batchsiz ro is
bound mask mask indic
real detect background object
bound
class bacthsiz ro is
bound mask
class bacthsiz ro is

return
numpi return metric numpi metric element


detect metric bbox shape
detect metric smooth l1 bbox
bbox
bbox axi

pred label shape
hyp label shape
label metric label shape

pred argmax label axi
hyp argmax label axi
label metric equal pred hyp

label metric calcrang mean
detect metric calcrang mean

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon transform activ ident explin rectlin softmax tanh
logist normal
neon transform cost cross entropi binari cross entropi multi
sum squar mean squar log loss
misclassif top k misclassif
accuraci precis recal smooth l1 loss
object detect

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon transform transform transform


ident transform
init name
ident init name

call


bprop



rectlin transform

re lu activ nair hinton icml 2010
option slope make leaki re lu
comput

init slope name
rectlin init name
slope slope

call
maximum slope minimum

bprop
greater slope less


explin transform

activ clevert unterthin hochreit iclr 2016 submiss

init alpha name
explin init name
alpha alpha

call
maximum alpha minimum

bprop
greater minimum alpha less


normal transform

normal input divisor

init name divisor
normal init name
divisor divisor

call
divisor

bprop



softmax transform

soft max activ
comput

init name epsilon
softmax init name
epsilon epsilon

call
reciproc
axi axi
axi

bprop



tanh transform

hyperbol tangent activ
comput

init name
tanh init name

call
tanh

bprop
squar


logist transform

logist sigmoid activ
comput

init name shortcut
initi logist base whether shortcut

arg
shortcut shortcut use
actual deriv return bprop


logist init name name

shortcut shortcut

shortcut shortcut
method bprop func shortcut
gradient need calcul

argument
shortcut shortcut use
actual deriv return bprop

shortcut shortcut

shortcut
bprop func

bprop func

call


bprop
return deriv logist sigmoid output
arg
tensor op tree input

return
op tree deriv logist sigmoid
return shortcut
return deriv shortcut


bprop func

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


neon nervana object
neon util persist load
numpi


param layer

return flatten

plist
layer
ptupl
plist extend ptupl isinst ptupl plist append ptupl
plist


optim nervana object


optim take param updat state
respons keep track schedul

init name
optim init name name

classmethod
pdict
schedul pdict
pdict schedul
scl load
sched scl pdict schedul config
pdict schedul sched
pdict

optim layer epoch
not implement error

clip gradient norm param clip norm

scale magnitud network gradient

argument
param layer paramet
clip norm option valu scale gradient
magnitud

scale factor
clip norm
grad grad param grad state param
grad squar sum squar grad grad grad
grad norm zero
grad norm sqrt grad squar sum
scale factor clip norm grad norm clip norm
scale factor

clip gradient valu grad clip valu

element wise clip gradient

argument
grad gradient singl layer
gradient clip valu option valu element wise clip
gradient
default

clip valu
clip grad clip valu clip valu

grad


schedul nervana object

learn rate schedul constant step learn rate

constant learn rate

init step config chang

argument
step config option configur epoch step rate
step time epoch indic default constant

chang option step mode learn rate
multipli chang step step
step step schedul pass chang
step config must also then step
learn rate chang


isinst step config isinst chang
step config chang chang step config must
length step config dedupl epoch level assign

step config step config
chang chang
step

learn rate learn rate epoch

current learn rate given epoch initi rate

argument
learn rate initi learn rate
epoch current epoch use calcul effect learn rate


isinst step config isinst chang
epoch step config
step store current
step chang step config index epoch
step
learn rate

step

isinst step config
step floor epoch step config

isinst step config
step epoch step config

learn rate chang step


exp schedul schedul

exponenti learn rate schedul

argument
decay much exponenti decay appli learn rate

init decay
decay decay

learn rate learn rate epoch
learn rate decay epoch


poli schedul schedul

polynomi learn rate schedul

argument
total epoch total epoch calcul interpol decay
power total decay paramet


init total epoch power
total epoch float32 total epoch
power power

learn rate learn rate epoch
learn rate epoch total epoch power


gradient descent momentum optim


stochast gradient descent momentum


init learn rate momentum coef stochast round
wdecay gradient clip norm gradient clip valu
name schedul schedul

argument
learn rate multipl coeffici updat
momentum coef coeffici momentum
stochast round option stochast
round
round nearest
width
stochast round note
affect
backend
wdecay option amount weight decay default
gradient clip norm option valu scale gradient
magnitud
default
gradient clip valu option valu element wise clip
gradient
default
name option optim layer pretti name
default
schedul neon optim optim schedul option learn
rate schedul default constant learn rate

gradient descent momentum init name name
learn rate momentum coef learn rate momentum coef
gradient clip norm gradient clip norm
gradient clip valu gradient clip valu
wdecay wdecay
schedul schedul
stochast round stochast round

optim layer epoch

appli learn rule layer updat state

argument
layer layer object optim
epoch current epoch need schedul

lrate schedul learn rate learn rate epoch
param param layer

scale factor clip gradient norm param gradient clip norm

param grad state param
param round stochast round
state momentum coef
state append zero like grad
grad grad
grad clip gradient valu grad gradient clip valu

momentum coef
veloc lrate scale factor grad wdecay param

veloc state
veloc veloc momentum coef
lrate scale factor grad wdecay param
param param veloc


rm prop optim


root mean squar propag


init stochast round decay rate learn rate epsilon
gradient clip norm gradient clip valu name
schedul schedul

argument
stochast round stochast round
round nearest
perform stochast round width
onli affect backend
decay rate decay rate state
learn rate multipl coeffic updat
epsilon smooth epsilon avoid divid zero
gradient clip norm option valu scale gradient
magnitud
default
gradient clip valu option valu element wise clip
gradient
default
schedul neon optim optim schedul option learn rate schedul
default constant
note
onli constant learn rate support current

rm prop init name name
state

epsilon epsilon
decay rate decay rate
learn rate learn rate
schedul schedul
gradient clip norm gradient clip norm
gradient clip valu gradient clip valu
stochast round stochast round

optim layer epoch

appli learn rule layer updat state

argument
layer layer object optim
epoch current epoch need schedul

lrate schedul learn rate learn rate epoch
epsilon decay epsilon decay rate
param param layer

scale factor clip gradient norm param gradient clip norm

param grad state param

param round stochast round
state
state append zero like grad

grad grad
grad clip gradient valu grad gradient clip valu

updat state
state state
state decay state squar grad decay

param param
scale factor grad lrate sqrt state epsilon epsilon


adagrad optim


ada grad learn rule updat duchi2011


init stochast round learn rate epsilon
gradient clip norm gradient clip valu name

argument
stochast round stochast round
round nearest
perform stochast round width
onli affect backend
learn rate multipl coeffic updat
epsilon smooth epsilon avoid divid zero
gradient clip norm option valu scale gradient
magnitud
default
gradient clip valu option valu element wise clip
gradient
default
note
onli constant learn rate support current

adagrad init name name
state
epsilon epsilon
learn rate learn rate
gradient clip norm gradient clip norm
gradient clip valu gradient clip valu
stochast round stochast round

optim layer epoch

appli learn rule layer updat state

argument
layer layer object optim
epoch current epoch need schedul

lrate epsilon learn rate epsilon
param param layer

scale factor clip gradient norm param gradient clip norm

param grad state param

param round stochast round
state
state append zero like grad

grad grad
grad clip gradient valu grad gradient clip valu

updat state
state state
state state squar grad
param param scale factor grad lrate sqrt state epsilon


adadelta optim


adadelta base learn rule updat
zeiler2012


init stochast round decay epsilon name

arg
stochast round stochast round
round nearest
perform stochast round width
onli affect backend
decay decay paramet adadelta
epsilon epsilon paramet adadelta

adadelta init name name
decay decay
epsilon epsilon
stochast round stochast round

optim layer epoch

appli learn rule layer updat state

argument
param tupl form param grad state
correspond paramet grad
state layer updat
epoch current epoch need schedul

epsilon decay epsilon decay

param param layer

param grad state param
param round stochast round

state
grad delt updat
state extend zero like grad rang

grad grad
state state decay decay grad grad
state sqrt state epsilon state epsilon grad
state state decay decay state state

param param state


adam optim


adam base learn rule updat http arxiv 1412 6980v8


init stochast round learn rate beta beta
epsilon name adam

arg
stochast round stochast round
round nearest
perform stochast round width
onli affect backend
learn rate multipl coeffici updat
beta adam paramet beta1
beta adam paramet beta2
epsilon numer stabil paramet

adam init name name
beta beta
beta beta
epsilon epsilon
learn rate learn rate
stochast round stochast round

optim layer epoch

appli learn rule layer updat state

argument
param tupl form param grad state
correspond paramet grad state layer updat
epoch current epoch need schedul

epoch
learn rate sqrt beta beta

param param layer

param grad state param
param round stochast round
state
run run
state extend zero like grad rang

grad grad
state
beta beta grad
beta beta grad grad

param param sqrt epsilon


multi optim optim


wrapper multipl optim within model


init optim map name


arg
optim map dict dictionari specifi map layer optim
layer name layer name attribut latter take
preced former finer layer layer control
name layer valu optim
layer optimizer1 bia optimizer2
special bia optimizer3 optimizer3 layer name
special bia optimizer2 bia layer optimizer1
layer

multi optim init name name
optim map optim map
optim map must specifi
optim layer optim map



classmethod
pdict
pdict optim map
optim
pdict optim map
ocl load
config pdict optim map
pdict optim map config
conf pdict optim map config
pdict optim map ocl conf
pdict

descript
desc modulenm
desc config optim map
optim map
desc optim map descript
desc config optim map desc
desc

optim layer

map optim correspond layer

dict
layer layer
classnam layer name
name layer name

name optim map
optim map name
classnam optim map
optim map classnam

optim map


layer

append layer


reset map map

pass optim map subsequ optim call
map refresh sinc recreat

optim map map


optim layer epoch

determin optim contain layer
appli optim function layer

note

recalcul optim map chang
train



optim layer


optim epoch

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon optim optim gradient descent momentum rm prop adagrad
adadelta adam schedul exp schedul poli schedul
multi optim

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

collect order dict
log

neon version neon version
neon nervana object
neon backend backend block
neon transform cross entropi binari logist
neon util persist load save load
neon util modeldesc model descript
neon layer sequenti activ tree singl output tree
numpi

logger log get logger name


model nervana object

basic model store layer describ model train layer
weight dataset evalu test serial mode
addit function ad callback function

argument
layer layer contain layer container
serial model descript
dataset iter data ignor remov
weight want recreat layer
state deseri serial model
descript default
name model name default model
optim optim optim defin learn rule
updat model paramet descent momentum ada delta


init layer dataset weight name model optim
model init name
optim optim
abl remov
state abl remov
epoch index
finish
initi
cost
nbatch
ndata

dataset
logger warn dataset deprec argument ignor

layer model descript dict
load model serial file dataset could
deseri layer load state weight
layer
load layer load state weight

wrap layer sequenti contain layer
layer sequenti tree singl output tree
layer layer

layer sequenti layer
layer propag parallel data

properti
layer optim
layer layer optim

shortcut
infer whether bprop shortcut use activ
cost otherwis noth
lastlay layer

cost costfunc cross entropi binari
lastlay activ
lastlay transform logist
lastlay transform shortcut

attribut except
thrown leav transform shortcut noth


initi dataset cost
initi


propag shape layer configur
prev input dataset
prev input layer configur prev input

cost
cost initi prev input
cost cost

alloc space
layer alloc
layer alloc delta
initi



string represent model layer

config network layer layer nest
config

dataset cost optim epoch callback

train model paramet dataset minim cost
gradient descent updat layer weight accord learn rule
defin optim

argument
dataset iter iter minibatch
element tupl input label
dimens featur size batch size
dimens label size batch size
length iter batch batch size
cost cost defin model minim base
output last layer input label
optim optim defin learn rule updat model paramet
epoch number time iter dataset
callback callback defin callback mini batch epoch

nbatch dataset nbatch
ndata dataset ndata
shortcut infer bprop shortcut use
total cost dtype float32
optim optim
initi dataset cost

callback train epoch
epoch index epoch finish
nbatch dataset nbatch

callback epoch epoch index

epoch dataset callback

callback epoch epoch index

epoch index

callback train

epoch dataset callback

helper perform train dataset epoch

argument
dataset iter dataset iter perform

epoch epoch index
total cost
iter minibatch dataset
enumer dataset
callback minibatch epoch
block minibatch

fprop

total cost total cost cost cost

delta back propag layer
everi layer revers
delta cost error

bprop delta
optim optim layer optim epoch epoch

block minibatch
callback minibatch epoch

divid total cost batch
never total cost averag
across minibatch train
total cost total cost dataset nbatch

fprop infer

forward propag minibatch model

argument
tensor input minibatch
infer flag perform train infer
onli affect batch norm dropout layer

return
tensor output layer model

layer fprop infer

bprop delta

back propag error minibatch model

argument
delta tensor deriv cost respect last layer output

layer bprop delta

dataset metric

evalu model dataset accord input metric

argument
dataset iter dataset evalu
metric cost evalu dataset

initi dataset
run error zero metric metric name dtype float32
nprocess
dataset reset
dataset
fprop infer

thi logic handl partial batch size dataset
nstep shape isinst
shape

dataset ndata nprocess
run error metric calcrang slice nstep nstep
nprocess nstep
run error nprocess
run error

output dataset

activ output model layer dataset

argument
dataset iter dataset iter perform

return
host numpi output layer entir dataset

initi dataset
dataset reset move pointer back begin dataset
dataset nbatch
layer layer output
isinst output branch termin
ypred
enumer dataset
fprop infer
ypred
dim0 dim1 shape
ypred dim1 dim0 dtype dtype
nstep dim1
batch slice dim1 dim1
ypred batch

handl recurr
nstep
nstep
ypred ypred reshap transpos copi reshap

ypred dataset ndata

descript weight keep state

get descript model requir reconstruct model
weight like yaml file

return
dict descript compon model

pdict dict
pdict neon version neon version
compat mode compat mode compat mode neon
pdict backend name
compat mode compat mode
seed seed
state state

cost
pdict cost cost descript
optim
pdict optim optim descript

pdict model layer descript weight weight
keep state keep state
pdict

save param path keep state

serial save model paramet path specifi

argument
param path file write serial paramet dict
keep state whether save optim state
default

serial keep state keep state param path

load param path load state

load model paramet layer weight epoch optim
state save param path serial

argument
param path file contain serial python dict layer
weight state
load state weight load
model layer alreadi
creat otherwis creat layer
serial paramet learn
state well

deseri load param path load state load state
logger info model weight load param path

load weight weight path

deprec
func load instead

logger warn call deprec load weight
load instead
load weight path

deseri model dict load state

load layer weight state model paramet
dictionari pass

argument
model dict dict dictionari describ model includ layer
cost optim backend set
gener serial
iter data ignor remov

load state weight load
model layer alreadi
creat otherwis creat layer
serial paramet learn
state well



logger warn deprec argument ignor

epoch index model dict
epoch index model dict epoch index
model model dict
logger error use model serial format
serial model format

param layer layer optim
param dict model dict layer state
param layer param dict

state load state
state


backend model dict
compat mode model dict backend
compat mode model dict backend compat mode

model dict backend

model dict model
main contain load

hasattr layer
layer main contain model dict model config

layer load weight model dict model load state

load state state model dict backend

state model dict backend state
valu error
could come switch backend type
logger warn problem restor exist state

serial tell write paramet learn
associ layer ignor layer
learn paramet model store state
optim save model infer
need rememb state
serial keep state

creat dictionari store layer paramet epoch complet

argument
file save format model dictionari
keep state whether save optim state

return
dict model includ layer paramet epoch complet


model dict weight
pdict descript weight keep state keep state
pdict epoch index epoch index
initi
pdict train input shape layer shape

save pdict

pdict

batch size

actual minibatch size eventhough buffer alloc consid
excess pad process layer shorten
current neon layer control process
someon want inform experi

layer batch size



actual minibatch sequenc length eventhough buffer alloc
consid excess pad process layer shorten
current neon layer control process
someon want inform experi

layer

benchmark dataset infer cost optim
niter nskip

measur runtim comput fprop bprop seper well
full minibatch time infer fprop

argument
dataset iter dataset iter perform

cost cost defin model minim base
output last layer input label

niter option number minibatch averag

nskip option iter begin skip
calcul runtim statist

return
dictionari fprop bprop time

initi model
infer
cost optim need cost optim
benchmark bprop updat
cost cost
initi dataset cost
optim optim
total cost
total cost

iter minibatch dataset
time order dict
time key fprop infer fprop bprop iter
time key
time full niter nskip
count

fprop start init mark
fprop init mark
bprop init mark

count niter nskip
dataset reset
enumer dataset

record mark fprop start mark start fprop

fprop

infer
total cost total cost cost cost

record mark fprop mark fprop start bprop

infer
delta cost error
bprop delta
optim optim layer optim epoch

record mark bprop mark bprop
synchron mark bprop

synchron mark fprop

time fprop count time fprop start fprop
infer
time bprop count time fprop bprop
time iter count time fprop count time bprop count

count
count niter nskip


result
header func mean median unit
stat tupl stat lower stat header

titl header
num func stat stat unit

head titl format header
head
head head
head
stat
step time
timesu time step nskip
stat step
stat stat
stat step stat getattr stat timesu
num format unit msec func step stat step

stat

copyright 2014 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon model model model

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon initi initi array
constant
gaussian
glorot uniform
ident init
kaim
orthonorm
uniform
xavier

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


numpi

neon nervana object
neon backend backend tensor


initi nervana object

abstract paramet tensor initi inherit

fill param
not implement error


constant initi

initi paramet tensor singl valu

arg
option valu assign tensor element

init name constant init
constant init name name


fill param
param


array constant

initi paramet tensor valu specifi
size

same function constant serial need dump
tensor valu

arg
val ndarray tensor option valu assign tensor element

descript
desc array descript
isinst desc config tensor
desc config desc config
desc


uniform initi

initi paramet tensor valu drawn
uniform distribut

arg
option lower bound rang draw valu
high option upper bound rang draw valu

init high name uniform init
uniform init name name
high high

fill param
param uniform high param shape


gaussian initi

initi paramet tensor valu drawn
normal distribut

arg
option mean normal
scale option standard deviat normal sigma

init scale name gaussian init
gaussian init name name
scale scale

fill param
param normal scale param shape


glorot uniform initi

initi paramet tensor valu drawn
uniform distribut region whose bound determin
polici describ
understand difficulti train deep feedforward neural network
http jmlr proceed paper glorot10a glorot10a

normal rang scale averag input dimens
output dimens tensor question

init name autouniform init
glorot uniform init name name

fill param
sqrt param shape param shape
param uniform param shape


xavier initi

altern form glorot input node use scale rang

arg
local option whether layer local convolut



init local name xavier
xavier init name name
local local

fill param
param shape local
scale sqrt
param uniform scale scale param shape


kaim initi

init local name kaim
kaim init name name
local local

fill param
param shape local
scale sqrt
param normal scale param shape


ident init initi
init local name ident
ident init init name name
local local

fill param
nout param shape
zero nout dtype float32

param


orthonorm initi

implement taken lasagn refer sax http arxiv 1312 6120


init scale name orthonorm
orthonorm init name name
scale scale

fill param
random normal param shape
linalg full matric
pick correct shape
shape param shape
param scale

thi minim singl layer implement adapt andrej karpathi
code minim charact level vanilla model licens
http gist github karpathi d4dee566867f8291f086

adapt includ
remov file
remov recurr output affin layer
remov sampl part
contain size weight
keep loss fun provid input error
initi weight bias main test script extern
initi weight bias
abl read hashabl valu compar anoth recurr
implement


numpi


recurr

init size hidden size
hidden size hidden size
size size
zero hidden size size input hidden
zero hidden size hidden size hidden hidden
zero hidden size hidden bia

loss fun input error

input error integ
return hidden state gradient model paramet



zero hidden size
input
zero hidden size
input shape

forward
xrang
matrix input
hidden state
tanh

flatten

backward comput gradient go backward
dhnext zero like
d wxh zero like
d whh zero like
zero like

error
zero like
dout zero

revers xrang
dhnext backprop

trace
backprop tanh nonlinear
dhraw multipli squar
dhraw
d wxh dhraw
d whh dhraw
dhnext dhraw
dout dhraw
dout dout flatten

d wxh d whh dout

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



gener gradient test appli pool layer


itertool
numpi
neon nervana object
neon layer layer pool
test grad func gener gradient comp


reset method layer class
use reset layer
run fprop bprop multipl time
produc repeat result
layer need defin
pool with reset pool
reset
nglayer


pytest gener test metafunc
main test gener
gener paramet combo
test base whether
option given test
option ad conftest

paramet
metafunc config option




poolarg metafunc fixturenam
farg
metafunc config option

nifm



nifm


farg product nifm
metafunc parametr poolarg farg


pool test
test pool backend cpu64 poolarg
nifm fshape batch size poolarg
nervana object nervana object batch size batch size
nifm batch size
epsilon
make sure perturnationc never chang element
arang epsilon
shuffl
random shuffl
reshap nifm batch size

lshape nifm
layer pool with reset fshape

pert frac test input
select pert frac fraction inp perturb
pert ceil size pert frac
pert ind random permut size pert

gener gradient comp layer

epsilon epsilon
lshape lshape
pert ind pert ind


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test lookup tabl layer often use word embed

itertool
numpi
neon backend backend
neon nervana object
neon initi initi glorot uniform
neon layer layer lookup tabl


pytest gener test metafunc
metafunc config option




basic linarg metafunc fixturenam
farg
metafunc config option

nout
vocab size 1000 2000


nout
vocab size
farg product nout vocab size
farg
metafunc parametr basic linarg farg


test lookupt zero error backend basic linarg
basic saniti check weight random input
nout batch size vocab size basic linarg
nervana object batch size

dtypeu float32

init glorot glorot uniform
layer lookup tabl
vocab size vocab size embed nout init init glorot

random random integ vocab size size batch size
layer configur
layer alloc
layer prev layer hack forc delta buffer alloc
layer delta layer iobuf

input layer reshap batch size
layer fprop input
layer
rang batch size


dtypeu zero nout batch size
layer bprop layer

layer





test lookupt one error backend basic linarg
nout batch size vocab size basic linarg
nervana object batch size

dtypeu float32

init glorot glorot uniform
layer lookup tabl
vocab size vocab size embed nout init init glorot

random random integ vocab size size batch size
layer configur
layer alloc
layer prev layer hack forc delta buffer alloc
layer delta layer iobuf

input layer reshap batch size
layer fprop input
layer
rang batch size


dtypeu one nout batch size
layer bprop layer

layer
unqidx count uniqu count
zero nout
unqidx count






test lookupt rand error backend basic linarg
nout batch size vocab size basic linarg
nervana object batch size

dtypeu float32

init glorot glorot uniform
layer lookup tabl
vocab size vocab size embed nout init init glorot

random random integ vocab size size batch size
layer configur
layer alloc
layer prev layer hack forc delta buffer alloc
layer delta layer iobuf

input layer reshap batch size
layer fprop input
layer
rang batch size


dtypeu random random nout batch size
layer bprop layer

layer
unqidx count uniqu count
zero nout
unqidx count


enumer



allclos atol rtol
allclos atol rtol





name main

farg

backend backend
datatyp float32
batch size
seed

test lookupt zero error farg

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



gener gradient test appli linear layer


itertool
numpi
neon nervana object
neon layer layer linear
neon initi initi gaussian
test grad func gener gradient comp


reset method layer class
use reset layer
run fprop bprop multipl time
produc repeat result
layer need defin
linear with reset linear
reset



pytest gener test metafunc
main test gener
gener paramet combo
test base whether
option given test
option ad conftest

paramet
metafunc config option




test
mlparg metafunc fixturenam
farg
metafunc config option

nout


nout

gener list
farg product nout

parameter call test function
mlparg argument
metafunc parametr mlparg farg


test backend cpu64 mlparg
nout batch size mlparg
gradient check
batch size batch size
nervana object nervana object batch size batch size

init gaussian
layer linear with reset nout nout init init
random randn batch size

epsilon
pert frac test input
select pert frac fraction inp perturb
pert ceil size pert frac
pert ind random permut size pert

gener gradient comp layer

epsilon epsilon
pert ind pert ind


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


thi test compar neon layer numpi refer
implement compar neon bprop delta gradient
estim finit differ
numpi refer contain method forward
backward
run singl layer compar numer valu

follow made sure gr us
initi valu zero
initi one random valu
input random matrix
input error random matrix
shape insid input size
need transpos
shape insid neon batch size batch size


itertool
numpi

neon nervana object
neon initi initi constant gaussian
neon layer
neon transform logist tanh
test ref gru
test util allclos


pytest gener test metafunc


refgruarg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr refgruarg farg

gradgruarg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr gradgruarg farg


test compar one backend refgruarg
comparison refer code
one init
input size hidden size batch size refgruarg
nervana object nervana object batch size batch size

check input size hidden size
batch size constant


test compar rand backend refgruarg
comparison refer code
one init
input size hidden size batch size refgruarg
nervana object nervana object batch size batch size

check input size hidden size batch size
gaussian


compar neon refer implement
check input size hidden size
batch size init func mom
init func initi model
mom mean random input
input shape input size batch size
output shape hidden size batch size
nervana object nervana object batch size batch size

neon
hidden size
init func
activ tanh
gate activ logist

gener random input tensor
random rand input shape mom mom
inpa
gener random delta tensor
delta random randn output shape

neon fprop
configur input size
prev layer
alloc
delta iobuf shape
fprop inpa

refer numpi
ref gru input size hidden size
wgru weight

make weight bias neon model
rang rang hidden size
rang rang hidden size hidden size
rang rang hidden size hidden size

wgru weight rang
wgru weight rang
wgru weight rang

wgru weight input rang
wgru weight input rang
wgru weight input rang

wgru weight recur rang
wgru weight recur rang
wgru weight recur rang

transpos input fprop
refer code expect shape
input shape input size batch size
output shape hidden size batch size
copi reshap
batch size input size swapax
delta delta copi reshap
batch size hidden size swapax

d wgru
loss fun
delta

verifi hidden state
allclos output

rtol
atol

fprop verifi

test bprop
make sure neon match numpi bprop
bprop delta
grab delta gradient buffer
d winput neon input
d wrecur neon recur
neon
d wxr neon d winput neon rang
d wxz neon d winput neon rang
d wxc neon d winput neon rang
d wrr neon d wrecur neon rang
d wrz neon d wrecur neon rang
d wrc neon d wrecur neon rang
neon neon rang
neon neon rang
neon neon rang

drzc neon rzhcan delta buffer
neon drzc neon rang
neon drzc neon rang
neon drzc neon rang

d wxr d wgru
d wxz d wgru
d wxc d wgru
d wrr d wgru
d wrz d wgru
d wrc d wgru
d wgru
d wgru
d wgru

verifi hidden delta
verifi delta
allclos neon

rtol
atol

verifi delta
allclos neon

rtol
atol

verifi hcan delta
allclos neon

rtol
atol

verifi updat input
d wxr
allclos d wxr neon
d wxr
rtol
atol
d wxz
allclos d wxz neon
d wxz
rtol
atol
d wxc
allclos d wxc neon
d wxc
rtol
atol

verifi updat recur

d wrr
allclos d wrr neon
d wrr
rtol
atol
d wrz
allclos d wrz neon
d wrz
rtol
atol
d wrc
allclos d wrc neon
d wrc
rtol
atol

verifi updat bia

allclos neon

rtol
atol

allclos neon

rtol
atol

allclos neon

rtol
atol

bprop verifi




reset
order fprop multipl time
gradient check test
variabl need
clear


output



test gradient neon backend gradgruarg
input size hidden size batch size gradgruarg
nervana object nervana object batch size batch size
gradient check input size hidden size batch size


gradient check input size hidden size batch size
threshold
threshold fraction differ
gradient estim
bprop delta
given layer paramet calcul
gradient compar deriv
obtain bprop
rang perturb
perturb size best result
thi necessari comput

minimum error
perturb grad diff
pert rang
need gener scale input outsid
issu random gener
gener insid gradient calc

input shape input size batch size
output shape hidden size batch size

rand scale random random output shape
random randn input shape

pert pert
grad delta gradient calc
input size
hidden size
batch size
epsilon pert
rand scale rand scale

grad delta
pert


reset seed model
allclos grad delta rtol atol
nervana object reset

check best valu worst error less threshold
worst error perturb pert
threshold threshold
threshold


gradient calc input size hidden size batch size
epsilon rand scale
nervana object nervana object batch size batch size

input shape input size batch size

gener input given

random randn input shape

neon
hidden size init gaussian activ tanh gate activ logist
inpa copi

fprop baselin input
configur input size
prev layer
alloc
delta iobuf shape
fprop inpa

random scale hash gener fake loss
rand scale
rand scale random random shape
loss would
loss rand scale

back prop rand scale error
copi avoid interact
delta neon bprop copi rand scale

perturb input element
grad zero inpa shape
pert copi
pert rang inpa size
save pert flat pert

pert flat pert save epsilon
reset
alloc
fprop pert

pert flat pert save epsilon
reset
alloc
fprop pert

calcul loss perturb
loss rand scale
loss rand scale
comput gradient estim
grad loss loss epsilon

grad flat pert grad

reset perturb input element
pert flat pert save


grad delta neon

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


convolut layer test

itertool
numpi
neon nervana object
neon layer layer convolut
neon initi initi uniform
test util allclos


pytest gener test metafunc
random seed
metafunc config option




zero convarg metafunc fixturenam
farg
metafunc config option

nofm


nofm
farg product nofm
metafunc parametr zero convarg farg

one convarg metafunc fixturenam
farg
metafunc config option

indim
nifm

stride
nofm

fargs1 product indim nifm nofm
stride

stride
fargs2 product indim nifm nofm
stride
farg chain fargs1 fargs2


indim
nifm

nofm
stride

farg product indim nifm nofm
stride
metafunc parametr one convarg farg

rand convarg metafunc fixturenam
farg
finfo float32
metafunc config option
indim
nifm

nofm

wrng
stride

fargs1 product indim nifm nofm
stride wrng

stride
fargs2 product indim nifm nofm
stride wrng
farg chain fargs1 fargs2

indim
nifm

nofm

stride
wrng

farg product indim nifm nofm
stride wrng
metafunc parametr rand convarg farg


test conv zero backend zero convarg
fshape nofm batch size zero convarg

nervana object batch size

basic saniti check weight random input
init unif uniform high
inshap
insiz prod inshap
neon layer convolut fshape fshape fshape nofm
stride pad init init unif
neon layer random random insiz batch size
lshape inshap
neon layer configur inshap
neon layer prev layer
neon layer alloc
neon layer delta neon layer iobuf inshap
neon layer fprop


zero shape
delta neon layer bprop neon layer
delta delta

neon layer




test conv one backend one convarg
dtypeu float32
indim nifm fshape nofm batch size stride one convarg
nervana object batch size

weight
init unif uniform high

inshap nifm indim indim
insiz prod inshap

neon layer convolut fshape fshape fshape nofm
stride stride pad init init unif
neon layer one insiz batch size
lshape inshap
neon layer configur inshap
neon layer prev layer
neon layer alloc
neon layer delta neon layer iobuf inshap
fprop
neon layer fprop

gener refer layer
layer conv layer ref
batch size
ident
inshap
inshap
fshape fshape
nofm
stride
dtypeu
pad
init weight one
layer weight one neon layer shape astyp dtypeu
layer fprop
layer copi
allclos atol rtol

gener
one shape astyp float32

bprop
neon layer bprop neon layer
neon layer

bprop
layer bprop astyp dtypeu

expect output updat uniform matrix
element ofmsiz batch size
updat layer updat

check neon layer
allclos updat atol rtol

delta complic sinc matrici
uniform go refer code directli
toler exact
layer berror nopad neon layer delta





test conv rand backend rand convarg
indim nifm fshape nofm batch size stride rand convarg
nervana object batch size

dtypeu float32
init unif uniform high

inshap nifm indim indim
insiz prod inshap

gener neon conv layer
neon layer convolut fshape fshape fshape nofm
stride stride pad init init unif

gener refer layer
layer conv layer ref
batch size
ident
inshap
inshap
fshape fshape
nofm
stride
dtypeu
pad

setup input rang
inpa random random insiz batch size
inpa
inpa
inpa inpa astyp dtypeu
neon layer inpa
lshape inshap

fprop neon
neon layer configur inshap
neon layer prev layer
neon layer alloc
neon layer delta neon layer iobuf inshap
neon neon layer fprop

pull neon weight layer weight
layer weight neon layer
layer fprop inpa
copi layer

estim numer precis
permut order layer
fprop calcul
layer fprop inpa permut
perm layer
atol perm

compar neon layer fprop output
empir determin atol
allclos neon atol atol rtol

gener random delta
erra random random neon shape
erra
erra

erra erra astyp dtypeu
neon layer erra

neon bprop
neon delta neon layer bprop
neon neon layer

code bprop
layer bprop erra
delta copi layer berror nopad
copi layer updat

estim precis permut
oper order layer code
layer bprop erra permut
delta perm layer berror nopad
perm layer updat

atol delta delta perm
allclos delta neon delta atol atol rtol

atol perm
allclos neon atol atol rtol



conv check code adapt
cnn8



ident



ident prime
one shape


prime func
func ident
ident prime


conv layer ref

init nifm ifmshap nopad fshape
nofm stride dtypeu pad
ident
ifmheight ifmwidth ifmshap nopad
ifmshap nopad ifmshap nopad
pad pad
ifmshap ifmheight pad ifmwidth pad
fshape fshape

stride stride
fheight fwidth fshape
ofmheight ifmshap fheight stride
ofmwidth ifmshap fwidth stride
ofmshap ofmheight ofmwidth
ifmsiz ifmshap ifmshap
ifmsiz nopad ifmshap nopad ifmshap nopad
ofmsiz ofmheight ofmwidth
nout ofmsiz nofm

nifm nifm
nofm nofm
fsize nifm fheight fwidth
weight zero nofm fsize dtype dtypeu

gprime prime
zero nout dtype dtypeu
zero nout dtype dtypeu
ofmstart rang ofmsiz nofm ofmsiz
ofmloc zero ofmsiz nofm dtype
rang ofmsiz
ofmloc ofmstart
figur connect previou layer
thi list
link
sfsize fheight fwidth use
makelink nifm ifmsiz ifmshap ofmshap fshape stride
updat zero weight shape dtype dtypeu
updateshard zero fheight fwidth
nofm fsize dtype dtypeu
updatebuf zero nofm fsize dtype dtypeu copi


bpropbuf zero fsize dtype dtypeu
berror zero ifmsiz nifm dtype dtypeu
berrorshard zero fheight fwidth
ifmsiz nifm dtype dtypeu

makelink nifm ifmsiz ifmshap ofmshap fshape stride
figur local connect previou layer
thi work dimens
ndim ifmshap
dimsiz ndim dtype int32
rang ndim
dimsiz prod ifmshap
link
ofmdim ndindex ofmshap
thi variabl track left corner
recept field
ofmdim
rang ndim
dimsiz ofmdim
stride
indlist rang fshape
rang ndim
indarray indlist
dimind rang fshape
indlist extend indarray dimind dimsiz
indarray indlist
rang nifm
indlist extend indarray ifmsiz
link append indlist
link link dtype int32

fprop input nopad permut
pad
pad
input input nopad astyp float32 copi

input nopad shape
nifm
extend ifmshap nopad
input nopad reshap
pad
input zero nifm ifmshap ifmshap
input
input input reshap astyp float32 copi
input input

rang ofmsiz
comput weight averag recept field
store result within destin featur
filter shot
rflink link
input rflink
weight
permut
ind random permut shape
ofmloc ind ind

ofmloc

bprop naiv error permut
rang ofmsiz
rflink link
error ofmloc
weight
permut
ind random permut shape
ind ind bpropbuf

bpropbuf
berror rflink bpropbuf

bprop error epsilon permut
input input

propag error backward
berror fill
bprop naiv error permut permut
bshp berror shape nifm ifmshap ifmshap
pad

clip pad neon comparison

berror nopad berror reshap bshp
berror nopad berror nopad reshap bshp copi

berror nopad berror copi

updat fill
rang ofmsiz
accumul weight updat go
correspond cell output featur map
rflink link
deltaslic error ofmloc

deltaslic
input rflink
permut
ind random permut shape
ind ind updatebuf

updatebuf
updat updatebuf

updat weight
multipli updat epsilon updat
skip updat weight delta
subtract weight updat weight

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



util function test

numpi
numpi random nprnd


spars rand shape frac round
gener input spars activ
input dimens lstm test
frac fraction matrix element
nonzero round
binari matrix element
either
prod shape
ind nprnd permut frac

draw frac random number
val nprnd random ind size

round
val ceil val
zero shape
flat ind val
ind


allclos atol rtol
allclos
fail stat
return
allclos rtol rtol atol atol


error thresh
median atol
amax argmax
worst flat amax flat amax
atol
error thresh
median rtol
amax argmax
worst flat amax flat amax



symallclos rtol
symetr rel allclos
check
divid
less equal rtol

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


log
numpi


neon nervana object
neon array iter load mnist
neon text text

log basic config level
logger log get logger


test dataset backend
train train test test nclass load mnist path

train array iter train train nclass nclass
train nervana object

rang
batch batch train
batch shape batch shape
train index


test text backend
text
lorem ipsum dolor amet consectetur adipis elit
eiusmod tempor incididunt labor dolor magna
aliqua enim minim veniam qui nostrud exercit
ullamco labori nisi aliquip commodo consequat
dui aut irur dolor reprehenderit volupt velit
ess cillum dolor fugiat nulla pariatur excepteur sint
occaecat cupidatat proident sunt culpa officia
deserunt mollit anim laborum

path test text
open path
write text

nervana object
time step
valid split

load pars charact level
train path valid path text creat valid file
path valid split valid split
train text time step train path
valid text time step valid path vocab train vocab

train nervana object
train

batch batch enumer train


char train index token
argmax batch axi tolist
first sent first batch contigu first sent
batch
batch rang
sent join char batch
start time step batch time step train nbatch
sent text start start time step
sent sent

valid start text valid split
batch batch enumer valid


char train index token
argmax batch axi tolist
batch rang
sent join char batch
start time step batch time step
valid nbatch valid start
sent text start start time step
sent sent

remov path
remov train path
remov valid path

thi minim singl layer implement adapt doctor teeth code
http github doctor teeth blob master

adapt includ
remov output affin transform
provid input forward error backward
initi weight bias zero main test script extern
initi weight bias
abl read hashabl valu compar anoth
implement


numpi




init size hidden size

thi

todo back initi
todo glorot initi
input weight
hidden size hidden size
size size

input candid
zero hidden size size
input reset
zero hidden size size
input interpol
zero hidden size size

recurr weight
hidden candid
zero hidden size hidden size
hidden reset
zero hidden size hidden size
hidden interpol
zero hidden size hidden size

bias
zero hidden size bia candid
zero hidden size bia reset
zero hidden size bia interpol

weight


use grad check clean
name

weight
weight
weight
weight
weight
weight
weight
weight
weight

loss fun input error

doe forward backward network input error
input vector length
error vector length


rbar zbar cbar

input
hidden

thi reset hidden state everi sequenc
todo mayb need
zero hidden size

input

zero hidden size

forward comput output index time
xrang
everi variabl vbar repres activ version
everi variabl qnext repres variabl time
understood context

input vector time
matrix input

gate modul much signal goe
candid
rbar

rbar
todo alreadi exist sigmoid

gate interpol candid
comput
zbar

zbar

candid comput use describ
cbar
multipli
tanh cbar

todo
one one like

comput interpol candid
multipli
multipli one

flatten

alloc space grad loss respect weight
d wxc zero like
d wxr zero like
d wxz zero like
d rhc zero like
d rhr zero like
d rhz zero like

alloc space grad loss respect bias
zero like
zero like
zero like

error receiv beyond sequenc
dhnext zero like
drbarnext zero like rbar
dzbarnext zero like zbar
dcbarnext zero like cbar
input zero like
input zero like

error
zero like
zero hidden size
zero hidden size
zero hidden size

backward time
revers xrang

everi variabl repres
variabl influenc multipl time step
weight multipl
time step

influenc cost way
interpol
multipli dhnext one

transform weight rbar
drbarnext

transform weight zbar
dzbarnext

transform weight cbar
multipli dcbarnext

error






multipli

backprop tanh
dcbar multipli one squar

multipli dcbar
multipli

backprop sigmoid
drbar multipli multipli one
dzbar multipli multipli one

d wxr drbar
d wxz dzbar
d wxc dcbar

d rhr drbar
d rhz dzbar
d rhc dcbar multipli

drbar
dcbar
dzbar

dhnext

drbarnext drbar
dzbarnext dzbar
dcbarnext dcbar

drbar flatten
dzbar flatten
dcbar flatten

d wxc d wxr d wxz d rhc d rhr d rhz















copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


log
numpi

pickl

neon backend backend
neon util argpars neon argpars extract valid arg
neon pascalvoc
neon dataset dataset

log basic config level
logger log get logger


test pascalvoc backend
http west amazonaw nervana pascal
filenam pascal
size 423982870

workdir filepath dataset valid path append filenam
path exist filepath
dataset fetch dataset filenam filepath size

open filepath handl
neon pickl load handl read

neon
batch neon batch
roi neon roi
dataset neon dataset
year neon year
output neon output
roi random sampl neon roi random sampl
shuffl neon shuffl

train pascalvoc dataset year path output output
batch batch roi roi
roi random sampl roi random sampl shuffl shuffl

batch imag
batch ro is
batch label
batch bbtarget
batch mask
batch batch enumer train

imag neon batch
imag neon batch

roi neon batch
roi neon batch roi

label neon batch
label neon batch label

bbtarget neon batch
bbtarget neon batch bbtarget

mask neon batch
mask neon batch mask

allclos imag neon imag atol rtol
allclos roi neon roi atol rtol
allclos label neon label atol rtol
allclos bbtarget neon bbtarget atol rtol
allclos mask neon mask atol rtol


name main

setup backend
parser neon argpars
arg parser pars arg
arg batch size

setup backend
backend extract valid arg arg backend
test pascalvoc arg

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



gener gradient test appli layer


itertool
numpi
neon nervana object
neon layer layer
test grad func gener gradient comp


reset method layer class
use reset layer
run fprop bprop multipl time
produc repeat result
layer need defin
lrn with reset
reset
nglayer


pytest gener test metafunc
main test gener
gener paramet combo
test base whether
option given test
option ad conftest

paramet
metafunc config option




lrnarg metafunc fixturenam
farg
metafunc config option

nifm



nifm

farg product nifm
metafunc parametr lrnarg farg


lrnorm backend cpu64 lrnarg
nifm fshape batch size lrnarg
nervana object nervana object batch size batch size
nifm batch size
epsilon
make sure perturb never chang element
arang epsilon
shuffl
random shuffl
reshap nifm batch size

lshape nifm
layer lrn with reset depth fshape ascal bpower

pert frac test input
select pert frac fraction inp perturb
pert ceil size pert frac
pert ind random permut size pert

gener gradient comp layer

epsilon epsilon
lshape lshape
pert ind pert ind



test larg backend cpu64
ad extra test larg locat
sensit small input

nifm
depth
batch size

nervana object nervana object batch size batch size
nervana object

shape nifm batch size
shape full nifm batch size


epsilon
random seed 1234

pert
pert2 ravel multi index pert shape full
pert pert2 pert

zero shape
pert
inpa

lshape shape full
layer lrn with reset depth depth ascal bpower

layer configur lshape
layer own delta
layer prev layer
layer alloc
layer delta layer iobuf shape

loss scale one inpa shape
layer fprop inpa
bprop delta layer bprop loss scale
bprop delta bprop delta pert

shift
copi
pert epsilon
copi
pert epsilon

layer fprop pert
layer fprop pert

grad epsilon
grad bprop delta
copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test activ function


math tanh tanh
numpi
neon nervana object
neon transform ident rectlin softmax tanh logist


compar tensor func input output deriv
nervana object
temp output shape
dtypeu float32
deriv
temp func bprop dtypeu input

temp func dtypeu input
cond temp output
cond prod output shape

ident



test ident backend
input reshap
output reshap
compar tensor ident input output


test ident deriv backend
input reshap
output one
compar tensor ident input output deriv

rectifi linear unit



test rectlin posit backend
input reshap
output reshap
compar tensor rectlin input output


test rectlin neg backend
input
output
compar tensor rectlin input output


test rectlin mix backend
input
output
compar tensor rectlin input output


test rectlin deriv posit backend
input reshap
output reshap
compar tensor rectlin input output deriv


test rectlin deriv neg backend
input
output
compar tensor rectlin input output deriv


test rectlin deriv mix backend
input
output
compar tensor rectlin input output deriv

leaki rectifi linear unit



test leaki rectlin posit backend
slope
input reshap
output reshap
compar tensor rectlin slope slope input output


test leaki rectlin neg backend
slope
input
output input slope
compar tensor rectlin slope slope input output


test leaki rectlin mix backend
slope
input
output slope
compar tensor rectlin slope slope input output


test leaki rectlin deriv posit backend
slope
input reshap
output reshap
compar tensor rectlin slope slope input output deriv


test leaki rectlin deriv neg backend
slope
input
output slope
compar tensor rectlin slope slope input output deriv


test leaki rectlin deriv mix backend
slope
input
output slope
compar tensor rectlin slope slope input output deriv

softmax



test softmax backend
input reshap
output input input
compar tensor softmax input output


test softmax deriv backend
input reshap
output one shortcut
compar tensor softmax input output deriv


tanh



test tanh backend
input reshap
output
tanh tanh tanh reshap
compar tensor tanh input output


test tanh deriv backend
input
tanh tanh tanh reshap
bprop output
output tanh
tanh
tanh reshap
compar tensor tanh input output deriv

logist



test logist backend
input reshap
output input
compar tensor logist input output


test logist deriv backend
bprop output
input reshap
input input
output input input
compar tensor logist shortcut
input output deriv

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


numpi

neon backend backend
neon array iter load mnist text
neon dataload load test
neon initi gaussian constant
neon layer gener cost affin
neon layer dropout conv pool sequenti merg multistream recurr
neon model model
neon optim gradient descent momentum
neon transform rectlin logist cross entropi binari


test model output backend

path load test path
text time step path path

weight initi
init constant

model initi
layer
recurr init activ logist
affin vocab init bia init activ rectlin


model model layer layer
output model output

output shape
ndata length nclass

sinc init constant model train
along featur valu
allclos output output rtol atol
allclos output output rtol atol

along time valu increas
alltru output output
alltru output output


test model setter backend

weight initi
init constant

model initi
layer
recurr init activ logist
affin init bia init activ rectlin


model model layer layer
model batch size
model


test model output backend
train train test test nclass load mnist path
train array iter train backend

init norm gaussian scale

layer affin nout init init norm bia init norm activ rectlin
affin nout init init norm activ logist shortcut
model layer layer

initi train
train
fprop
append copi
output vstack

train reset
output output train
allclos output output

test model benchmark infer
benchmark train infer niter


test model serial backend
train train test test nclass load mnist path

train array iter
train train train nclass nclass lshape

init norm gaussian scale

initi model
path1 sequenti conv init init norm bia constant activ rectlin
pool
affin nout init init norm bia init norm activ rectlin
path2 sequenti affin nout init init norm bia constant activ rectlin
dropout keep
affin nout init init norm bia init norm activ rectlin
layer merg multistream layer path1 path2 merg stack
affin nout init init norm batch norm activ rectlin
affin nout init init norm activ logist shortcut

save test model serial save pickl
model layer layer
optim gradient descent momentum learn rate momentum coef
cost gener cost costfunc cross entropi binari
initi train cost cost
test
epoch
train model epoch test batch
epoch rang epoch
enumer train
fprop
delta cost error
bprop delta
optim optim layer optim epoch epoch
test


expect output test batch state layer
output
pdict serial layer optim
enumer train
output append fprop infer
test


serial model
save save keep state

load model
model save

initi train
output
pdict serial layer optim
enumer train
output append fprop infer
test


check output state
output output output output
allclos output output

pdict pdict
state state
isinst batch norm

allclos

allclos


isinst batch norm

allclos
isinst ndarray
allclos



remov save

name main
backend backend batch size
test model setter
test model output nervana

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


convolut layer test

numpi
neon nervana object
neon layer sequenti conv merg sum skip node activ
neon initi initi gaussian ident init
neon transform rectlin
test util allclos

init1 gaussian scale
relu rectlin
batch size


conv fsize stride relu
dict fshape fsize fsize stride stride pad fsize
activ rectlin relu
init init1
batch norm



dict fshape stride pad activ init ident init


ident skip stride
mainpath conv conv stride stride
conv conv relu
sidepath skip node stride conv
merg sum mainpath sidepath
activ rectlin



project skip stride
mainpath conv conv stride stride
conv conv relu
sidepath skip node stride conv conv stride relu
merg sum mainpath sidepath
activ rectlin



factori copi modfunc stride name
modfunc stride

branch copi branch layer layer
branch copi layer branch layer

serial

layer layer layer layer


test skip noupsampl backend
nervana object

mergesum test config modfunc ident skip stride


test skip upsampl backend
nervana object

mergesum test config modfunc ident skip stride


test proj upsampl backend
nervana object

mergesum test config modfunc project skip stride


mergesum test config modfunc stride
conv conv
neon layer modfunc stride
inshap
insiz prod inshap
inpa random random insiz batch size

neon sequenti neon layer
neon configur inshap
inpa

neon alloc
neon layer nest
neon layer layer prev layer
neon alloc delta
neon neon fprop

make refer pathway
factori copi neon layer modfunc stride
conv conv
conv conv


lcopi lref
lcopi
lcopi lref serial

path1 sequenti
path2 sequenti
path1 path2
configur inshap
alloc
alloc delta

path1 fprop
path2 fprop
neon like
neon maximum

need bsum test valid
allclos neon neon rtol
fprop match
begin back prop
erra random random neon shape
erra

neon layer bprop
neon layer bprop
trunk neon

erra
greater neon

pstart

revers path1 layer pstart
bprop


revers path2 layer pstart
bprop

like


allclos trunk neon rtol


name main
test skip noupsampl

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test initi class

itertool
numpi

neon nervana object
neon initi initi array constant uniform gaussian glorot uniform


pytest gener test metafunc
arg metafunc fixturenam
farg
dim1
dim2
farg product dim1 dim2
metafunc parametr arg farg


test constant backend arg
nervana object
dim1 dim2 arg
shape dim1 dim2

wdev shape
init constant
init fill wdev
whost wdev
flat whost flatten
flat





test backend arg
nervana object
dim1 dim2 arg
shape dim1 dim2

wloc arang shape shape reshap shape
wdev shape

init array wdev
init fill wloc
equal wdev wloc



test uniform backend arg
nervana object
dim1 dim2 arg
shape dim1 dim2
wdev shape
uniform init uniform high
uniform init fill wdev
whost wdev
flat whost flatten
flat





test gaussian backend arg
nervana object
dim1 dim2 arg
shape dim1 dim2
wdev shape
gaussian init gaussian 10000 scale
gaussian init fill wdev
whost wdev
flat whost flatten
flat
robust test





test glorot backend arg
nervana object
shape
shape 1000 10000
wdev shape
wdev shape
glorot init glorot uniform
glorot init fill wdev
glorot init fill wdev
whost wdev
whost wdev
mean mean whost
mean mean whost
mean mean


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test cost function

itertool
numpi
neon nervana object
neon backend backend
neon transform cross entropi binari cross entropi multi sum squar
mean squar misclassif precis recal
smooth l1 loss


pytest gener test metafunc

farg metafunc fixturenam
farg
metafunc config option
shape1
shape2


shape1
shape2

farg product shape1 shape2
metafunc parametr farg farg


compar tensor func output deriv
nervana object
temp output shape
dtypeu float32
deriv
temp func bprop dtypeu dtypeu


temp func dtypeu dtypeu

ipdb ipdb trace
cond temp output
cond prod output shape


cross entropi binari



test cross entropi binari backend
output 0001 reshap
target reshap

expect maximum output
expect mlog maximum output
expect result target expect target expect mlog
keepdim
compar tensor cross entropi binari
output target expect result


test cross entropi binari limit backend
output 0001 reshap
target reshap

expect maximum output
expect mlog maximum output
expect result target expect target expect mlog
keepdim
compar tensor cross entropi binari
output target expect result


test cross entropi binari deriv backend
output 0001 reshap
target reshap
bprop assum shortcut
expect result output target output shape
compar tensor
cross entropi binari output target expect result deriv



cross entropi multi



test cross entropi multi backend
output 0001 reshap
target reshap

expect maximum output
expect result target expect axi keepdim
compar tensor cross entropi multi
output target expect result


test cross entropi multi limit backend
output 0001 reshap
target reshap

expect maximum output
expect result target expect axi keepdim
compar tensor cross entropi multi
output target expect result


test cross entropi multi deriv backend
output 0001 reshap
target reshap
expect result output target output shape
compar tensor cross entropi multi output target expect result
deriv


sum squar



test squar backend
output 0001 reshap
target reshap
expect result output target axi keepdim
compar tensor sum squar output target expect result


test squar limit backend
output 0001 reshap
target reshap
expect result output target axi keepdim
compar tensor sum squar output target expect result


test squar deriv backend
output 0001 reshap
target reshap
expect result output target output shape
compar tensor sum squar output
target expect result deriv


mean squar



test mean squar backend
output 0001 reshap
target reshap
expect result mean output target axi keepdim
compar tensor mean squar output target expect result


test mean squar limit backend
output 0001 reshap
target reshap
expect result mean output target axi keepdim
compar tensor mean squar output target expect result


test mean squar deriv backend
output 0001 reshap
target reshap
expect result output target output shape output shape
compar tensor mean squar output
target expect result deriv


misclassif



compar metric func output deriv
nervana object
dtypeu float32
temp func dtypeu dtypeu
cond temp output
cond prod output shape


test misclassif backend
nervana object
output

target
expect result one
compar metric misclassif
output target expect result


precis recal



test precis recal backend
nervana object

pred
target
expect result
compar metric precis recal pred target expect result


test precis recal binar backend
nervana object

pred


target


expect result
compar metric precis recal binar pred target
expect result


smooth loss



test smooth l1 random backend farg
farg
shape
magnitud
output random random shape magnitud
target random random shape
output target
expect result zero shape


expect result
expect result
expect result expect result axi keepdim
compar tensor smooth l1 loss output
target expect result
deriv


test smooth l1 zero backend farg
farg
shape
output zero shape
target zero shape
output target
expect result zero shape


expect result
expect result
expect result expect result axi keepdim
compar tensor smooth l1 loss output
target expect result
deriv


test smooth l1 one backend farg
farg
shape
output one shape
target one shape
output target
expect result zero shape


expect result
expect result
expect result expect result axi keepdim
compar tensor smooth l1 loss output
target expect result
deriv


test smooth l1 random deriv backend farg
farg
shape
magnitud
output random random shape magnitud
target random random shape
output target
expect result zero shape


expect result
expect result sign
compar tensor smooth l1 loss output
target expect result
deriv

name main
backend backend batch size
farg
test smooth l1 random farg
test smooth l1 random deriv farg

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

log
numpi

neon nervana object

log basic config level
logger log get logger


test dropout backend
nervana object
batch size

array2 random randn reshap dtype float32
error random randn reshap dtype float32
mask

logger info fprop
array2
array2 dropout array2
make binari mask mask keepthresh
array2 mask array2
array2

logger info bprop
error
error array2 error
error

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



gener gradient test appli batchnorm layer


itertool
numpi
neon nervana object
neon layer layer batch norm
test grad func gener gradient comp


reset method layer class
use reset layer
run fprop bprop multipl time
produc repeat result
layer need defin
batch norm with reset batch norm
reset
init name name


pytest gener test metafunc
main test gener
gener paramet combo
test base whether
option given test
option ad conftest

paramet
metafunc config option




test
bnarg metafunc fixturenam
farg
metafunc config option




gener list
farg product

parameter call test function
mlparg argument
metafunc parametr bnarg farg


test batchnorm backend cpu64 bnarg
batch size bnarg
nervana object nervana object batch size batch size

layer batch norm with reset
shape
size
isinst tupl
shape
size prod
random randn size batch size

epsilon
pert frac test input
select pert frac fraction inp perturb
pert ceil size pert frac
pert ind random permut size pert

gener gradient comp layer

epsilon epsilon
lshape shape
pert ind pert ind


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

numpi

neon optim schedul exp schedul


test step schedul backend

test constant rate step variou mode programm step

init

schedul constant learn rate
schedul
epoch rang
learn rate learn rate init epoch epoch
init

test uniform step schedul
step config
chang
schedul step config step config chang chang
epoch rang
learn rate learn rate init epoch epoch
test repeat call epoch
learn rate learn rate init epoch epoch
epoch
allclos init chang floor epoch step config
allclos init chang floor epoch step config

test step schedul
schedul step config chang
allclos learn rate learn rate epoch
allclos learn rate learn rate epoch
allclos learn rate learn rate epoch
test repeat call epoch
allclos learn rate learn rate epoch
allclos learn rate learn rate epoch
allclos learn rate learn rate epoch


test schedul backend

test exponenti learn rate schedul

init
decay
exp schedul decay
epoch rang
learn rate learn rate init epoch epoch
allclos init decay epoch

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


convolut layer test

numpi
neon nervana object
neon backend backend
neon layer sequenti conv pool branch node affin tree
neon initi initi gaussian constant
neon transform rectlin

init1 gaussian scale
relu rectlin
bia constant
common dict activ relu init init1 bia bia
commonp1 dict activ relu init init1 bia bia pad
commonp3s2 dict activ relu init init1 bia bia pad stride
pool2s1p1 dict fshape pad stride
batch size


make tree trunk branch1 branch2 alpha

make copi tree version
trunk layer config trunk
bnode branch node name bnode
branch1 layer config branch1
branch2 layer config branch2
tree trunk bnode branch1 bnode branch2 alpha

second copi share refer version
trunkb layer config trunk
branch1b layer config branch1
branch2b layer config branch2
trunkb branch1b branch2b


test branch model
nervana object backend batch size
nervana object
trunk layer conv config dict fshape common
layer pool config dict pool2s1p1
branch1 layer conv config dict fshape common
layer pool config dict pool2s1p1
layer affin config dict nout common
layer affin config dict nout init init1 activ relu
branch2 layer conv config dict fshape common
layer pool config dict pool2s1p1
layer affin config dict nout common
layer affin config dict nout init init1 activ relu

alpha
neon layer make tree trunk branch1 branch2 alpha

inshap
insiz prod inshap

forc bprop delta comput
inpa random random insiz batch size
inpa

neon layer configur inshap
neon layer alloc
neon layer alloc delta
neon neon layer fprop

layer sequenti sequenti sequenti
layer configur inshap
layer configur layer shape
layer configur layer shape
alloc layer
alloc delta layer

copi weight
layer layer layer layer layer layer layer
weight layer layer
neon weight layer neon layer layer optim
weight layer neon weight layer


forward prop
middl layer fprop
fprop middl layer

neon
differ
differ

back prop
erra random random shape neon
erra

input layer neon layer layer layer refer trunk root
input layer prev layer
input layer delta iobuf inshap

neon layer bprop
errp input layer delta

enumer layer
layer prev layer
inshap inshap layer shape
layer delta iobuf inshap

join iobuf layer shape
branch err bprop revers layer alpha
join branch err branch err

layer bprop join

differ errp
differ
differ


name main
test branch model

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test linear layer

itertool
numpi

neon nervana object
neon initi initi uniform
neon layer layer linear


pytest gener test metafunc
metafunc config option




basic linarg metafunc fixturenam
farg
metafunc config option
1023 1024 1025
nout 1023 1024 1025


nout
farg product nout
metafunc parametr basic linarg farg

allrand arg metafunc fixturenam
farg
finfo float32
weight rang

metafunc config option
2048 0e10

0e10
farg product
metafunc parametr allrand arg farg


test linear zero backend basic linarg
basic saniti check weight random input
nout batch size basic linarg
nervana object batch size

dtypeu float32

init unif uniform high
layer linear nout nout init init unif
layer dtypeu random random batch size
layer configur
layer prev layer hack forc delta buffer alloc
layer alloc
layer delta layer iobuf
layer fprop



dtypeu zero nout batch size
delta layer bprop layer
delta delta

layer





test linear one backend basic linarg
basic saniti check one input
weight check output
weight output
check confirm correct
oper
nout batch size basic linarg
nervana object batch size

dtypeu float32

init unif uniform high
layer linear nout nout init init unif
layer dtypeu one batch size
layer configur
layer prev layer hack forc delta buffer alloc
layer alloc
layer delta layer iobuf
layer fprop
layer
sum reshap nout one batch size

larger layer need estim numer precis
atol prec
allclos sum atol rtol
sum



test rand backend allrand arg
test random weight random input
dtypeu float32
rngmax allrand arg
rngmax
1024
nout 2048
batch size
nervana object batch size

init unif uniform high
layer linear nout nout init init unif
random random batch size


astyp dtypeu
layer configur
layer prev layer hack forc delta buffer alloc
layer alloc
layer delta layer iobuf
layer fprop layer
layer

expect output numpi


larger layer need estim numer precis
atol prec ntrial
allclos atol atol rtol
atol

random random nout batch size

astyp dtypeu
delta layer bprop layer
layer

delta
atol prec ntrial
allclos delta delta atol atol rtol
delta delta atol


atol prec ntrial
allclos atol atol rtol
atol




permut indici chang order comput
estim numer precis
rough estim
prec ntrial
float64
float64


trial rang ntrial
ind random permut shape
method give better estim precis toler
take
rang shape
rang shape
multipli ind ind


need scale comparison
ind ind
float32
save worst iter

need scale result
match multipli valu



copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


pool layer test

itertool
numpi
neon nervana object
neon layer layer pool
test util allclos


pytest gener test metafunc
random seed
metafunc config option




poolarg metafunc fixturenam
check pad need larg input
farg
metafunc config option


nifm




nifm

farg

stride
farg append product nifm stride
farg chain farg
metafunc parametr poolarg farg


pool shape fshape pad stride ncheck
given input tensor expect poll output
certain batch
lshape shape
shape
ncheck
check ind arang
ncheck
check ind random permut
check ind check ind ncheck

check ind ncheck
check ind sort check ind

lshape append
inpa reshap lshape
outshap lshape
output lshape fshape pad stride pool
output lshape fshape pad stride pool
check ind

pad
pad shape lshape
lshape pad
lshape pad
lshape
zero pad shape
pad pad pad pad inpa

inpa

zero outshap
ind c rang outshap
indh rang outshap
hrng indh stride indh stride fshape
indw rang outshap
wrng indw stride indw stride fshape
indb enumer check ind
check ind c hrng hrng wrng wrng indb
ind c indh indw check
check ind


test pad backend poolarg
fshape nifm pad stride batch size poolarg

nervana object batch size

basic saniti check random input
inshap nifm
insiz prod inshap
neon layer pool fshape fshape stride stride pad pad

neon layer random random insiz batch size
lshape inshap
neon layer configur inshap
neon layer prev layer
neon layer alloc
neon layer delta neon layer iobuf inshap

neon layer fprop

ncheck batch size batch size

check ind pool lshape
fshape fshape
pad
stride stride
neon layer
ncheck ncheck

shape shape
shape append batch size
outa reshap shape

allclos outa check ind atol rtol

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test bi lstm layer

itertool
numpi

neon nervana object
neon initi initi glorot uniform
neon layer recurr bi lstm lstm step
neon transform logist tanh
numpi concaten


pytest gener test metafunc


farg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr farg farg


test bi lstm fprop backend farg

basic saniti check weight random input
input size hidden size batch size farg
shape input size
shape hidden size
nervana object batch size

setup direct
init glorot glorot uniform
bilstm bi lstm hidden size gate activ logist
activ tanh init init glorot reset cell
bilstm configur shape
bilstm prev layer
bilstm alloc
bilstm delta bilstm iobuf bilstm shape

setup direct
init glorot glorot uniform
lstm hidden size gate activ logist
activ tanh init init glorot reset cell
configur shape
prev layer
alloc
delta iobuf shape

weight backward weight
nout hidden size
bilstm input bilstm input
bilstm recur bilstm recur
bilstm bilstm
bilstm
input bilstm input
recur bilstm recur
bilstm


input random flip left right input
random random input size batch size
revers step copi shape

axi
bilstm
bilstm


output
bilstm fprop copi
bilstm buffer
bilstm fprop
fprop copi

view
step nout shape
step nout shape
step nout shape
step nout shape
step shape

assert fprop

revers revers
allclos rtol atol
allclos rtol atol
allclos rtol atol
allclos rtol atol


test bi lstm fprop backend farg

basic saniti check weight random input
input size hidden size batch size farg
shape input size
shape hidden size
nervana object batch size

setup direct
init glorot glorot uniform
bilstm bi lstm hidden size gate activ logist init init glorot
activ tanh reset cell
bilstm configur shape
bilstm prev layer
bilstm alloc
bilstm delta bilstm iobuf bilstm shape

weight
nout hidden size
bilstm input bilstm input
bilstm recur bilstm recur
bilstm bilstm
bilstm

input random flip left right input
random random input size batch size
revers step copi shape

axi
bilstm
bilstm

output
bilstm fprop copi

bilstm buffer
bilstm fprop copi

view
step nout shape
step nout shape
step nout shape
step nout shape

assert

revers revers
allclos rtol atol
allclos rtol atol


test bi lstm bprop backend farg

basic saniti check weight random input
input size hidden size batch size farg
shape input size
shape hidden size
nervana object batch size

setup direct
init glorot glorot uniform
bilstm bi lstm hidden size gate activ logist
activ tanh init init glorot reset cell
bilstm configur shape
bilstm prev layer
bilstm alloc
bilstm delta bilstm iobuf bilstm shape

weight backward weight
nout hidden size
bilstm input bilstm input
bilstm recur bilstm recur
bilstm bilstm
bilstm

input view
random random input size batch size
revers step copi shape
axi

alloc buffer
bilstm
bilstm

output
bilstm fprop
copi
bilstm bprop copi
bilstm buffer
bilstm fprop
copi
bilstm bprop copi

view
step nout shape
step nout shape
step nout shape
step nout shape

assert

revers revers
allclos rtol atol
allclos rtol atol

step shape
step shape

revers
allclos rtol atol

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


convolut layer test

numpi
neon nervana object
neon layer sequenti conv pool merg broadcast affin
neon initi initi gaussian constant
neon transform rectlin softmax
test util allclos

init1 gaussian scale
relu rectlin
bia constant
common dict activ relu init init1 bia bia
commonp1 dict activ relu init init1 bia bia pad
commonp3s2 dict activ relu init init1 bia bia pad stride
pool3s1p1 dict fshape pad stride
batch size


fshape



incept kval name
kval

branch1 sequenti conv fshape common
branch2 sequenti conv fshape common
conv fshape commonp1
branch3 sequenti pool pool3s1p1
conv fshape common
partit branch1 branch2 branch3
merg broadcast layer partit merg depth


incept bare kval name
kval
branch1 conv fshape common
branch2 conv fshape common conv fshape commonp1
branch3 pool pool3s1p1
conv fshape common

branch1 sequenti branch1
branch2 sequenti branch2
branch3 sequenti branch3

branch1 branch2 branch3 layer


branch1 layer branch1 layer



branch2 layer branch2 layer




branch3 layer branch3 layer



branch1 layer branch2 layer branch3 layer


main branch
conv fshape commonp3s2
pool fshape stride pad
conv fshape commonp1
pool fshape stride pad


branch
pool fshape stride
affin nout init init1 activ softmax bia bia


test branch model backend
random seed
nervana object

main1 main branch
incept
branch
neon layer sequenti main1

inshap
insiz prod inshap
inpa random random insiz batch size
neon layer configur inshap
neon layer inpa

neon layer alloc
neon layer nest
neon layer layer prev layer
neon layer alloc delta
neon layer layer delta iobuf inshap
neon neon layer fprop

make refer pathway
main trunk2 sequenti main branch
main trunk2 configur inshap
main2 main trunk2 layer
main2 prev layer
main2 delta iobuf inshap
incept bare


oshap inshap
main2
oshap configur oshap

main1 trunk neon layer layer
main2 main1 trunk


alloc
delta iobuf shape


alloc
delta iobuf shape

creat combin output buffer
merg output like neon layer layer output


main2
fprop

start



fprop
start shape
merg output start
start

merg output

trunk sequenti layer
trunk
fprop

neon
allclos neon neon rtol

begin back prop
erra random random neon shape
erra
revers neon layer layer
bprop

neon delta
errb neon layer layer error view
revers
errb bprop errb

delta root branch layer compar
delta zero like delta
delta delta delta delta

neon delta delta

allclos neon delta neon delta rtol


test branch model fork backend
neon layer branch node tree
random seed
nervana object

bnode branch node
incept
top1 branch
top2 branch
sequenti main branch bnode top1
bnode top2

alpha2
neon layer tree alpha alpha2

inshap
insiz prod inshap
inpa random random insiz batch size
neon layer configur inshap
neon layer inpa

neon layer alloc
neon layer nest
neon layer layer layer prev layer
neon layer alloc delta
neon layer layer layer delta iobuf inshap
neon neon layer fprop
neon neon

make refer pathway
main trunk2 sequenti main branch
main trunk2 configur inshap
main2 main trunk2 layer
main2 prev layer
main2 delta iobuf inshap

branch2 sequenti branch
lbranch2 branch2 layer
incept bare

lbranch2
oshap inshap
main2
oshap configur oshap

main1 trunk neon layer layer layer
main2 main1 trunk


alloc
delta iobuf shape

lbranch2 neon layer layer layer



lbranch2

alloc
delta iobuf shape

creat combin output buffer
merg output like neon layer layer layer output


main2
fprop
main2

start

main2

fprop
start shape
merg output start
start

merg output

trunk sequenti top1 layer
trunk
fprop

neon
allclos neon neon rtol

second branch
neon ref2 branch2 fprop main2
allclos neon ref2 neon

begin back prop
erra random random shape neon
erra
neon layer layer layer delta iobuf inshap
neon layer bprop

bottom neon delta neon layer layer layer delta
middl neon delta neon layer layer layer delta

err0
revers trunk
err0 bprop err0

err1
revers lbranch2
err1 bprop err1

errb neon layer layer layer error view
revers
errb bprop errb

delta root branch layer compar
delta zero like delta
delta alpha2 lbranch2 delta
delta delta delta delta delta
neon delta delta
allclos middl neon delta neon delta rtol

delta
main2 delta iobuf inshap

revers main2
bprop

bottom neon delta main2 delta
allclos bottom neon delta bottom neon delta rtol


name main
test branch model fork

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



gener gradient test appli bia layer


itertool
numpi
neon nervana object
neon layer layer bia
neon initi initi gaussian
test grad func gener gradient comp


reset method layer class
use reset layer
run fprop bprop multipl time
produc repeat result
layer need defin
bia with reset bia
reset



pytest gener test metafunc
main test gener
gener paramet combo
test base whether
option given test
option ad conftest

paramet
metafunc config option




test
biasarg metafunc fixturenam
farg
metafunc config option




gener list
farg product

parameter call test function
mlparg argument
metafunc parametr biasarg farg


test bia backend cpu64 biasarg
batch size biasarg
nervana object nervana object batch size batch size
init gaussian
layer bia with reset init init
random randn batch size

epsilon
pert frac test input
select pert frac fraction inp perturb
pert ceil size pert frac
pert ind random permut size pert

gener gradient comp layer

epsilon epsilon
lshape shape
pert ind pert ind


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


itertool
numpi

neon nervana object
neon layer deconvolut
neon initi uniform


pytest gener test metafunc
metafunc config option




zero convarg metafunc fixturenam
farg
metafunc config option





farg product
metafunc parametr zero convarg farg

one convarg metafunc fixturenam
farg
metafunc config option
indim
nifm

nofm

indim
nifm

nofm
farg product indim nifm nofm
metafunc parametr one convarg farg

rand convarg metafunc fixturenam
farg
finfo float32
metafunc config option
indim
nifm

nofm
1e10
wrng

indim
nifm

nofm

wrng
farg product indim nifm nofm
wrng
metafunc parametr rand convarg farg


test dconv zero backend zero convarg
fshape nofm batch size zero convarg
nervana object batch size

dtypeu float32
init unif uniform high
inshap
insiz prod inshap
neon layer deconvolut fshape fshape fshape nofm
stride
pad
init init unif
shape insiz batch size
random random shape astyp dtypeu
neon layer
lshape inshap
neon layer configur inshap
neon layer prev layer
neon layer alloc
neon layer delta neon layer iobuf inshap

outa neon layer fprop
outa


dtypeu zero outa shape
delta neon layer bprop nervana object
delta delta

neon layer




test dconv one backend one convarg
indim nifm fshape nofm batch size one convarg
nervana object batch size
dtypeu float32

weight
init unif uniform high

inshap nifm indim indim
insiz prod inshap

neon layer deconvolut fshape fshape fshape nofm stride
pad init init unif
neon layer one insiz batch size astyp dtypeu
lshape inshap
fprop
neon layer configur inshap
neon layer prev layer
neon layer alloc
neon layer delta neon layer iobuf inshap
neon layer fprop
nifm
fshape fshape nifm

gener
one shape astyp dtypeu

bprop
neon layer bprop nervana object
neon layer

gener refer layer
layer deconv ref layer batch size ident inshap inshap
fshape fshape nofm dtypeu

layer weight one neon layer shape astyp dtypeu

bprop
layer bprop

expect output updat uniform matrix
element ofmsiz batch size
updat layer ofmsiz batch size

check neon layer
updat updat

toler exact
layer neon layer delta




test dconv rand backend rand convarg
indim nifm fshape nofm batch size rngmax rand convarg
nervana object batch size
dtypeu float32
rngmax

init unif uniform high
inshap indim indim nifm
insiz prod inshap

gener neon deconv layer
need nofm
neon layer deconvolut fshape fshape fshape nofm stride
pad init init unif
insiz prod inshap

gener refer deconv layer
layer deconv ref layer batch size ident inshap inshap
fshape fshape nofm dtypeu

setup input rang
inpa random random insiz batch size
inpa
inpa
inpa inpa astyp dtypeu
neon layer inpa
lshape inshap

fprop neon
neon layer configur inshap
neon layer prev layer
neon layer alloc
neon layer delta neon layer iobuf inshap
neon neon layer fprop
pull neon weight layer weight
layer weight neon layer
copi layer berror

estim numer precis
layer fprop inpa permut
out2 layer berror
atol out2
allclos neon atol atol rtol
neon atol

gener
erra random random neon shape
erra
erra
erra erra astyp dtypeu



deconv check code adapt
cnn8 current stride



ident



ident prime
one shape


prime func
func ident
ident prime


deconv ref layer
what pass

init nifm ifmshap fshape nofm stride dtypeu
ident
swap
ofmshap ifmshap
ofmheight ofmwidth ifmshap
fheight fwidth fshape
ifmheight ofmheight stride fheight
ifmwidth ofmwidth stride fwidth
nifm nofm
nofm nifm

ifmshap ifmheight ifmwidth
ifmsiz ifmheight ifmwidth
ofmsiz ofmheight ofmwidth
nout ofmsiz nofm
fsize nifm fheight fwidth
weight zero nofm fsize dtype dtypeu

gprime prime
zero nout dtype dtypeu
zero nout dtype dtypeu
ofmstart
rang ofmsiz nofm ofmsiz
ofmloc zero ofmsiz nofm dtype
rang ofmsiz
ofmloc ofmstart

link
makelink nifm ifmsiz ifmshap
ofmshap fshape stride
updat zero weight shape dtype dtypeu
updateshard zero
fheight fwidth nofm fsize dtype dtypeu
updatebuf zero nofm fsize dtype dtypeu


bpropbuf zero fsize dtype dtypeu
berror zero
ifmsiz nifm dtype dtypeu
berrorshard zero
fheight fwidth ifmsiz nifm dtype dtypeu

makelink nifm ifmsiz ifmshap ofmshap fshape stride
ndim ifmshap
dimsiz ndim dtype int32
rang ndim
dimsiz prod ifmshap
link
ofmdim ndindex ofmshap
ofmdim
rang ndim
dimsiz ofmdim
stride
indlist rang fshape
rang ndim
indarray indlist
dimind rang fshape
indlist extend indarray dimind dimsiz
indarray indlist
rang nifm
indlist extend indarray ifmsiz
link append indlist
link link dtype int32

note repres delta
bprop error permut
rang ofmsiz
rflink link
error rflink
weight
permut
ind random permut shape
ofmloc ind ind

ofmloc

note berror output
fprop input permut

berror fill
rang ofmsiz
rflink link
input ofmloc
weight
permut
ind random permut shape
ind ind bpropbuf

bpropbuf
berror rflink bpropbuf

updat fill
rang ofmsiz
accumul weight updat go
correspond cell output featur map
rflink link
deltaslic input ofmloc

deltaslic
input rflink
permut
ind random permut shape
ind ind updatebuf

updatebuf
updat updatebuf

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test merg layer linear layer

itertool
numpi

neon nervana object
neon initi initi uniform
neon layer affin merg multistream sequenti


pytest gener test metafunc
farg
finfo float32
weight rang


farg product
metafunc parametr allrand arg farg


test concat backend allrand arg
test linear layer merg concat
dtypeu float32
rngmax allrand arg
diff size input output
nin 1024
nout 2048
batch size
nervana object batch size
nervana object

init unif uniform high
layer sequenti affin nout nout init init unif nout nout
input dtypeu random random batch size nin
merg merg multistream layer merg stack
input layer
merg configur input
merg alloc
merg delta
merg fprop input

sublay layer layer
weight layer layer sublay
concaten weight input

allclos atol

dtypeu random random nout batch size nout nout
concat concaten
merg bprop concat
input

layer sublay
allclos layer



test concat sequenc backend allrand arg
test linear layer merg concat
dtypeu float32
rngmax allrand arg
diff size input step

step
nout
batch size
nervana object batch size
nervana object

init unif uniform high
layer sequenti affin nout nout init init unif rang
input dtypeu random random batch size step
step step
merg merg multistream layer merg recurr
input layer
merg configur input
merg alloc
merg delta
merg fprop input

sublay layer layer
weight layer layer sublay
concaten weight input axi

allclos atol

dtypeu random random nout batch size step step step
concat concaten axi
merg bprop concat
input

layer sublay
allclos layer


copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



gener gradient test appli differ layer activ

numpi


sweep epsilon layer pert shape lshape
pert frac
sweep given perturb pert
perturb magnitud gave best
match brop delta finit diff grad

shape
output shape provid
run fprop
inpa layer copi
shape lshape lshape inpa shape
layer configur shape
shape layer shape

gener loss scale outsid
model state reset comput
repeat reason first
repeat loss scale gener insid
gener gradient comp
loss scale random random shape

select pert frac fraction inp perturb
pert ceil inpa size pert frac
pert ind random permut inpa size pert

layer reset reset initi state

diff
pert
epsilon diff
epsilon pert
gener gradient comp layer

epsilon epsilon
loss scale loss scale
lshape lshape
pert ind pert ind
layer reset reset initi state
diff diff
diff
pert epsilon
epsilon
diff pert diff pert
pert diff


gener gradient comp layer

epsilon
loss scale
lshape
pert ind
given layer test bprop
finit differ

neon fprop
layer reset
inpa layer copi
shape lshape lshape inpa shape
layer configur shape
layer own delta
layer prev layer
layer alloc
layer delta layer iobuf shape
layer fprop inpa

shape shape

scale random matrix
loss scale
loss scale random random shape

loss
loss loss scale

bprop input delta rand scale
bprop delta layer bprop layer loss scale copi




pert copi
pert ind
pert ind rang size
pert pert ind
save pert flat pert
subtract perturb input
pert flat pert save epsilon
fprop perturb input
layer reset
layer configur shape
layer alloc
inpa layer pert copi
layer fprop inpa copi

pert flat pert save epsilon
inpa layer pert copi
layer reset
layer configur shape
layer alloc
layer fprop inpa copi

calcul loss output
loss loss scale
loss loss scale
grad loss loss epsilon

reset input
pert flat pert save

bprop bprop delta flat pert

grad bprop


val grad bprop

grad bprop


grad bprop


val grad bprop

worst diff val grad bprop
val
val
worst diff val grad bprop
val
val

python
script run exampl check
without throw except


glob glob
subprocess subp

modifi follow suit environ
epoch
backend
subset
addit arg

base data nervana
batch path join base data macrobatch
cifar batch path join base data cifar10 macrobatch

skip exampl singl gtx970
file skip timeseri lstm fast rcnn alexnet
msra
batch alexnet imagenet allcnn
msra
cifar batch cifar10 msra
subset batch cifar batch

jenkin environ setup
getenv executor number
base data local jenkin
batch path join base data macrobatch
cifar batch path join base data cifar10 macrobatch
addit arg format getenv executor number

path isdir exampl
io error must root none repo

check venv activ
virtual
subp call shell
io error need activ virtualenv

exampl glob exampl
exampl append exampl babi train

result
exampl

path basenam
file skip
skip exampl

cmdarg progress format
epoch backend path splitext
addit arg
python format cmdarg

batch
format batch
cifar batch
format cifar batch

format base data

subset
subset format subset
subp call shell

result append


error
result

failur format
error
error

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test pool layer

itertool
numpi

neon backend backend
neon nervana object
timeit timer timeit

spatial scale


fprop slice stride offset

slice dimens
index pool output index
stride
input
offset hstart

hstart floor stride
hend ceil stride

hstart hstart offset
hend hend offset

slice hstart hend hend hstart


pytest gener test metafunc

farg metafunc fixturenam
farg





size
farg product
size
metafunc parametr farg farg


bprop roipool roi error channel height width
roi imag

function perform bprop roi pool use differ
backend

featur map reshap channel height width
roi batch roi imag
error error reshap channel roi batch

delta zero featur map shape reshap channel height width

combin featur ro is
xrang roi batch
xmin ymin xmax ymax roi
xmin round xmin spatial scale
xmax round xmax spatial scale
ymin round ymin spatial scale
ymax round ymax spatial scale
width xmax xmin
height ymax ymin

stride height
stride width

xrang
sliceh lenh fprop slice stride height ymin
sliceh stop sliceh start

xrang
slicew lenw fprop slice stride width xmin
slicew stop slicew start


featur map sliceh slicew reshap
channel
argmax axi

delta view delta sliceh slicew reshap
channel
delta view
rang channel error
delta sliceh slicew delta view reshap channel
lenh
lenw

delta


fprop roipool roi channel height width roi imag

featur map reshap channel height width
roi batch roi imag
output zero channel roi batch

combin featur ro is
xrang roi batch
xmin ymin xmax ymax roi
xmin round xmin spatial scale
xmax round xmax spatial scale
ymin round ymin spatial scale
ymax round ymax spatial scale
width xmax xmin
height ymax ymin

stride height
stride width

xrang
sliceh fprop slice stride height ymin
sliceh stop sliceh start

xrang
slicew fprop slice stride width xmin
slicew stop slicew start


featur map sliceh slicew reshap
channel
output axi

output reshap roi batch


test roipool fprop random backend farg

roi imag size farg

gener random featur random ro is
featur map random random
reshap
roi batch roi imag

roi vstack one roi imag rang
roi random random roi batch

roi zero roi batch
roi random random roi batch spatial scale
roi random random roi batch spatial scale
roi
random random roi batch spatial scale
roi
random random roi batch spatial scale

roi hstack roi roi

numpi fprop insid test script
output fprop roipool featur map roi

roi imag size size

call backend roipool kernel
nervana object
nervana object
input featur map
roi roi
output shape size size roi batch
output zero output shape
make sure
argmax zero output shape int32

start time timeit
roipool fprop input roi output argmax roi batch
size size spatial scale
nervana backend roipool fprop format timeit start time

output output reshap roi batch
allclos output output atol rtol


test roipool fprop backend roi input output

roi input output


input shape
roi batch size output shape
output output reshap roi batch
roi imag roi batch
featur map input reshap astyp order

numpi fprop insid test script
output fprop roipool featur map roi

roi imag size size

allclos output output atol rtol

call nervana gpu roipool kernel
nervana object
nervana object
input featur map
roi roi
output shape size size roi batch
output zero output shape dtype float32
make sure
argmax zero output shape dtype int32

start time timeit
roipool fprop input roi output argmax roi batch
size size spatial scale

output backend output reshap roi batch

nervana backend roipool fprop format timeit start time

allclos output output backend atol rtol


test roipool bprop random backend farg

roi imag size farg
roi batch roi imag
gener random featur random ro is
featur size

featur map rang featur size reshap

input error zero
size size roi batch

rang size size
input error roi batch
rang rang reshap input error roi batch shape

roi vstack one roi imag rang
roi random random roi batch

full frame
roi zero roi batch
roi one roi batch
roi one roi batch
roi one roi batch spatial scale
roi one roi batch spatial scale

roi hstack roi roi

numpi fprop insid test script
output bprop roipool featur map roi input error

roi imag size size

call backend roipool kernel
nervana object
nervana object
input featur map
roi roi
output shape size size roi batch
output zero output shape dtype float32
make sure
argmax zero output shape dtype int32
input error input error
output error zero featur map shape

roipool fprop input roi output argmax roi batch
size size spatial scale
start time timeit
roipool bprop input error roi output error argmax
roi batch size
size spatial scale
nervana backend roipool bprop format timeit start time

output error reshap

output error reshap


output error input error

output output error
allclos output output atol rtol


test roipool bprop backend roi input output fprop
input error

roi input output fprop input error


input shape
roi batch size input error shape

output fprop output fprop reshap roi batch
featur map input reshap astyp order
input error input error reshap
roi batch astyp order

compar kernel need call fprop first bprop
nervana object
nervana object
input featur map
roi roi
output shape size size roi batch
output zero output shape dtype float32
make sure
argmax zero output shape dtype int32
input error input error
output error zero output fprop shape

roipool fprop input roi output argmax roi batch
size size spatial scale

output fprop output reshap roi batch

allclos
output fprop output fprop atol rtol

start time timeit
roipool bprop input error roi output error argmax
roi batch size
size spatial scale
nervana gpu roipool bprop format timeit start time
output backend output error

allclos output fprop output backend atol rtol


name main


backend backend batch size compat mode caff

compar random
farg
test roipool fprop random farg
test roipool bprop random farg

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



test optim


numpi
copi

neon nervana object
neon backend backend
neon optim gradient descent momentum rm prop adadelta adam adagrad
neon optim multi optim
neon layer conv affin lstm
neon initi gaussian constant
neon transform rectlin logist tanh


dummi layer

init






compar tensor func param param2 epoch
func optim dummi layer param epoch epoch
param grad state param
cond param param2
cond prod param2 shape


wrap
nervana object
dtypeu float32
dtypeu


test backend
lrate wdecay
gradient descent momentum
learn rate lrate momentum coef wdecay wdecay
param random rand
param2 copi deepcopi param
grad random rand
grad2 grad
state random rand
veloc state
param2 param2 veloc grad2 lrate wdecay lrate param
param wrap param wrap grad wrap state
compar tensor param param2


test rmsprop backend
rm prop
param random rand
param2 copi deepcopi param
grad random rand
grad2 grad
state random rand
state state
decay decay rate
denom sqrt decay state squar grad2 decay epsilon epsilon
param2 grad2 learn rate denom
param wrap param wrap grad wrap state
compar tensor param param2


test adadelta backend
adadelta
param random rand
param2 copi deepcopi param
grad random rand
grad2 grad
state random rand
random rand
random rand
states2 copi deepcopi state
copi deepcopi state
copi deepcopi state
decay decay
states2 states2 decay decay grad2 grad2
states2 sqrt
states2 epsilon states2 epsilon grad2
states2 states2 decay decay states2 states2
param2 states2
param
wrap param wrap grad wrap state wrap state wrap state
compar tensor param param2


test adagrad backend
adagrad
param random rand
param2 copi deepcopi param
grad random rand
grad2 grad
state random rand
states2 copi deepcopi state
states2 states2 squar grad2
denom sqrt states2 epsilon
param2 grad2 learn rate denom
param
wrap param wrap grad wrap state
compar tensor param param2


test adam backend
adam adam
param random rand
param2 copi deepcopi param
grad random rand
grad2 grad
state random rand
random rand
states2 copi deepcopi state
copi deepcopi state
epoch
epoch
adam learn rate sqrt adam beta adam beta
states2
adam beta adam beta grad2
adam beta adam beta grad2 grad2
param2 sqrt adam epsilon
param
wrap param wrap grad wrap state wrap state
compar tensor adam param param2 epoch epoch


test multi optim backend
gradient descent momentum
learn rate momentum coef wdecay
adadelta
adam adam
rm prop
rm prop gradient clip valu
init gaussian scale

conv stride pad
init init bia constant activ rectlin
affin nout 4096 init init
bia constant activ rectlin
lstm output size 1000 init init activ logist gate activ tanh
output size init init activ logist gate activ tanh
layer
layer
layer layer
isinst layer
layer extend layer

layer append layer

multi optim
bia
convolut adam
linear
lstm


optim layer
adam name convolut
name bia
name linear
name activ
name lstm
name

name main
backend backend batch size
test multi optim

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


thi test compar neon lstm layer numpi refer lstm
implement compar neon lstm bprop delta gradient
estim finit differ
numpi refer lstm contain method forward
backward
run singl layer lstm compar numer valu

follow made sure lst ms
initi valu zero
initi random valu
input random matrix
input error random matrix
shape insid lstm batch size input size
need transpos
shape insid lstm neon input size batch size


itertool
numpi

neon nervana object
neon initi initi constant gaussian
neon layer recurr lstm
neon transform logist tanh
test lstm lstm ref lstm
test util spars rand allclos


pytest gener test metafunc
metafunc config option




reflstmarg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr reflstmarg farg

gradlstmarg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr gradlstmarg farg


test compar one backend reflstmarg
comparison refer code
one init
input size hidden size batch size reflstmarg
nervana object nervana object batch size batch size

check lstm input size hidden size
batch size constant


test compar rand backend reflstmarg
comparison refer code
one init
input size hidden size batch size reflstmarg
nervana object nervana object batch size batch size
check lstm input size hidden size batch size
gaussian


compar neon lstm refer lstm implement
check lstm input size hidden size
batch size init func mom
init func initi model
mom mean random input
input shape input size batch size
hidden shape hidden size batch size
nervana object nervana object batch size batch size

neon lstm
lstm lstm hidden size
init func
activ tanh
gate activ logist

random rand input shape mom mom
inpa lstm
neon fprop
lstm configur input size
lstm prev layer hack forc alloc delta buffer
lstm alloc
lstm delta lstm iobuf lstm shape
lstm fprop inpa

refer numpi lstm
lstm ref lstm
wlstm lstm init input size hidden size

make weight bias neon model
wlstm lstm
wlstm input size lstm input
wlstm input size lstm recur

transpos input fprop
copi reshap batch size input size
hout cprev hprev batch cach lstm forward
wlstm

output need transpos well
hout hout reshap batch size hidden size
ifo gf batch cach ifo gf reshap batch size hidden size
batch cach reshap batch size hidden size

compar result
verifi ifog
allclos lstm ifog buffer
ifo gf
rtol
atol

verifi cell state
allclos lstm buffer

rtol
atol

verifi hidden state
allclos lstm output
hout
rtol
atol

fprop verifi

test bprop
gener random delta tensor
delta random randn hidden shape

lstm bprop lstm delta
grab delta gradient buffer
d winput neon lstm input
d wrecur neon lstm recur
neon lstm

delta delta copi reshap batch size hidden size
d wlstm lstm backward delta
batch cach
d wrecur d wlstm hidden size
d winput d wlstm input size
d wlstm
reshap batch size input size

compar result
make sure neon lstm match numpi lstm bprop
verifi updat recur

allclos d wrecur neon
d wrecur
rtol
atol

verifi updat input
allclos d winput neon
d winput
rtol
atol

verifi updat bia
allclos neon flatten

rtol
atol

verifi output delta
allclos lstm delta buffer

rtol
atol

bprop verifi




reset lstm lstm
order fprop multipl time
gradient check test
lstm variabl need
clear
lstm
lstm
lstm output



test gradient lstm backend gradlstmarg
input size hidden size batch size gradlstmarg
nervana object nervana object batch size batch size
gradient check input size hidden size batch size


test gradient neon lstm backend gradlstmarg
input size hidden size batch size gradlstmarg
nervana object nervana object batch size batch size
gradient check input size hidden size batch size


gradient check input size hidden size batch size
epsilon dtypeu float64 threshold
check refer code
estim gradient ad perturb
input weight compar
valu calcul bprop

gener spars random input matrix
nervana object nervana object batch size batch size
input shape input size batch size
hidden shape hidden size batch size
ind spars rand input shape frac input shape
random randn input shape

convert input matrix neon code format
swapax astyp dtypeu

gener refer lstm
lstm ref lstm
wlstm lstm init input size hidden size astyp dtypeu

init paramet done neon
wlstm random randn wlstm shape

hout cprev hprev cach lstm forward wlstm

scale hout random matrix
rand scale random random hout shape
rand scale dtypeu rand scale

line would loss
loss rand scale hout

bprop input delta rand scale
d wlstm lstm backward rand scale cach

grad zero shape
pert copi
pert rang size
save pert flat pert

subtract perturb input
pert flat pert save epsilon
fprop perturb input
hout cprev hprev cach lstm forward pert wlstm

pert flat pert save epsilon
hout cprev hprev cach lstm forward pert wlstm

calcul loss output
loss rand scale hout
loss rand scale hout

grad flat pert loss loss epsilon

reset input
pert flat pert save

gradient estim within threshold
bprop calcul delta
allclos grad rtol threshold atol



gradient check input size hidden size batch size
threshold
threshold fraction differ
gradient estim
bprop delta
given layer paramet calcul
gradient compar deriv
obtain bprop
rang perturb
perturb size best result
thi necessari comput

minimum error
perturb grad diff
pert rang
need gener scale input outsid
issu random gener
gener insid gradient calc

input shape input size batch size
output shape hidden size batch size
rand scale random random output shape

random randn input shape

pert pert
grad delta gradient calc
input size
hidden size
batch size
epsilon pert
rand scale rand scale

grad delta
pert


reset seed model
allclos grad delta rtol atol
nervana object reset

check best valu worst error less threshold
worst error perturb pert
threshold threshold
threshold


gradient calc input size hidden size batch size
epsilon rand scale
nervana object nervana object batch size batch size

input shape input size batch size

gener input given

random randn input shape

neon lstm
lstm lstm hidden size gaussian activ tanh gate activ logist
inpa lstm copi

fprop baselin input
lstm configur input size
lstm prev layer hack forc alloc delta buffer
lstm alloc
lstm delta lstm iobuf lstm shape
lstm fprop inpa

random scale hash gener fake loss
rand scale
rand scale random random shape
loss would
loss rand scale

back prop rand scale error
copi avoid interact
delta neon lstm bprop lstm copi rand scale

perturb input element
grad zero inpa shape
pert copi
pert rang inpa size
save pert flat pert

pert flat pert save epsilon
reset lstm lstm
lstm alloc
lstm fprop lstm pert

pert flat pert save epsilon
reset lstm lstm
lstm alloc
lstm fprop lstm pert

calcul loss perturb
loss rand scale
loss rand scale
comput gradient estim
grad loss loss epsilon

grad flat pert grad

reset perturb input element
pert flat pert save

lstm
grad delta neon

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test bi rnn layer

itertool
numpi

neon nervana object
neon initi initi glorot uniform
neon layer recurr bi rnn recurr step
neon transform logist
numpi concaten


pytest gener test metafunc

farg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr farg farg


test bi rnn fprop backend farg

basic saniti check weight random input
input size hidden size batch size farg
shape input size
shape hidden size
nervana object batch size

setup direct
init glorot glorot uniform
birnn bi rnn hidden size activ logist init init glorot
birnn configur shape
birnn prev layer
birnn alloc
birnn delta birnn iobuf birnn shape

setup direct
init glorot glorot uniform
recurr hidden size activ logist init init glorot
configur shape
prev layer
alloc
delta iobuf shape

weight backward weight
nout hidden size
birnn input birnn input
birnn recur birnn recur
birnn birnn
birnn
input birnn input
recur birnn recur
birnn


input random flip left right input
random random input size batch size
revers step copi shape

axi
birnn
birnn


output
birnn fprop copi
birnn buffer
birnn fprop
fprop copi

view
step nout shape
step nout shape
step nout shape
step nout shape
step shape

assert fprop

revers revers
allclos rtol atol
allclos rtol atol
allclos rtol atol
allclos rtol atol


test bi rnn fprop backend farg

basic saniti check weight random input
input size hidden size batch size farg
shape input size
shape hidden size
nervana object batch size

setup direct
init glorot glorot uniform
birnn bi rnn hidden size activ logist init init glorot
birnn configur shape
birnn prev layer
birnn alloc
birnn delta birnn iobuf birnn shape

weight
nout hidden size
birnn input birnn input
birnn recur birnn recur
birnn birnn
birnn

input random flip left right input
random random input size batch size
revers step copi shape

axi
birnn
birnn

output
birnn fprop copi

birnn buffer
birnn fprop copi

view
step nout shape
step nout shape
step nout shape
step nout shape

assert

revers revers
allclos rtol atol
allclos rtol atol


test bi rnn bprop backend farg

basic saniti check weight random input
input size hidden size batch size farg
shape input size
nervana object batch size

setup direct
init glorot glorot uniform
birnn bi rnn hidden size activ logist init init glorot
birnn configur shape
birnn prev layer
birnn alloc
birnn delta birnn iobuf birnn shape

weight backward weight
birnn input birnn input
birnn recur birnn recur
birnn birnn
birnn

weight direct
init glorot glorot uniform
recurr hidden size activ logist init init glorot
configur shape
prev layer
alloc
delta iobuf shape

input view
random random input size batch size
revers step copi shape
axi

alloc buffer
birnn
birnn

output
birnn fprop
birnn bprop copi
birnn buffer
birnn fprop
birnn bprop copi

step shape
step shape
revers
allclos rtol atol

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


thi test compar neon recurr layer numpi refer recurr
implement compar neon recurr bprop delta gradient
estim finit differ
numpi refer recurr layer contain method forward
backward
test run singl layer recurr layer compar numer valu
refer model handl batch size

follow made sure recurr layer
initi valu zero
initi one random valu
input random matrix
input error random matrix
shape insid recurr input size
shape insid recurr neon featur batch size


itertool
numpi

neon nervana object
neon initi initi constant gaussian
neon layer recurr
neon transform tanh
test recurr recurr ref recurr
test util allclos


pytest gener test metafunc


refgruarg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr refgruarg farg

gradgruarg metafunc fixturenam
farg
metafunc config option







farg product
metafunc parametr gradgruarg farg


test compar one backend refgruarg
comparison refer code
one init
input size hidden size batch size refgruarg
nervana object nervana object batch size batch size

check input size hidden size
batch size constant


test compar rand backend refgruarg
comparison refer code
gaussian random init
input size hidden size batch size refgruarg
nervana object nervana object batch size batch size

check input size hidden size batch size
gaussian


compar neon refer implement
check input size hidden size
batch size init func mom
init func initi model
mom mean random input
input shape input size batch size
output shape hidden size batch size
nervana object nervana object batch size batch size

creat model
neon
recurr hidden size init func activ tanh

refer numpi
ref recurr input size hidden size




gener
gener random input tensor
random rand input shape mom mom
inpa
gener random delta tensor
delta random randn output shape

refer code expect shape
input shape input size batch size
output shape hidden size batch size
copi reshap
batch size input size swapax
delta delta copi reshap
batch size hidden size swapax

run model
neon fprop
configur input size
prev layer
alloc
delta iobuf shape
fprop inpa

weight initi fprop
make weight bias neon model
input
recur


d wxh d whh
loss fun delta

test bprop
bprop delta
grab delta gradient buffer
d wxh neon input
d whh neon recur
neon

compar output
verifi hidden state
allclos output

rtol
atol
fprop verifi

verifi updat
d wxh
allclos d wxh neon
d wxh
rtol
atol
d whh
allclos d whh neon
d whh
rtol
atol

verifi updat bia

allclos neon

rtol
atol

bprop verifi




reset
order fprop multipl time
gradient check test
variabl need
clear


output



test gradient neon backend gradgruarg
input size hidden size batch size gradgruarg
nervana object nervana object batch size batch size
gradient check input size hidden size batch size


gradient check input size hidden size batch size
threshold
threshold fraction differ
gradient estim
bprop delta
given layer paramet calcul
gradient compar deriv
obtain bprop
rang perturb
perturb size best result
thi necessari comput

minimum error
perturb grad diff
pert rang
need gener scale input outsid
issu random gener
gener insid gradient calc

input shape input size batch size
output shape hidden size batch size

rand scale random random output shape
random randn input shape

pert pert
grad delta gradient calc
input size
hidden size
batch size
epsilon pert
rand scale rand scale

grad delta
pert


reset seed model
allclos grad delta rtol atol
nervana object reset

check best valu worst error less threshold
worst error perturb pert
threshold threshold
threshold


gradient calc input size hidden size batch size
epsilon rand scale
nervana object nervana object batch size batch size

input shape input size batch size

gener input given

random randn input shape

neon
recurr hidden size gaussian activ tanh
inpa copi

fprop baselin input
configur input size
prev layer
alloc
delta iobuf shape
fprop inpa

random scale hash gener fake loss
rand scale
rand scale random random shape
loss would
loss rand scale

back prop rand scale error
copi avoid interact
delta neon bprop copi rand scale

perturb input element
grad zero inpa shape
pert copi
pert rang inpa size
save pert flat pert

pert flat pert save epsilon
reset
alloc
fprop pert

pert flat pert save epsilon
reset
alloc
fprop pert

calcul loss perturb
loss rand scale
loss rand scale
comput gradient estim
grad loss loss epsilon

grad flat pert grad

reset perturb input element
pert flat pert save


grad delta neon

thi refer lstm numpi implement adapt karpathi code

adapt includ
initi valu
abl read intermedi valu compar anoth lstm
implement

numpi


lstm

staticmethod
init input size hidden size

initi paramet lstm weight bias matrix
one

input size hidden size
hidden size
sqrt input size hidden size
wlstm one
wlstm

staticmethod
forward wlstm

shape input size length sequenc batch size

input size shape
wlstm shape hidden size

zero

zero

perform lstm forward input
xphpb wlstm shape plu plu bia
input tick lstm
zero xphpb
hidden represent lstm gate cell content
hout zero
ifog zero input forget output gate ifog
ifo gf zero nonlinear
zero cell content
zero tanh cell content
xrang
concat input lstm
prevh hout
bia
input size
input size prevh
comput gate activ dot work line

ifog wlstm
linear
sigmoid gate
ifo gf ifog
ifo gf tanh ifog tanh
comput cell activ
prevc
ifo gf ifo gf
ifo gf prevc
tanh
hout ifo gf

cach
cach wlstm wlstm
cach hout hout
cach ifo gf ifo gf
cach ifog ifog
cach
cach
cach
cach
cach

well lstm prev state init
need
hout hout cach

staticmethod
backward d hout cach

wlstm cach wlstm
hout cach hout
ifo gf cach ifo gf
ifog cach ifog
cach
cach
cach
cach
cach
hout shape
input size wlstm shape bia

backprop lstm
d ifog zero ifog shape
d ifo gf zero ifo gf shape
d wlstm zero wlstm shape
d hin zero shape
zero shape
zero input size
zero
zero
d hout d hout copi make copi funni side effect

copi carri gradient later

d hout copi

revers xrang
tanh ct
d ifo gf tanh ct d hout
backprop tanh linear first backprop
tanh ct ifo gf d hout


d ifo gf
ifo gf

d ifo gf
ifo gf
d ifo gf ifo gf
d ifo gf ifo gf

backprop activ function
d ifog ifo gf
d ifo gf
ifo gf
d ifog d ifo gf

backprop matrix multipli
d wlstm transpos d ifog
d hin d ifog wlstm transpos

backprop ident transform
d hin input size

d hout d hin input size

d hin input size

debug

hidden size wlstm shape input size
d wrecur d wlstm hidden size
d winput d wlstm input size
d wlstm
d wlstm

staticmethod
run batch fprop with given input hidden size

lstm model given input dimens
batch size hidden size


shape
batch size shape
input size shape

wlstm lstm init input size hidden size

batch forward
hout cprev hprev batch cach lstm forward wlstm

ifo gf batch cach ifo gf
batch cach

hout ifo gf batch cach

staticmethod
run batch bprop with given delta hidden size batch cach delta

lstm model given input error dimens
batch size hidden size


delta

batch version gradient
d wlstm lstm backward batch cach

input size d wlstm shape hidden size
d wrecur d wlstm hidden size
d winput d wlstm input size
d wlstm

d wrecur d winput d wlstm


test case



check sequenti match batch
check lstm forward backward interact

sequenc length batch size hidden size
input size
wlstm lstm init input size input size hidden size
random randn input size
random randn
random randn

sequenti forward
cprev
hprev
cach xrang
hcat zero
xrang

cprev hprev cach lstm forward wlstm cprev hprev
cach cach
hcat hprev

saniti check perform batch forward check thing
batch cach lstm forward wlstm
allclos hcat sequenti batch forward match

loss
wrand random randn hcat shape
loss hcat wrand
wrand

batch version gradient
bd wlstm bdc0 bdh0 lstm backward batch cach

perform sequenti backward
zero like
d wlstm zero like wlstm
zero like
zero like
dcnext
dhnext
revers xrang
reshap
d wlst mt dcprev dhprev lstm backward
cach dcnext dhnext
dhnext dhprev
dcnext dcprev

d wlstm d wlst mt accumul lstm gradient


dcprev
dhprev

make sure gradient match
make sure batch version agre sequenti version
allclos
allclos bd wlstm d wlstm
allclos bdc0
allclos bdh0


check batch gradient
check batch gradient correct

let gradient check beast
sequenc length batch size hidden size
input size
wlstm lstm init input size input size hidden size
random randn input size
random randn
random randn

batch forward backward
cach lstm forward wlstm
wrand random randn shape
loss wrand weight nice hash think
wrand
d wlstm lstm backward cach


lstm forward wlstm
wrand

gradient check
delta
error warn
error error
tocheck wlstm
grad analyt d wlstm
name wlstm
xrang tocheck
tocheck
dmat grad analyt
name name
gradcheck
xrang size
flat
flat delta
loss0
flat delta
loss1
flat

grad analyt dmat flat
grad numer loss0 loss1 delta

grad numer grad analyt
error zero
statu
grad numer grad analyt
error enough precis check
statu small warn

error grad analyt grad numer
grad numer grad analyt
statu
error error warn
statu warn
error error error
statu notok

stat
check param index analyt
numer rel error
statu name repr unravel index shape
grad analyt grad numer error

name main
check sequenti match batch
input check press gradient check
check batch gradient
everi line start have nice

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test recurr output layer

itertool
numpi

neon backend backend
neon nervana object
neon layer recurr recurr sum recurr mean recurr last


pytest gener test metafunc


refgruarg metafunc fixturenam
farg
metafunc config option





farg product
metafunc parametr refgruarg farg


test recurr backend refgruarg
batch size refgruarg
nervana object batch size

shape
layer recurr sum
layer configur shape
layer prev layer
layer alloc
layer delta layer iobuf shape

zero
layer zero batch size
layer fprop
layer bprop
zero batch size


one
layer one batch size
layer fprop
layer bprop
one batch size


random batch
rinp random random batch size
rinp repeat axi
layer
layer fprop
layer bprop
allclos rinp
allclos

full random
random random batch size
layer
layer fprop
layer bprop
comp zero shape
comp zero shape
rang
comp comp batch size batch size
comp batch size batch size
allclos comp
allclos comp


test recurr mean backend refgruarg
batch size refgruarg
nervana object batch size

shape
layer recurr mean
layer configur shape
layer prev layer
layer alloc
layer delta layer iobuf shape

zero
layer zero batch size
layer fprop
layer bprop
zero batch size


one
layer one batch size
layer fprop
layer bprop
one batch size


random
rinp random random batch size
rinp repeat axi
layer
layer fprop
layer bprop
allclos rinp
allclos

full random
random random batch size
layer
layer fprop
layer bprop
comp zero shape
comp zero shape
rang
comp comp batch size batch size
comp batch size batch size
comp

allclos comp
allclos comp


test recurr last backend refgruarg
batch size refgruarg
nervana object batch size

shape
layer recurr last
layer configur shape
layer prev layer
layer alloc
layer delta layer iobuf shape

zero
layer zero batch size
layer fprop
layer bprop
zero batch size


one
layer one batch size
layer fprop
layer bprop
one batch size
batch size batch size

batch size zero batch size

random
rinp random random batch size
rinp repeat axi
layer
layer fprop
layer bprop
allclos rinp
allclos batch size rinp

full random
random random batch size
layer
layer fprop
layer bprop
comp zero shape
comp zero shape
comp batch size
comp batch size


name main

farg
backend backend
test recurr farg
python
script run exampl check
without throw except


glob glob
subprocess subp

path isdir exampl
io error must root none repo

check venv activ
virtual
subp call shell
io error need activ virtualenv

benchmark glob exampl convnet benchmark

result
benchmark


path basenam
python format

subp call shell

result append


error
result

failur format
error
error

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens

neon initi initi uniform
neon transform activ rectlin
neon layer layer linear convolut conv bia activ affin


test conv wrapper backend

verifi conv wrapper construct right layer object

conv conv uniform
isinst conv
conv
isinst conv convolut

conv conv uniform bia uniform
isinst conv
conv
isinst conv convolut
isinst conv bia

conv conv uniform activ rectlin
isinst conv
conv
isinst conv convolut
isinst conv activ

conv conv uniform bia uniform activ rectlin
isinst conv
isinst conv convolut
isinst conv bia
isinst conv activ
conv


test affin wrapper backend

verifi affin wrapper construct right layer object

nout
affin nout uniform
isinst

isinst linear
nout nout

affin nout uniform bia uniform
isinst

isinst linear
isinst bia

affin nout uniform activ rectlin
isinst

isinst linear
isinst activ

affin nout uniform bia uniform activ rectlin
isinst

isinst linear
isinst bia
isinst activ
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


small cifar10 base convolut neural network adapt neon exampl
serial test


numpi
neon array iter load cifar10
neon initi uniform
neon layer affin conv pool gener cost
neon model model
neon optim gradient descent momentum
neon transform misclassif rectlin softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
arg parser pars arg

hyperparamet
arg datatyp float16
cost scale
epoch arg epoch

train train test test nclass load cifar10 path arg

nmax train shape arg batch size
nmax arg batch size
train train nmax
train train nmax

train array iter train train nclass nclass lshape name train
test array iter test test nclass nclass lshape name test

init uniform high
arg datatyp float32 float64
gradient descent momentum learn rate
momentum coef
stochast round arg round
arg datatyp float16
gradient descent momentum learn rate cost scale
momentum coef
stochast round arg round

layer conv init init activ rectlin batch norm
pool
conv init init activ rectlin batch norm
pool
affin nout init init activ rectlin batch norm
affin nout init init activ softmax

arg datatyp float32 float64
cost gener cost costfunc cross entropi multi
arg datatyp float16
cost gener cost costfunc cross entropi multi scale cost scale

model model layer layer

configur callback
callback callback model test arg callback arg

callback callback load callback callback descript model train test
model train optim epoch epoch cost cost callback callback

misclassif error model test metric misclassif
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


argpars

pickl


neon util modeldesc model descript


compar file file1 file2

helper compar serial model file

thi compar model weight state layer
config paramet

return
file match

model
file1 file2
path exist could find file

open
model append model descript pickl load

model model


name main
parser argpars argument parser descript compar serial model file
parser argument file1
parser argument file2
arg parser pars arg

compar file arg file1 arg file2
error model match


match
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


googlenet model serial test script adapt
small mini batch

numpi

neon layer conv pool merg broadcast branch node affin tree dropout
neon layer gener cost multicost
neon initi constant xavier
neon optim gradient descent momentum poli schedul multi optim
neon transform rectlin softmax cross entropi multi
neon model model
neon imag loader
neon callback callback callback
neon util argpars neon argpars
neon util persist load save

pars command line
parser neon argpars
parser argument resum action store
help first without resum save file
arg parser pars arg

arg backend mgpu
batch size reason work bia layer

batch size

subset make sure everi epoch count
option dict repo arg
inner size
dtype float32
subset 09990891117239205
train imag loader name train scale rang shuffl
transform option

init1 xavier local
initx xavier local
bia constant
relu rectlin

common dict activ relu init initx bia bia
commonp1 dict activ relu init initx bia bia pad
commonp2 dict activ relu init initx bia bia pad
pool3s1p1 dict fshape pad stride
pool3s2p1 dict fshape pad stride


incept kval name
kval

branch1 conv name name common
branch2 conv name name reduc common
conv name name commonp1
branch3 conv name name reduc common
conv name name commonp2
branch4 pool name name pool pool3s1p1
conv name name pool proj common
merg broadcast layer branch1 branch2 branch3 branch4 merg depth


main branch branch node
conv pad stride name conv1 common
pool name pool1 pool3s2p1
conv name conv2 reduc common
conv name conv2 commonp1
pool name pool2 pool3s2p1
incept name incept
incept name incept
pool name pool3 pool3s2p1
incept name incept
branch node
incept name incept
incept name incept
incept name incept
branch node
incept name incept
pool name pool4 pool3s2p1
incept name incept
incept name incept
pool fshape stride name pool5
affin nout 1000 init init1 activ softmax
bia constant name loss3 classifi


branch bnode
todo dropout back
loss
bnode
pool fshape stride name pool
conv name conv common
affin nout 1024 init init1 activ relu bia bia name
dropout keep name drop
affin nout 1000 init init1 activ softmax
bia constant name classifi


setup cost cross entropi
cost multicost cost gener cost costfunc cross entropi multi
gener cost costfunc cross entropi multi
gener cost costfunc cross entropi multi
weight want consid main path

arg resum
build model scratch

construct model
branch node branch node name branch rang
main1 main branch branch node
aux1 branch branch node
aux2 branch branch node

model model layer tree main1 aux1 aux2 alpha


load save model
model model serial test
model initi train cost cost

configur callback
callback callback model progress output file temp1
serial histori save path serial test

sched poli schedul total epoch power
gradient descent momentum wdecay 0002 schedul sched
bias gradient descent momentum schedul sched

multi optim bia bias
arg resum
model epoch
model train optim epoch cost cost callback callback

train reset
imag
train

train batch provid
save
save copi
arg resum
load



fprop bprop minibatch save result
fprop model fprop

fprop save fprop
save
fprop model fprop
fprop save2 fprop
fprop save fprop save2
fprop iter match

minibatch
hand
delta model cost error
model bprop delta
arg resum
model optim
model optim optim model layer optim epoch model epoch index

fprop measur model state
fprop model fprop
fprop save2 fprop

arg resum
save fprop save fprop save2 serial test out1

load save file compar
run1 load serial test out1

compar initi fprop
run1 fprop save
deseri model match serial model

post extra train fprop
run1 fprop save2


valu error deseri train match serial train

singl epoch optim real effect
fprop save fprop save2
train effect model
pass
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


alexnet model adapt serial test

subset iter epoch
partial minibatch dropout turn reproduc
learn rate scale handl reduc dropout percentag



neon util argpars neon argpars
neon initi constant gaussian
neon layer conv dropout pool gener cost affin
neon optim gradient descent momentum multi optim schedul
neon transform rectlin softmax cross entropi multi top k misclassif
neon model model
neon imag loader
neon callback callback callback

pars command line gener backend
parser neon argpars
arg parser pars arg

setup provid
option dict repo arg
inner size
subset 09990891117239205
train imag loader name train scale rang shuffl
transform option
test imag loader name valid scale rang shuffl
transform option

layer conv init gaussian scale bia constant
activ rectlin pad stride
pool stride
conv init gaussian scale bia constant
activ rectlin pad
pool stride
conv init gaussian scale bia constant
activ rectlin pad
conv init gaussian scale bia constant
activ rectlin pad
conv init gaussian scale bia constant
activ rectlin pad
pool stride
affin nout 4096 init gaussian scale bia constant activ rectlin
dropout keep
affin nout 4096 init gaussian scale bia constant activ rectlin
dropout keep
affin nout 1000 init gaussian scale bia constant activ softmax
model model layer layer

drop weight epoch drop bia epoch
weight sched schedul
gradient descent momentum wdecay 0005 schedul weight sched
stochast round arg round
bias gradient descent momentum schedul schedul
stochast round arg round
multi optim bia bias

configur callback
valmetr top k misclassif
callback callback model test metric valmetr arg callback arg
cost gener cost costfunc cross entropi multi
model train optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train network layer
perform vector copi task paper


neon initi uniform
neon layer gener cost mask affin
neon model model
neon optim rm prop
neon transform tanh cross entropi binari logist
neon callback callback callback
neon util argpars neon argpars
neon ticker copi task

pars command line
parser neon argpars
arg parser pars arg

batch size

count
size

hyperparamet paper
hidden size
gradient clip valu

load pars charact level
ticker task copi task size
train ticker ticker task

weight initi
init uniform high

output size
memori locat
size memori locat

model initi
layer
hidden size init activ tanh gate activ logist
affin train nout init bia init activ logist


cost gener cost mask costfunc cross entropi binari

model model layer layer

optim rm prop gradient clip valu gradient clip valu
stochast round arg round

configur callback
callback callback model arg callback arg

train valid
sinc ticker gener
callback watch ticker callback train

train model
model train
optim optim
epoch arg epoch
cost cost
callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train small multi layer perceptron multipl branch

branch node use indic point differ layer sequenc diverg

topolog network

cost1 cost3





cost2












neon callback callback callback
neon array iter load mnist
neon initi gaussian
neon layer gener cost affin branch node multicost singl output tree
neon model model
neon optim gradient descent momentum
neon transform rectlin logist softmax
neon transform cross entropi binari cross entropi multi misclassif
neon util argpars neon argpars


pars command line
parser neon argpars

arg parser pars arg

load mnist
split train test set
train train test test nclass load mnist path arg

setup train iter
train array iter train train nclass nclass
setup valid iter
valid array iter test test nclass nclass

setup weight initi
init norm gaussian scale

normrelu dict init init norm activ rectlin
normsigm dict init init norm activ logist shortcut
normsoft dict init init norm activ softmax

setup model layer
branch node name
branch node name


affin nout name normrelu

affin nout name normrelu
affin nout name normrelu

affin nout name normsoft


affin nout name normrelu
affin nout name normsigm


affin nout name normrelu
affin nout name normsigm


setup cost cross entropi
cost multicost cost gener cost costfunc cross entropi multi
gener cost costfunc cross entropi binari
gener cost costfunc cross entropi binari
weight

setup optim
optim gradient descent momentum momentum coef stochast round arg round

initi model
alpha
model layer singl output tree alpha alpha

setup standard callback
callback callback valid arg callback arg


train optim optim epoch arg epoch cost cost callback callback

todo introduc multicost metric support line current fail
sinc misclassif metric expect singl tensor
tensor
misclassif error valid metric misclassif
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train small multi layer perceptron fulli connect layer mnist

thi exampl command line enabl differ neon featur

exampl

python mnist
exampl epoch mnist nervana backend

python mnist freq
after train epoch valid test process model
cost display

python mnist serial checkpoint
after everi iter train model dump pickl file name
checkpoint chang serial paramet chang frequenc
model save

python mnist model file checkpoint
befor start train model model state valu store
checkpoint file name checkpoint


log

neon callback callback callback
neon array iter load mnist
neon initi gaussian
neon layer gener cost affin
neon model model
neon optim gradient descent momentum
neon transform rectlin logist cross entropi binari misclassif
neon util argpars neon argpars


pars command line
parser neon argpars

arg parser pars arg

logger log get logger
logger set level arg thresh

load mnist
split train test set
train train test test nclass load mnist path arg

setup train iter
train array iter train train nclass nclass lshape
setup valid iter
valid array iter test test nclass nclass lshape

setup weight initi
init norm gaussian scale

setup model layer
layer affin nout init init norm activ rectlin
affin nout init init norm activ logist shortcut

setup cost cross entropi
cost gener cost costfunc cross entropi binari

setup optim
optim gradient descent momentum momentum coef stochast round arg round

initi model
model layer layer

configur callback
callback callback valid arg callback arg


train optim optim epoch arg epoch cost cost callback callback
misclassif error valid metric misclassif
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


simplifi version model
add batch normal
remov scale jitter
remov convolut infer


neon util argpars neon argpars extract valid arg
neon backend backend
neon initi constant glorot uniform
neon layer conv dropout pool gener cost affin
neon optim gradient descent momentum multi optim schedul
neon transform rectlin softmax cross entropi multi top k misclassif
neon model model
neon imag loader
neon callback callback callback

pars command line
parser neon argpars
parser argument subset
help subset train dataset percentag
arg parser pars arg

hyperparamet
arg batch size
cost scale

batch norm
bias batch norm constant

setup backend
backend extract valid arg arg backend

initi provid
option dict repo arg
inner size
scale rang
subset arg subset
train imag loader name train option
test imag loader name valid transform option

init1 glorot uniform
relu rectlin
common dict init init1 activ rectlin batch norm batch norm bia bias
conv dict pad common

model layer conv stack differ featur size
layer

nofm
layer append conv nofm conv
layer append conv nofm conv
nofm

layer append conv nofm conv

layer append conv nofm conv
layer append pool stride

layer append affin nout 4096 common
layer append dropout keep
layer append affin nout 4096 common
layer append dropout keep
layer append affin nout 1000 init init1 bia constant activ softmax

cost gener cost costfunc cross entropi multi scale cost scale

model layer layer

configur callback
valmetr top k misclassif
callback callback test metric valmetr arg callback arg

creat learn rate schedul optim
weight sched schedul rang
gradient descent momentum wdecay 0005 schedul weight sched
bias gradient descent momentum schedul weight sched
multi optim bia bias

train optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


thi allow deep residu network cifar10 detail
deep residu learn imag recognit http arxiv 1512 03385

prior run need write pad cifar10 batch imag loader consum

batch writer cifar10
path save batch
macro size 10000
target size

then exampl

cifar10 msra
logfil
progress
epoch
save path save path
freq
backend
path save batch
network resnet

thi set error could

good practic batch store
local machin avoid access macrobatch network
exampl mount locat

neon util argpars neon argpars
neon initi kaim ident init
neon layer conv pool gener cost activ affin
neon layer merg sum skip node
neon optim gradient descent momentum schedul
neon transform rectlin softmax cross entropi multi misclassif
neon model model
neon imag loader
neon callback callback callback

pars command line gener backend
parser neon argpars
parser argument network plain choic plain resnet
help network creat plain resnet
parser argument depth
help depth stage network depth
parser argument subset
help subset train dataset percentag
arg parser pars arg

setup provid
imgset option dict inner size scale rang aspect ratio
repo arg subset arg subset
train imag loader name train shuffl transform imgset option
test imag loader name valid shuffl transform imgset option


conv fsize stride relu batch norm
dict fshape fsize fsize stride stride pad fsize
activ rectlin relu
init kaim local
batch norm batch norm



dict fshape stride pad activ init ident init


factori stride
mainpath conv conv stride stride
conv conv relu
sidepath skip node stride conv

merg sum mainpath sidepath
activ rectlin


structur deep residu part network
arg depth modul convolut layer featur depth
nfm stage stage sort rang arg depth
stride prev prev nfm nfm

construct network
layer conv conv
stride nfm stride
layer append factori stride
layer append pool
layer append affin init kaim local batch norm activ softmax

model model layer layer
gradient descent momentum wdecay 0001 schedul schedul

configur callback
valmetr misclassif
callback callback model test metric valmetr arg callback arg
cost gener cost costfunc cross entropi multi

model train optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl highlight abil differ optim differ
layer differ compon layer


neon array iter load mnist
neon initi gaussian constant
neon layer gener cost affin
neon model model
neon optim gradient descent momentum multi optim rm prop
neon transform rectlin logist cross entropi binari
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
arg parser pars arg

train train test test nclass load mnist arg
train array iter train train nclass nclass lshape
valid array iter test test nclass nclass lshape

weight initi
init norm gaussian scale

initi model
layer
layer append affin nout init init norm bia constant
activ rectlin
layer append affin nout init init norm bia constant
activ logist shortcut
name special linear

cost gener cost costfunc cross entropi binari
model layer layer

valid
optim gradient descent momentum learn rate momentum coef
optim rm prop

bia layer last linear layer
optim layer optim
multi optim optim
bia optim
special linear optim

configur callback
callback callback valid arg callback arg

train optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


small cifar10 base convolut neural network showcas cost
scale fp16 format


numpi
neon array iter load cifar10
neon initi uniform
neon layer affin conv pool gener cost
neon model model
neon optim gradient descent momentum
neon transform misclassif rectlin softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
arg parser pars arg

hyperparamet
arg datatyp float16
cost scale
epoch arg epoch

train train test test nclass load cifar10 path arg

train array iter train train nclass nclass lshape
test array iter test test nclass nclass lshape

init uniform high
arg datatyp float32 float64
gradient descent momentum learn rate
momentum coef
stochast round arg round
arg datatyp float16
gradient descent momentum learn rate cost scale
momentum coef
stochast round arg round

layer conv init init activ rectlin batch norm
pool
conv init init activ rectlin batch norm
pool
affin nout init init activ rectlin batch norm
affin nout init init activ softmax

arg datatyp float32 float64
cost gener cost costfunc cross entropi multi
arg datatyp float16
cost gener cost costfunc cross entropi multi scale cost scale

model layer layer

configur callback
callback callback test arg callback arg

train optim epoch epoch cost cost callback callback

misclassif error test metric misclassif
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train lstm base recurr network draw sampl
network train shakespear dataset
charact level pars

refer
gener sequenc recurr neural network graves2014
graves2014 http arxiv 1308 0850

numpi

neon backend backend
neon text
neon dataload load shakespear
neon initi uniform
neon layer gener cost lstm affin
neon model model
neon optim rm prop
neon transform logist tanh softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
arg parser pars arg

overrid save path
arg save path
arg save path text pickl

arg callback arg save path
arg callback arg save path arg save path

arg callback arg serial
arg callback arg serial

hyperparamet
arg batch size
time step
hidden size
gradient clip valu

setup backend
backend extract valid arg arg backend

download shakespear text
path load shakespear path arg
train path valid path text creat valid file path

load pars charact level
train text time step train path
valid text time step valid path vocab train vocab

weight initi
init uniform high

model initi
layer
lstm hidden size init activ logist gate activ tanh
affin train vocab init bia init activ softmax

model model layer layer

cost gener cost costfunc cross entropi multi usebit

optim rm prop gradient clip valu gradient clip valu stochast round arg round

configur callback
callback callback model valid arg callback arg

valid
model train optim optim epoch arg epoch cost cost callback callback


sampl prob

sampl index probabl distribut

prob prob prob
argmax random multinomi prob

batch size time step gener reset buffer

time step
predict 1000

layer
lstm hidden size init activ logist gate activ tanh
affin train vocab init bia init activ softmax

model model layer layer
model load arg save path
model initi dataset train shape time step

gener text
text
seed token romeo

zero train vocab time step

seed token
fill
train token index
model fprop

rang predict
take last predict feed fprop
pred sampl
text append train index token pred

fill
pred
model fprop

join seed token text
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


small cifar10 base fulli connect layer


neon array iter load cifar10
neon initi uniform
neon layer gener cost affin
neon model model
neon optim gradient descent momentum
neon transform misclassif cross entropi binari logist rectlin
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
arg parser pars arg

train train test test nclass load cifar10 path arg

train array iter train train nclass nclass lshape
test array iter test test nclass nclass lshape

init uniform high
gradient descent momentum learn rate momentum coef

model layer
layer affin nout init init activ rectlin
affin nout init init activ logist shortcut

cost gener cost costfunc cross entropi binari

model layer layer

configur callback
callback callback test arg callback arg

train optim epoch arg epoch cost cost callback callback

misclassif error test metric misclassif
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train imag caption model precomput imag featur
refer sentenc use standard imag caption dataset
flickr8k flickr30k coco http stanford peopl karpathi deepimages
store format model transform imag featur
sentenc hidden dimens size prepend imag
first word sequenc lstm

refer
http github karpathi neuraltalk




neon backend backend
neon load flickr8k imag caption imag caption test
neon initi uniform constant array
neon layer gener cost mask lstm affin dropout sequenti merg multistream
neon model model
neon optim rm prop
neon transform logist tanh softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
arg parser pars arg

hyperparamet
hidden size
epoch arg epoch

setup backend
backend extract valid arg arg backend

download dataset
path load flickr8k path arg other setnam flickr30k coco

load
train imag caption path path imag

weight initi
init uniform high
init2 array train train bia init

model initi
imag path sequenti affin hidden size init bia constant
sent path sequenti affin hidden size init name sent

layer
merg multistream layer imag path sent path merg recurr
dropout keep
lstm hidden size init activ logist gate activ tanh reset cell
affin train vocab size init bia init2 activ softmax


cost gener cost mask costfunc cross entropi multi usebit

configur callback
checkpoint model path imag caption2
arg callback arg save path
arg callback arg save path checkpoint model path

arg callback arg serial
arg callback arg serial

model model layer layer

callback callback model arg callback arg

rm prop decay rate learn rate 0005 epsilon gradient clip valu

train model
model train optim epoch epoch cost cost callback callback

load model exit evalu bleu score test
path exist arg callback arg save path
model load arg callback arg save path
test imag caption test path path
sent target test predict model
test bleu score sent target
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



all cnn style convnet cifar10

refer
strive simplic convolut springenberg2015
springenberg2015 http arxiv 1412 6806


neon initi gaussian
neon optim gradient descent momentum schedul
neon layer conv dropout activ pool gener cost
neon transform rectlin softmax cross entropi multi misclassif
neon model model
neon array iter load cifar10
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
parser argument learn rate help initi learn rate
parser argument weight decay help weight decay
parser argument deconv action store
help save visual deconvolut
arg parser pars arg

hyperparamet
epoch arg epoch

train train test test nclass load cifar10 path arg
normal
contrast normal
whiten

realli class nearest power match conv output
train array iter train train nclass lshape
valid array iter test test nclass lshape

init gaussian scale
gradient descent momentum learn rate arg learn rate momentum coef
wdecay arg weight decay
schedul schedul step config chang

relu rectlin
conv dict init init batch norm activ relu
convp1 dict init init batch norm activ relu pad
convp1s2 dict init init batch norm activ relu pad stride

layer dropout keep
conv convp1
conv convp1
conv convp1s2
dropout keep
conv convp1
conv convp1
conv convp1s2
dropout keep
conv convp1
conv conv
conv conv
pool
activ softmax

cost gener cost costfunc cross entropi multi

model layer layer

arg model file

path exist arg model file found arg model file
load arg model file

configur callback
callback callback valid arg callback arg

arg deconv
callback deconv callback train valid

train optim epoch epoch cost cost callback callback
misclassif error valid metric misclassif
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train earli stop
train stop stop condit satisfi
epoch reach whichev first



neon array iter load mnist
neon initi gaussian
neon layer gener cost affin
neon model model
neon optim gradient descent momentum
neon transform rectlin logist cross entropi binari
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
arg parser pars arg

train train test test nclass load mnist path arg
train array iter train train nclass nclass lshape
valid array iter test test nclass nclass lshape

weight initi
init norm gaussian scale

initi model
layer
layer append affin nout init init norm batch norm activ rectlin
layer append affin nout init init norm activ logist shortcut
cost gener cost costfunc cross entropi binari
model layer layer

defin stop
take input tupl state
describ cumul valid state gener
valid error time
return output tupl state bool
repres state whether stop


stop valid error ever increas epoch epoch
stop func





valid
optim gradient descent momentum learn rate momentum coef

configur callback
arg callback arg freq
arg callback arg freq

callback callback valid arg callback arg
callback earli stop callback stop func
callback save best state callback path join arg earli stop best state
train
optim optim
epoch arg epoch
cost cost
callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train lstm network sentiment analysi

refer
emnlp2015 http arxiv 1503 00185v5

python exampl imdb lstm rlayer lstm




neon backend backend
neon dataload load imdb
neon dataiter array iter
neon text preprocess
neon initi uniform glorot uniform
neon layer gener cost lstm affin dropout lookup tabl
recurr sum recurr deep bi lstm deep bi rnn
neon model model
neon optim adagrad
neon transform logist tanh softmax cross entropi multi accuraci
neon callback callback callback
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
parser argument rlayer lstm
choic bilstm lstm birnn
help recurr layer lstm bilstm birnn

arg parser pars arg

hyperparamet refer
arg batch size
gradient clip valu
vocab size 20000
sentenc length
embed
hidden size
reset cell

setup backend
backend extract valid arg arg backend

make dataset
path load imdb path arg
train train test test nclass path
vocab size vocab size
sentenc length sentenc length

vocab size vocab size
sentenc length sentenc length
train sentenc train shape
test sentenc test shape

train array iter train train nclass
valid array iter test test nclass

weight initi
uniform embed high embed
glorot uniform

arg rlayer lstm
rlayer lstm hidden size activ tanh
gate activ logist reset cell
arg rlayer bilstm
rlayer deep bi lstm hidden size activ tanh depth
gate activ logist reset cell
arg rlayer
rlayer recurr hidden size activ tanh reset cell
arg rlayer birnn
rlayer deep bi rnn hidden size activ tanh depth reset cell


layer
lookup tabl vocab size vocab size embed embed init
rlayer
recurr sum
dropout keep
affin bia activ softmax


model model layer layer

cost gener cost costfunc cross entropi multi usebit
optim adagrad learn rate gradient clip valu gradient clip valu

configur callback
callback callback model valid arg callback arg

train model
model train optim optim epoch arg epoch cost cost callback callback

model
train accuraci model train metric accuraci
test accuraci model valid metric accuraci
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



all cnn style convnet imagenet

refer
strive simplic convolut springenberg2014
springenberg2014 http arxiv 1412 6806


neon util argpars neon argpars
neon backend backend
neon initi glorot uniform
neon optim gradient descent momentum schedul
neon layer conv dropout activ pool gener cost data transform
neon transform rectlin softmax cross entropi multi normal
neon model model
neon callback callback callback
neon imag loader

pars command line
parser neon argpars
parser argument deconv action store
help save visual deconvolut
parser argument subset
help subset train dataset percentag
arg parser pars arg


hyperparamet
batch size

setup backend
backend backend arg backend
batch size batch size
seed arg seed
devic arg devic
datatyp arg datatyp

setup provid
option dict repo arg
inner size
scale rang
subset arg subset
train imag loader name train option
test imag loader name valid transform option

relu rectlin

init glorot uniform

paramet straight springenberg2014
gradient descent momentum learn rate
schedul schedul step config
chang
momentum coef wdecay 0005


model layer
layer
layer append data transform transform normal divisor

layer append conv init init activ relu stride pad
layer append conv init init activ relu stride
layer append conv init init activ relu stride pad

layer append conv init init activ relu stride
layer append conv init init activ relu stride
layer append conv init init activ relu stride pad

layer append conv init init activ relu stride pad
layer append conv init init activ relu stride
layer append conv init init activ relu stride pad

layer append dropout keep
layer append conv 1024 init init activ relu stride pad
layer append conv 1024 init init activ relu stride
layer append conv 1000 init init activ relu stride
layer append pool

layer append activ softmax

cost gener cost costfunc cross entropi multi

model model layer layer

arg model file

path exist arg model file found arg model file
model load arg model file

configur callback
callback callback model test arg callback arg
arg deconv
callback deconv callback train test

model train optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train lstm base recurr network
dataset use penn treebank dataset pars charact level

refer
andrej karpathi karpathi
karpathi http github karpathi


neon backend backend
neon text text
neon dataload load train load test
neon initi uniform
neon layer gener cost lstm affin
neon model model
neon optim rm prop schedul
neon transform logist tanh softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
parser argument rlayer lstm choic lstm
help recurr layer lstm
arg parser pars arg

hyperparamet
arg batch size note karpathi use
time step
hidden size
gradient clip valu

setup backend
backend extract valid arg arg backend

download penn treebank
train path load train path arg
valid path load test path arg

train text time step train path
valid text time step valid path vocab train vocab

weight initi
init uniform high

model initi
arg rlayer lstm
rlayer1 lstm hidden size init activ tanh gate activ logist
rlayer2 lstm hidden size init activ tanh gate activ logist

rlayer1 hidden size init activ tanh gate activ logist
rlayer2 hidden size init activ tanh gate activ logist

layer rlayer1
rlayer2
affin train vocab init bia init activ softmax

cost gener cost costfunc cross entropi multi usebit

model model layer layer

learn rate sched schedul rang arg epoch
optim rm prop gradient clip valu gradient clip valu
stochast round arg round
schedul learn rate sched

configur callback
callback callback model valid arg callback arg

train model
model train
optim optim
epoch arg epoch
cost cost callback callback

predict
ypred model output valid
shape valid nbatch arg batch size time step
predict ypred argmax reshap shape transpos
fraction correct predict valid mean
misclassif error fraction correct
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens



convolut autoencod exampl network mnist


numpi

neon array iter load mnist
neon initi uniform
neon layer conv pool gener cost deconv
neon model model
neon optim gradient descent momentum
neon transform rectlin sum squar
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
arg parser pars arg

load dataset
train train test test nclass load mnist path arg

input target train
train array iter train lshape

initi weight learn rule
init uniform high
gradient descent momentum learn rate momentum coef

defin layer
layer conv init init activ rectlin
pool
conv init init activ rectlin
pool
deconv fshape init init activ rectlin
deconv fshape init init activ rectlin stride
deconv fshape init init stride pad

defin cost
cost gener cost costfunc sum squar

model model layer layer

configur callback
callback callback model arg callback arg

model
model train optim epoch arg epoch cost cost callback callback

plot reconstruct digit

matplotlib pyplot

nrow
ncol
test zero nrow ncol
idx rang nrow rang ncol
idx
model layer layer output reshap
test

pyplot matshow test cmap gray
pyplot savefig reconstruct
import error
matplotlib need manual instal gener plot
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train lstm base recurr network
dataset use penn treebank dataset pars word level

refer
recurr neural network regular zaremba2015
gener sequenc recurr neural network graves2014
zaremba2015 http arxiv 1409 2329v5
graves2014 http arxiv 1308 0850

usag
python exampl word lstm rlayer lstm



neon backend backend
neon text text
neon dataload load train load test
neon initi uniform
neon layer gener cost lstm affin lookup tabl
neon model model
neon optim gradient descent momentum schedul
neon transform logist tanh softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
parser argument rlayer lstm choic lstm
help recurr layer lstm
arg parser pars arg

hyperparamet refer
arg batch size
time step
hidden size
gradient clip norm

setup backend
backend extract valid arg arg backend

download penn treebank
train path load train path arg
valid path load test path arg


defin custom pars input individu token
split individu word thi pass text
dataset creation seen
token
replac split

load pars word level
train text time step train path token token onehot input
valid text time step valid path vocab train vocab token token
onehot input

weight initi
init uniform high

model initi
rlayer output size hidden size init init
activ tanh gate activ logist
arg rlayer lstm
rlayer1 rlayer2 lstm rlayer lstm rlayer

rlayer1 rlayer2 rlayer rlayer

layer
lookup tabl vocab size train vocab embed hidden size init init
rlayer1
rlayer2
affin train vocab init bia init activ softmax


cost gener cost costfunc cross entropi multi usebit

model model layer layer

vanilla gradient descent decay schedul learn rate gradient scale
learn rate sched schedul rang arg epoch
optim gradient descent momentum gradient clip norm gradient clip norm
schedul learn rate sched

configur callback
callback callback model valid arg callback arg

train model
model train optim optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train network recurr layer tanh unit
dataset use penn treebank pars charact level

refer
advanc optim recurr network pascanu2012
pascanu2012 http arxiv 1212 0901


neon backend backend
neon text text
neon dataload load train load test
neon initi uniform
neon layer gener cost affin recurr
neon model model
neon optim rm prop
neon transform tanh softmax cross entropi multi
neon callback callback callback
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
arg parser pars arg

hyperparamet paper
arg batch size
time step
hidden size
gradient clip valu

setup backend
backend extract valid arg arg backend

download penn treebank
train path load train path arg
valid path load test path arg

load pars charact level
train text time step train path
valid text time step valid path vocab train vocab

weight initi
init uniform high

model initi
layer recurr hidden size init activ tanh
affin train vocab init bia init activ softmax

cost gener cost costfunc cross entropi multi usebit

model model layer layer

optim rm prop gradient clip valu gradient clip valu stochast round arg round

configur callback
callback callback model valid arg callback arg

train model
model train
optim optim
epoch arg epoch
cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


mnist exampl demonstr merg layer


neon array iter load mnist
neon initi gaussian
neon layer gener cost affin sequenti merg multistream
neon model model
neon optim gradient descent momentum
neon transform rectlin logist cross entropi binari
neon callback callback callback
neon util argpars neon argpars

pars command line
parser neon argpars
arg parser pars arg

hyperparamet
epoch arg epoch

train train test test nclass load mnist path arg
train array iter train train train nclass nclass lshape
valid array iter test test test nclass nclass lshape

weight initi
init norm gaussian scale

initi model
path1 sequenti layer affin nout init init norm activ rectlin
affin nout init init norm activ rectlin

path2 sequenti layer affin nout init init norm activ rectlin
affin nout init init norm activ rectlin

layer merg multistream layer path1 path2 merg stack
affin nout init init norm activ logist shortcut

model model layer layer
cost gener cost costfunc cross entropi binari

valid
optim gradient descent momentum learn rate momentum coef

configur callback
callback callback model valid arg callback arg

model train cost cost optim optim epoch epoch callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl show train synthet multi dimension time seri
after train network abl gener sequenc

usag
python exampl timeseri lstm

then look plot gener


numpi
math
neon backend backend
neon initi glorot uniform
neon layer gener cost lstm affin recurr last
neon model model
neon optim rm prop
neon transform logist tanh ident mean squar
neon callback callback callback
neon nervana object
neon util argpars neon argpars extract valid arg


plot

matplotlib pyplot
import error
matplotlib need instal manual gener plot need
exampl skip plot gener
plot


roll window

convert time lag vector


time step use predict

return

build time lag vector necessari neon

shape

shape shape shape
stride stride stride stride
stride trick stride shape shape stride stride


time seri

init npoint ncycl divid amplitud curvetyp lissajous1

curvetyp option lissajous1 lissajous2

nsampl npoint ncycl
linspac ncycl math nsampl

curvetyp lissajous1 lissajous2
not implement error

scale curvetyp lissajous1

math scale

math

zero nsampl
asarray astyp float32
asarray astyp float32


divid
train
test


data iter sequenc nervana object


thi take sequenc return iter provid batch suitabl
predict meant entir dataset small enough memori


init time step forward sequenc

implement load given backend tensor object backend specif
acceler devic copi devic

arg
ndarray input sequenc featur size within dataset
shape specifi exampl featur size
time step exampl sequenc
forward option mani forward step sequenc predict
exampl
sequenc option whether target sequenc singl step
also determin whether format
stride roll window
target valu sequenc input
reshap stride target
valu singl step input
roll window

length time step
forward forward
batch index
nfeatur nclass shape
nsampl shape
shape nfeatur time step
sequenc sequenc

target step time step sequenc
alloc devic buffer provid minibatch
buffer size nfeatur time batch size handl backend iobuf
iobuf nfeatur time step
iobuf nfeatur target step

sequenc
truncat make multipl batch
extra exampl nsampl time step
extra exampl
extra exampl

calcul mani batch
nsampl extra exampl
nbatch nsampl time step
ndata nbatch time step leftov

lag version
concaten forward forward
seri
reshap sequenc continu along batch
reshap nbatch time step nfeatur
reshap nbatch time step nfeatur

roll window time step

time step

nsampl shape
extra exampl nsampl
extra exampl
extra exampl
extra exampl

calcul mani batch
nsampl extra exampl
nbatch nsampl
ndata nbatch
seri

xshape nbatch time step nfeatur
yshape nbatch nfeatur
reshap xshape transpos
reshap yshape transpos

reset

reset start index dataset back zero

batch index

iter

gener use iter dataset

yield
tupl minibatch

batch index
batch index nbatch
batch reshap devic buffer shape
batch batch index reshap shape copi
batch batch index reshap shape copi

make batch backend tensor
batch
batch

batch index




replic neon error metric

featur axi
squar mean axi featur axi mean

name main

pars command line
parser neon argpars
parser argument curvetyp lissajous1 choic lissajous1 lissajous2
help input curv lissajous1 lissajous2
arg parser pars arg

network hyperparamet
hidden
arg batch size

follow flag train strategi
sequenc
input sequenc target output sequenc
layer output everi step use error optim
model contain layer affin layer
iter format accordingli stride along
whole seri overlap
sequenc
input sequenc target output singl step
layer output last step use error optim
model contain layer output layer recurr last
affin layer
iter format accordingli roll window

sequenc

note time seri higher lower frequenc requir differ amount
learn tempor pattern sequenc length batch size
train process also make differ learn perform


npoint
ncycl
predict
seed

main neon script

backend extract valid arg arg backend

file save train model
arg save path
arg save path timeseri

arg callback arg save path
arg callback arg save path arg save path

arg callback arg serial
arg callback arg serial

creat synthet whole seri
time seri time seri npoint ncycl ncycl curvetyp arg curvetyp

iter feed sequenc determin train strategi
train data iter sequenc time seri train sequenc sequenc
valid data iter sequenc time seri test sequenc sequenc

defin weight initi
init glorot uniform uniform high

defin model model differ strategi sequenc target
sequenc
layer
lstm hidden init activ logist gate activ tanh reset cell
affin train nfeatur init bia init activ ident


layer
lstm hidden init activ logist gate activ tanh reset cell
recurr last
affin train nfeatur init bia init activ ident


model model layer layer
cost gener cost mean squar
optim rm prop stochast round arg round

callback callback model valid arg callback arg

model
model train
optim optim
epoch arg epoch
cost cost
callback callback

visual model valid
train model train valid dataset output match
train output model output train reshap train nfeatur
valid output model output valid reshap valid nfeatur
train target train seri
valid target valid seri

calcul accuraci
terr train output train target
verr valid output valid target

terr verr terr verr

plot
figur
plot train output train output label predict
plot train target train target label target
legend
titl neon train
savefig neon seri train output

figur
plot valid output valid output label predict
plot valid target valid target label target
legend
titl neon valid
savefig neon seri valid output

gener sequenc
gener sequenc sequenc length sinc make differ



sequenc
layer
lstm hidden init activ logist gate activ tanh reset cell
affin train nfeatur init bia init activ ident


layer
lstm hidden init activ logist gate activ tanh reset cell
recurr last
affin train nfeatur init bia init activ ident


model model layer layer
model load arg save path
model initi dataset train nfeatur

output zero train nfeatur predict
seed time seri train seed

model train nfeatur
seed
reshap train nfeatur
model fprop infer

rang predict
take last predict feed fprop
pred
output pred
pred reshap train nfeatur
model fprop infer

output vstack seed output

plot
figur
plot output output label gener sequenc
plot seed seed label seed sequenc
legend
titl neon gener sequenc
savefig neon gener sequenc

figur
plot output label gener sequenc
plot seed label seed sequenc
legend
titl neon gener sequenc
savefig neon gener sequenc
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


run epoch alexnet imagenet
run complet alexnet
alexnet save path path save batch


neon util argpars neon argpars
neon initi constant gaussian
neon layer conv dropout pool gener cost affin
neon optim gradient descent momentum multi optim schedul
neon transform rectlin softmax cross entropi multi top k misclassif
neon model model
neon imag loader
neon callback callback callback

pars command line gener backend
parser neon argpars
parser argument subset
help subset train dataset percentag
arg parser pars arg

setup provid
option dict repo arg
inner size
subset arg subset
train imag loader name train scale rang shuffl option
test imag loader name valid scale rang transform
option

layer conv init gaussian scale bia constant
activ rectlin pad stride
pool stride
conv init gaussian scale bia constant
activ rectlin pad
pool stride
conv init gaussian scale bia constant
activ rectlin pad
conv init gaussian scale bia constant
activ rectlin pad
conv init gaussian scale bia constant
activ rectlin pad
pool stride
affin nout 4096 init gaussian scale bia constant activ rectlin
dropout keep
affin nout 4096 init gaussian scale bia constant activ rectlin
dropout keep
affin nout 1000 init gaussian scale bia constant activ softmax
model model layer layer

drop weight epoch drop bia epoch
weight sched schedul
gradient descent momentum wdecay 0005 schedul weight sched
stochast round arg round
bias gradient descent momentum schedul schedul
stochast round arg round
multi optim bia bias

configur callback
valmetr top k misclassif
callback callback model test metric valmetr arg callback arg
cost gener cost costfunc cross entropi multi
model train optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


run epoch alexnet imagenet
run complet alexnet
alexnet save path path save batch


neon util argpars neon argpars
neon initi kaim
neon layer conv pool gener cost activ
neon layer merg sum skip node
neon optim gradient descent momentum schedul
neon transform rectlin softmax cross entropi multi top k misclassif
neon model model
neon imag loader
neon callback callback callback
itertool


pars command line gener backend
parser neon argpars
parser argument depth
help network configur
parser argument bottleneck action store
help bottleneck modul compar modul
parser argument subset
help subset train dataset percentag
arg parser pars arg

arg depth
stage
arg depth
stage
arg depth
stage
arg depth
stage
arg depth
stage

depth paramet


setup provid
option dict repo arg
inner size
subset arg subset
train imag loader name train scale rang shuffl option
test imag loader name valid scale rang transform option


conv fsize stride relu batch norm
dict fshape fsize fsize
stride stride
activ rectlin relu
pad fsize
batch norm batch norm
init kaim local


factori stride
arg bottleneck
skip stride
stride stride
sidepath skip node skip conv conv stride

arg bottleneck
mainpath conv conv
conv conv stride
conv conv relu

mainpath conv conv stride
conv conv relu
merg sum mainpath sidepath
activ rectlin


layer conv conv stride
pool stride


structur deep residu part network
arg depth modul convolut layer featur depth
nfm chain iter enumer stage
stride prev prev nfm nfm

stride nfm stride
layer append factori stride

layer append pool
layer append conv conv train nclass relu batch norm
layer append activ softmax
model model layer layer

weight sched schedul
gradient descent momentum wdecay 0001 schedul weight sched

configur callback
valmetr top k misclassif
callback callback model test metric valmetr arg callback arg
cost gener cost costfunc cross entropi multi
model train optim epoch arg epoch cost cost callback callback
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


goog le net benchmark
http github soumith convnet benchmark

googlenet
googlenet

deriv full model found
http gist github nervanazoo 2e5be01095e935e90dd8


neon nervana object
neon util argpars neon argpars
neon initi xavier
neon layer conv pool gener cost affin merg broadcast
neon optim gradient descent momentum multi optim schedul
neon transform rectlin cross entropi multi
neon model model
neon array iter
numpi
parser neon argpars
arg parser pars arg

nervana object enabl winograd

setup provid
train random uniform
train random uniform 1000
train array iter train train nclass 1000 lshape

init1 xavier local
initx xavier local
relu rectlin

common dict activ relu init initx
commonp1 dict activ relu init initx pad
commonp2 dict activ relu init initx pad
pool3s1p1 dict fshape pad stride
pool3s2p1 dict fshape pad stride


incept kval
kval

branch1 conv common
branch2 conv common conv commonp1
branch3 conv common conv commonp2
branch4 pool pool3s1p1 conv common
merg broadcast layer branch1 branch2 branch3 branch4 merg depth

model model layer
conv pad stride common
pool pool3s2p1
conv common
conv commonp1
pool pool3s2p1
incept
incept
pool pool3s2p1
incept
incept
incept
incept
incept
pool pool3s2p1
incept
incept
pool fshape stride
affin nout 1000 init init1

weight sched schedul
gradient descent momentum wdecay 0005 schedul weight sched
multi optim
cost gener cost costfunc cross entropi multi

model benchmark train cost cost optim niter nskip
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


benchmark
http github soumith convnet benchmark




neon nervana object
neon util argpars neon argpars
neon initi gaussian
neon layer conv pool gener cost affin
neon optim gradient descent momentum multi optim schedul
neon transform rectlin softmax cross entropi multi
neon model model
neon array iter
numpi
parser neon argpars
arg parser pars arg

nervana object
nervana object enabl winograd

setup provid
train random uniform
train random uniform 1000
train array iter train train nclass 1000 lshape

layer conv init gaussian scale activ rectlin pad
pool stride
conv init gaussian scale activ rectlin pad
pool stride
conv init gaussian scale activ rectlin pad
conv init gaussian scale activ rectlin pad
pool stride
conv init gaussian scale activ rectlin pad
conv init gaussian scale activ rectlin pad
pool stride
conv init gaussian scale activ rectlin pad
conv init gaussian scale activ rectlin pad
pool stride
affin nout 4096 init gaussian scale activ rectlin
affin nout 4096 init gaussian scale activ rectlin
affin nout 1000 init gaussian scale activ softmax
model model layer layer

weight sched schedul
gradient descent momentum wdecay 0005 schedul weight sched
multi optim
cost gener cost costfunc cross entropi multi

model benchmark train cost cost optim niter nskip
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


overfeat benchmark
http github soumith convnet benchmark

overfeat
overfeat


neon nervana object
neon util argpars neon argpars
neon initi gaussian
neon layer conv pool gener cost affin
neon optim gradient descent momentum multi optim schedul
neon transform rectlin softmax cross entropi multi
neon model model
neon array iter
numpi
parser neon argpars
arg parser pars arg

nervana object enabl winograd

setup provid
train random uniform
train random uniform 1000
train array iter train train nclass 1000 lshape

layer conv init gaussian scale
activ rectlin pad stride
pool stride
conv init gaussian scale activ rectlin pad
pool stride
conv init gaussian scale activ rectlin pad
conv 1024 init gaussian scale activ rectlin pad
conv 1024 init gaussian scale activ rectlin pad
pool stride
affin nout 3072 init gaussian scale activ rectlin
affin nout 4096 init gaussian scale activ rectlin
affin nout 1000 init gaussian scale activ softmax
model model layer layer

weight sched schedul
gradient descent momentum wdecay 0005 schedul weight sched
multi optim
cost gener cost costfunc cross entropi multi

model benchmark train cost cost optim niter nskip
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


alexnet benchmark
http github soumith convnet benchmark

alexnet
alexnet


neon nervana object
neon util argpars neon argpars
neon initi gaussian
neon layer conv pool gener cost affin
neon optim gradient descent momentum multi optim schedul
neon transform rectlin softmax cross entropi multi
neon model model
neon array iter
numpi
parser neon argpars
arg parser pars arg

nervana object enabl winograd

setup provid
train random uniform
train random uniform 1000
train array iter train train nclass 1000 lshape

layer conv init gaussian scale
activ rectlin pad stride
pool stride
conv init gaussian scale activ rectlin pad
pool stride
conv init gaussian scale activ rectlin pad
conv init gaussian scale activ rectlin pad
conv init gaussian scale activ rectlin pad
pool stride
affin nout 4096 init gaussian scale activ rectlin
affin nout 4096 init gaussian scale activ rectlin
affin nout 1000 init gaussian scale activ softmax
model model layer layer

weight sched schedul
gradient descent momentum wdecay 0005 schedul weight sched
multi optim
cost gener cost costfunc cross entropi multi

model benchmark train cost cost optim niter nskip
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


interact demo base facebook dataset b ab i

refer
toward complet question answer prerequisit task
http arxiv 1502 05698

usag
specifi b ab i task
python exampl babi demo rlayer model weight babi

numpi

util creat model babi handler
neon backend backend
neon babi
neon text text
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
parser argument task choic xrang
help task train test b ab i dataset
parser argument rlayer choic lstm
help recurr layer lstm
parser argument model weight requir
help pickl file train weight
arg parser pars arg

setup backend
backend extract valid arg arg backend


load b ab i dataset
babi babi handler arg arg task
valid babi test

creat model
model infer creat model babi vocab size arg rlayer
model infer load arg model weight
model infer initi dataset valid

stori question answer babi test pars


stitch sentenc word
join word replac replac
replac


vector word
text sentenc babi word vector babi token word



n the vocabulari task word format babi vocab size
stitch sentenc babi vocab
n exampl test
n stori
stitch sentenc stori
question
stitch sentenc question
n answer
answer


user stori question
stori line
line input n pleas enter stori
line
stori line append line
line input
stori join stori line strip

question input pleas enter question

convert user input suitabl network input
vector stori babi stori maxlen
vector question babi queri maxlen

predict probabl forward propag
prob model infer fprop infer

answer
babi vocab size
indic argpartit prob axi
prob prob indic
sort indic argsort prob axi

n answer
revers sort

babi index word prob
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train facebook dataset b ab i

task number lstm baselin neon

singl support fact
support fact
three support fact
relat
three relat
question
count
list set
simpl negat
qa10 indefinit knowledg
qa11 basic corefer
qa12 conjunct
qa13 compound corefer
qa14 time reason
qa15 basic deduct
qa16 basic induct
qa17 posit reason
qa18 size reason
qa19 path find
qa20 agent motiv

refer
toward complet question answer prerequisit task
http arxiv 1502 05698

usag
specifi b ab i task
python exampl babi train rlayer save path babi lstm

util creat model babi handler
neon backend backend
neon
neon layer gener cost
neon optim adam
neon transform accuraci cross entropi multi
neon callback callback callback
neon util argpars neon argpars extract valid arg

pars command line
parser neon argpars
parser argument task choic xrang
help task train test b ab i dataset
parser argument rlayer choic lstm
help recurr layer lstm
arg parser pars arg

overrid save path
arg save path
arg save path babi

arg callback arg save path
arg callback arg save path arg save path

setup backend
arg batch size
backend extract valid arg arg backend

load b ab i dataset
babi babi handler arg arg task
train babi train
valid babi test

creat model
model creat model babi vocab size arg rlayer

setup callback
callback callback model valid arg callback arg

train model
model train
optim adam
epoch arg epoch
cost gener cost costfunc cross entropi multi
callback callback

output accuraci
train accuraci model train metric accuraci
test accuraci model valid metric accuraci

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


util function b ab i exampl demo

neon babi
neon initi glorot uniform uniform orthonorm
neon layer affin lookup tabl merg multistream lstm
neon model model
neon transform logist softmax tanh

b ab i task
subset
task
singl support fact
support fact
three support fact
relat
three relat
question
count
list set
simpl negat
qa10 indefinit knowledg
qa11 basic corefer
qa12 conjunct
qa13 compound corefer
qa14 time reason
qa15 basic deduct
qa16 basic induct
qa17 posit reason
qa18 size reason
qa19 path find
qa20 agent motiv



babi handler task

handl b ab i task

arg
path b ab i directori
task task b ab i dataset

return
babi handler b ab i task

task task task
babi path task task subset subset


creat model vocab size rlayer

creat lstm model b ab i dataset

arg
vocab size string b ab i
rlayer type recurr layer lstm

return
model model creat network

recurr layer paramet
rlayer rlayer lstm
rlayer dict output size reset cell
init glorot uniform init inner orthonorm
activ tanh gate activ logist

lstm swap activ function
rlayer lstm
rlayer updat dict activ logist gate activ tanh

lookup layer paramet
lookup dict vocab size vocab size embed init uniform

model construct
stori path lookup tabl lookup rlayer rlayer
queri path lookup tabl lookup rlayer rlayer

layer merg multistream layer stori path queri path merg stack
affin vocab size init glorot uniform activ softmax

model layer layer

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


h5pi
collect defaultdict
numpi
c pickl


neon text preprocess clean


build train path filepath label train data vocab file
vocab skip header train ratio

load file spit file record
review text review
typic pass
vocab process warn phrase need
though multipl pass convert text integ deal integ
thereaft

warn proof concept handl larg dataset
dataset entir memori numpi



fname filepath
vocab file
fname vocab filepath vocab

fname vocab vocab file

path exist fname path exist fname vocab
creat store note hdf5 orient store slice row
review text hold metadata process text file
review hold rate int
h5pi file fname
shape maxshap
dtype uint8
split
word uint16
warn vlen byte python
text h5pi special dtype vlen

review text creat dataset review shape shape maxshap maxshap
dtype compress gzip
review train creat dataset
train shape shape maxshap maxshap
dtype h5pi special dtype vlen int32 compress gzip

review valid creat dataset
valid shape shape maxshap maxshap
dtype h5pi special dtype vlen int32 compress gzip

wdata zero dtype

init vocab train
build vocab
vocab
vocab defaultdict
build vocab
nsampl

open file skip header need
open filepath
skip header
readlin

line enumer
rate review line strip split

clean review
review clean review
review word review strip split
word review word
split random rand train ratio

creat record
wdata rate
wdata text review
wdata word word
wdata split split
review text wdata

updat vocab need
build vocab
word review word
vocab word

nsampl

histogram label sentenc length
rate count uniqu
review text nsampl count
count uniqu
review text word nsampl count
vocab size vocab
nclass rate
review text attr vocab size vocab size
review text attr nrow nsampl
review text attr nclass nclass
review text attr distribut count
vocabulari size vocab size
sampl nsampl
class nclass
distribut rate count
count count
count sort count revers
sentenc length count

warn assum vocab order million word
sort vocab assign frequenc use downstream task
done train
build vocab
vocab sort sort
vocab item revers
vocab
enumer vocab sort
vocab

text integ
ntrain
nvalid
rang nsampl
text review text text
review text
split review text split
text vocab text strip split
split
review train ntrain text
ntrain

review valid nvalid text
nvalid
review text attr ntrain ntrain
review text attr nvalid nvalid
train valid format review text attr ntrain
review text attr nvalid
close open file
close
close

path exist fname vocab
vocab
vocab iteritem
vocab
vocabulari imdb dataset save format fname vocab
c pickl dump vocab vocab open fname vocab

fname fname vocab
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl infer lstm network amazon review analysi

python exampl imdb infer model weight imdb vocab file imdb vocab



neon backend backend
neon initi uniform glorot uniform
neon layer lstm affin dropout lookup tabl recurr sum
neon model model
neon transform logist tanh softmax
neon util argpars neon argpars extract valid arg
neon text preprocess clean
c pickl
numpi


pars command line
parser neon argpars
parser argument model weight requir
help pickl file train weight
parser argument vocab file requir
help vocabulari file
arg parser pars arg


hyperparamet refer
batch size
clip gradient
gradient limit
vocab size 20000
sentenc length
embed
hidden size
reset cell
epoch arg epoch

setup backend
backend extract valid arg arg backend



defin model train
init glorot glorot uniform
init uniform embed high embed
nclass
layer
lookup tabl vocab size vocab size embed embed init init
updat
lstm hidden size init glorot activ tanh
gate activ logist reset cell
recurr sum
dropout keep
affin nclass init glorot bia init glorot activ softmax



load weight
initi model
model model layer layer
load weight format arg model weight

model load arg model weight
model initi dataset sentenc length batch size

setup buffer accept review
xdev zero sentenc length dtype int32 featur size
xbuf zero sentenc length dtype int32

start
index

vocab vocab c pickl load open arg vocab file



line input enter review test data file

clean input
token clean line strip split

check start
sent vocab vocab vocab token
sent start index sent
sent vocab size sent

sentenc
xbuf
trunc sent sentenc length
xbuf trunc trunc
xdev xbuf copi
pred model fprop xdev infer infer flag dropout

sent format xbuf
pred format pred

python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


exampl train lstm network sentiment analysi
python exampl imdb train imdb vocab file imdb vocab


kaggl

http kaggl word2vec tutori

choos initi word embed layer word2 vec pleas make sure
googl news vector negative300

http drive googl file 0 b7 xk cwp i5 kdi nl nut tl ss21p qm m edit share


prepar build train
neon backend backend
neon array iter
neon initi uniform glorot uniform array
neon layer gener cost affin dropout lookup tabl lstm recurr sum
neon model model
neon optim adagrad
neon transform logist tanh softmax cross entropi multi accuraci
neon util argpars neon argpars extract valid arg
neon callback callback callback
neon text preprocess pad xy googl word2vec
h5pi
c pickl

pars command line
parser neon argpars
parser argument review file
label train data
help input movi review file
parser argument vocab file
label train data vocab
help output file save process vocabulari
parser argument action store
help download googl word2 vec
parser argument
googl news vector negative300
help built word2 vec
arg parser pars arg


hyperparamet
hidden size
embed
vocab size 20000
sentenc length
batch size
gradient limit
clip gradient
epoch arg epoch
embed updat

setup backend
backend extract valid arg arg backend

preprocess token
fname fname vocab build train filepath arg review file
vocab file arg vocab file skip header


play around googl news word vector init
arg
file arg
vocab vocab c pickl load open fname vocab
init embed googl word2vec file vocab
vocab size vocab size index
done load word2 vec vector embed size format embed
embed updat
init array init

init uniform embed embed


h5pi file fname
review h5train h5valid review train valid
ntrain nvalid nclass review attr
ntrain review attr nvalid review attr nclass


make train dataset
h5train ntrain


train train pad xy
vocab size vocab size sentenc length sentenc length
train array iter train train nclass nclass

make valid dataset
h5valid nvalid


valid valid pad xy
vocab size vocab size sentenc length sentenc length
valid array iter valid valid nclass nclass


initi
init glorot glorot uniform


defin layer
layer
lookup tabl vocab size vocab size embed embed init init
updat embed updat
lstm hidden size init glorot activ tanh gate activ logist
reset cell
recurr sum
dropout keep
affin nclass init glorot bia init glorot activ softmax


cost metric optim
cost gener cost costfunc cross entropi multi usebit
metric accuraci
model model layer layer
optim adagrad learn rate

configur callback
callback callback model valid arg callback arg

train model
model train
optim optim
epoch epoch
cost cost
callback callback

model
n train accuraci model train metric metric
test accuraci model valid metric metric
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


test train fast rcnn model detect pascal dataset
thi test current run imag time

refer
fast
http arxiv 1504 08083v2
http github rbgirshick fast rcnn

usag
python exampl fast rcnn test model file frcn

note
vgg16 base fast model support test batch size
imag test consum memori

dure test infer select search ro is use
network infer time vari base mani ro is
imag pascal 2007 averag select search ro is around
2000

dataset cach preprocess file
configur dataset use cach file
nervana voc devkit year train
nervana voc devkit year infer

evalu script adapt
http github rbgirshick faster rcnn commit 45e0da9a246fab5fd86e8c96dc351be7f145499f



numpi
heapq

neon pascal pascal class pascalvoc infer
neon util argpars neon argpars
util creat frcn model

pars command line
parser neon argpars
arg parser pars arg
arg model file need model file fast test

hyperparamet
arg batch size

batch arg batch size
roi 5403

setup dataset
imag test
year 2007
valid pascalvoc infer imag year path arg
roi roi

setup model
model creat frcn model
model load arg model file
model initi dataset valid

detect
imag valid imag
class valid class
imag index valid imag index
heurist keep averag detect imag prior

imag
heurist keep detect imag prior
imag
detect thresold adapt base
constraint
thresh one class
score hold minheap score use enforc
constraint
score xrang class
detect collect
box imag detect
score
box xrang imag
xrang class

thresh

total batch format valid nbatch

last strlen
iter minibatch dataset
enumer valid

test progress
finish format valid nbatch
stdout write last strlen
stdout write encod
last strlen
stdout flush

hasattr valid actual
model valid actual

output model fprop infer

score box valid post process output

skip background start process
pascal class

pick score bbox replat
pascal class index
box box
score score
keep one high enough score
ro is one
keep score reshap thresh class
keep


nonmaximum suppress
box box keep
score score keep
ind argsort score imag
score score ind
box box ind
push score onto minheap
score
heapq heappush score
collect detect
item minheap updat threshold
score
score
heapq heappop score
thresh score

box hstack box score newaxi astyp
float32 copi

xrang class
xrang imag
box
ind box thresh
box box ind

n appli detect
box valid appli box thresh

evalu detect
output frcn output
annopath imagesetfil valid evalu box path join arg output
annopath imagesetfil year imag pascal class
path join arg output
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


demo train fast rcnn model detect pascal dataset
thi demo current run imag time

refer
fast
http arxiv 1504 08083v2
http github rbgirshick fast rcnn

usag
python exampl fast rcnn demo model file frcn

note
vgg16 base fast model support test batch size
imag test consum memori

dure demo select search ro is use network
infer time vari base mani ro is imag
pascal 2007 averag select search ro is around 2000

dataset cach preprocess file
configur dataset use cach file
nervana voc devkit year train
nervana voc devkit year infer



numpi
imag
neon pascal pascal class
neon pascalvoc infer
neon util argpars neon argpars
util creat frcn model

plot

matplotlib pyplot
backend
import error
matplotlib need instal manual gener plot need
exampl skip plot gener
plot

pars command line
parser neon argpars
parser argument prefix
help prefix save imag file name
model file name
arg parser pars arg
arg model file need model file fast test

arg prefix
arg prefix path splitext path basenam arg model file

output path join arg frcn output
path isdir output
mkdir output

hyperparamet
arg batch size

batch arg batch size
roi 5403

setup dataset
imag test
imag year 2007
valid pascalvoc infer imag imag year path arg
roi roi shuffl

setup model

model creat frcn model
model load arg model file
model initi dataset valid

conf thresh
thresh

iter minibatch dataset
enumer valid

imag open file thi order


output model fprop infer

score box valid post process output

visual detect
plot
subplot figsiz
imshow aspect equal

pascal class

pick score bbox replat
pascal class index
box box
score score
keep one high enough score
keep score conf thresh
keep


nonmaximum suppress
box box keep
score score keep

keep valid nonmaximum suppress box score thresh

keep
box box keep
score score keep

draw detect bound box
ind score conf thresh
ind


detect format

plot
ind
bbox box
score score

patch
rectangl bbox bbox
bbox bbox
bbox bbox fill
edgecolor linewidth

text bbox bbox
format score
bbox dict facecolor blue alpha
fontsiz color white

axi
tight layout

plot
fname path join output format
arg prefix imag
imag year

savefig fname
close
python

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


train fast rcnn model pascal dataset
thi fast rcnn base vgg16 train imag i1 k

script download train vgg16 neon model
seed convolut pool layer fast start train
script given model file train
fast given model file

refer
fast
http arxiv 1504 08083v2
http github rbgirshick fast rcnn

usag
python exampl fast rcnn train save path frcn

note

vgg16 base fast model support train test small
batch size imag batch model train converg
around epoch with imag batch ro is imag train
consum memori

origin caff model goe 40000 iter train
imag minibatch

dataset cach preprocess file
configur dataset use cach file
nervana voc devkit year train
nervana voc devkit year infer



neon backend backend
neon pascalvoc train
neon transform cross entropi multi smooth l1 loss object detect
neon util argpars neon argpars extract valid arg
neon optim gradient descent momentum multi optim
neon callback callback callback
neon layer multicost gener cost gener cost mask
neon util persist save

util load weight creat frcn model scale bbreg weight

main script

pars command line
parser neon argpars
arg parser pars arg

overrid save path
arg save path
arg save path frcn

arg callback arg save path
arg callback arg save path arg save path

arg callback arg serial
arg callback arg serial arg epoch

hyperparamet
arg batch size

epoch arg epoch

batch arg batch size
roi
frcn fine tune
learn rate scale

frcn fine tune
learn rate scale

setup backend
backend extract valid arg arg backend

setup train dataset
train pascalvoc train trainval 2007 path arg
batch batch roi roi
flip
test pascalvoc train test 2007 path arg
batch batch roi roi
flip

setup model
model creat frcn model frcn fine tune

setup optim
gradient descent momentum learn rate scale wdecay 0005
gradient descent momentum learn rate scale

optim multi optim bia

train model seed imag model conv layer train weight
otherwis load model file
arg model file
load weight model arg

cost multicost cost gener cost costfunc cross entropi multi
gener cost mask costfunc smooth l1 loss
weight

callback callback model test arg callback arg

model train optim optim
epoch epoch cost cost callback callback

fast model requir scale bbox regress branch linear layer weight
save model
model scale bbreg weight model train bbtarget mean train bbtarget std

save model serial keep state arg save path

run
metric train model train metric object detect
train label accuraci deteciton logloss format metric train
metric train

metric test model test metric object detect
test label accuraci deteciton logloss format metric test
metric test

copyright 2015 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


util function fast rcnn model demo


c pickl
numpi

neon dataset dataset
neon initi gaussian constant xavier
neon transform rectlin softmax ident
neon model model
neon layer conv pool affin dropout roi pool branch node tree
neon util persist load



indic bound cooridn
xmin
ymin
xmax
ymax
frcn


layer

setup layer
init1 xavier local
relu rectlin

conv stride
pad
init init1
bia constant
activ relu

model layer
layer

conv stack differ featur size
layer append conv conv
layer append conv conv
layer append pool stride
layer append conv conv
layer append conv conv
layer append pool stride
layer append conv conv
layer append conv conv
layer append conv conv
layer append pool stride
layer append conv conv
layer append conv conv
layer append conv conv
layer append pool stride
layer append conv conv
layer append conv conv
layer append conv conv
use layer
layer append pool stride
layer append affin nout 4096 init initfc bia constant activ relu
layer append dropout keep
layer append affin nout 4096 init initfc bia constant activ relu
layer append dropout keep
layer append affin nout 1000 init initfc bia constant activ softmax

layer


creat frcn model frcn fine tune

branch node name

imagenet layer layer


frcn layer
roi pool
layer imagenet layer bprop enabl frcn fine tune
affin nout 4096 init gaussian scale
bia constant activ rectlin
dropout keep
affin nout 4096 init gaussian scale
bia constant activ rectlin
dropout keep

affin nout init gaussian scale
bia constant activ softmax

layer

affin nout init gaussian scale
bia constant activ ident


model layer tree frcn layer layer


scale bbreg weight model mean std
mean model mean
std model std
model layer layer layer
model layer layer layer std
model layer layer layer
model layer layer layer std mean
model


load weight model path
load train vgg16 neon model local
http west amazonaw nervana modelzoo
filenam
size 554227541

workdir filepath dataset valid path append path filenam
path exist filepath
dataset fetch dataset filenam filepath size

serial train vgg16 model
pdict load filepath

param layer model layer layer layer layer
param dict pdict model config layer

layer param layer param dict

layer name config name
layer load weight load state




annopath imagesetfil year imag class output

pascal metric chang 2010
metric year 2010
voc07 metric metric
enumer class
background

filenam format
year imag
filepath path join output filenam
prec filepath annopath imagesetfil
output ovthresh metric metric

format
open path join output
c pickl dump prec prec
mean format mean

copyright 2016 nervana system
licens apach licens version licens
file complianc licens
obtain copi licens

http apach licens licens

unless requir applic agre write softwar
distribut licens distribut basi
without warranti condit kind either express impli
licens specif languag govern permiss
limit licens


fast
licens licens licens detail
written bharath hariharan


evalu script variou util function
http github rbgirshick faster rcnn commit 45e0da9a246fab5fd86e8c96dc351be7f145499f


etre element tree

c pickl
numpi


pars filenam
pars pascal file
tree pars filenam
object
tree findal

name find name text
pose find pose text
truncat find truncat text
difficult find difficult text
bbox find bndbox
bbox bbox find xmin text
bbox find ymin text
bbox find xmax text
bbox find ymax text
object append

object


prec metric
prec metric
comput given precis recal
metric use
point method

metric
point metric

arang



prec


correct calcul
first append sentinel valu
mrec concaten
mpre concaten prec

comput precis envelop
rang mpre size
mpre maximum mpre mpre

calcul area curv look point
axi recal chang valu
mrec mrec

delta recal prec
mrec mrec mpre



detpath
annopath
imagesetfil
classnam
cachedir
ovthresh
metric
prec detpath
annopath
imagesetfil
classnam
ovthresh
metric

level pascal evalu

detpath path detect
detpath format classnam produc detect result file
annopath path annot
annopath format imagenam annot file
imagesetfil text file contain imag imag line
classnam categori name
cachedir directori cach annot
ovthresh overlap threshold
metric whether voc07 point comput


assum detect detpath format classnam
assum annot annopath format imagenam
assum imagesetfil text file line imag name
cachedir cach annot pickl file

first load
path isdir cachedir
mkdir cachedir
cachefil path join cachedir annot
read imag
open imagesetfil
line readlin
imagenam strip line

path isfil cachefil
load annot
rec
imagenam enumer imagenam
rec imagenam pars annopath format imagenam

read annot format
imagenam
save
save cach annot format cachefil
open cachefil
c pickl dump rec

load
open cachefil
rec c pickl load

extract object
rec
npo
imagenam imagenam
rec imagenam name classnam
bbox bbox
difficult difficult astyp

npo npo difficult
rec imagenam bbox bbox
difficult difficult


read det
detfil detpath format classnam
open detfil
line readlin

splitlin strip split line
imag splitlin
confid splitlin
splitlin

sort confid
sort argsort confid
sort score sort confid
sort
imag imag sort

det mark
imag
zero
zero
rang
rec imag
astyp
ovmax
bbgt bbox astyp

bbgt size
comput overlap
intersect
ixmin maximum bbgt
iymin maximum bbgt
ixmax minimum bbgt
iymax minimum bbgt
maximum ixmax ixmin
maximum iymax iymin
inter



bbgt bbgt
bbgt bbgt inter

overlap inter
ovmax overlap
jmax argmax overlap

ovmax ovthresh
difficult jmax
jmax

jmax





comput precis recal
cumsum
cumsum
npo
prec
prec metric

prec
code




extens modul document autodoc anoth directori
directori path directori rel
document root path abspath make absolut like shown
path insert path abspath

neon version neon version

gener configur

document need minim sphinx version state
need sphinx

sphinx extens name string they
extens come sphinx name sphinx custom
one
extens
sphinx autodoc
sphinx autosummari
sphinx napoleon
sphinx doctest
sphinx intersphinx
sphinx todo
sphinx coverag
sphinx mathjax
sphinx ifconfig
sphinx viewcod


autodoc set
autodoc flag member undoc member inherit member

autosummari set
autosummari gener

napoleon set use pars googl numpi style docstr
napoleon googl docstr
napoleon numpi docstr
napoleon
napoleon special
napoleon admonit exampl
napoleon admonit note
napoleon admonit refer
napoleon ivar
napoleon param
napoleon rtype

path contain templat rel directori
templat path templat

suffix sourc filenam
sourc suffix

encod sourc file
sourc encod

master toctre document
master index

gener inform project
project neon
copyright 2016 nervana system

version info project document act replac
version releas also use variou place throughout
built document

version
version neon version
full version includ alpha beta tag
releas version

languag content autogener sphinx refer document
support languag
languag

there option replac today either today
valu use
today
els today use format strftime call
today

list pattern rel sourc directori match file
directori ignor look sourc file
exclud pattern

re st role use markup text
document
role

append func cross refer text
parenthes

current name prepend descript
unit titl
name

sectionauthor moduleauthor direct shown
output they ignor
show author

name pygment syntax highlight style
pygment style borland

ignor prefix index sort
modindex common prefix

keep warn system messag paragraph built document
keep warn


option html output

theme html html help page document
builtin theme
html theme neon theme
html theme sphinx theme
html theme bootstrap

theme option theme specif custom look feel theme
option avail theme
document
html theme option

path contain custom theme rel directori
html theme path
html theme path sphinx theme html theme path
html theme path sphinx bootstrap theme html theme path

name sphinx document default
project releas document
html titl

shorter titl navig default html titl
html titl

name imag file rel directori place
sidebar
html logo neon theme favicon

name imag file within path favicon
doc thi file window icon file 16x16 32x32
pixel larg
html favicon neon theme favicon

path contain custom file style sheet
rel directori they copi builtin file
file name overwrit builtin
html path neon theme

extra path contain custom file robot
htaccess rel directori these file copi
directli root document
html extra path

last updat timestamp insert everi page bottom
given strftime format
html last updat

smarti pant use convert quot dash
typograph correct entiti
html smartyp

custom sidebar templat map document name name
html sidebar

addit templat render page map page name
name
html addit page

index gener
html domain indic

index gener
html index

index split individu page letter
html split index

link re st sourc ad page
html show sourcelink

creat sphinx shown html footer default
html show sphinx

copyright shown html footer default
html show copyright

open search descript file output page
contain link refer valu option must
finish html serv
html opensearch

thi file name suffix html file xhtml
html file suffix

output file name html help builder
htmlhelp basenam neondoc


option la te x output

latex element
paper size letterpap a4pap
papers letterpap

font size 10pt 11pt 12pt
pointsiz 10pt

addit stuff la te x preambl
preambl


group document tree la te x file list tupl
sourc start file target name titl
author documentclass howto manual
latex document index neon neon document
nervana system manual

name imag file rel directori place
titl page
latex logo

manual document toplevel head part
chapter
latex part

show page refer link
latex show pageref

show address extern link
latex show url

document append appendix manual
latex appendic

index gener
latex domain indic


option manual page output

entri manual page list tupl
sourc start file name descript author manual section
page
index neon neon document
nervana system


show address extern link
show url


option texinfo output

group document tree texinfo file list tupl
sourc start file target name titl author
menu entri descript categori
texinfo document index neon neon document
nervana system neon
line descript project miscellan

document append appendix manual
texinfo appendic

index gener
texinfo domain indic

display address footnot
texinfo show url footnot

gener detailmenu node menu
texinfo detailmenu


exampl configur intersphinx refer python standard librari
intersphinx map
python http doc python
numpi http doc scipi numpi

sphinx read the doc theme

from http github ryan roemer sphinx bootstrap theme




version

version join version
version full version


html theme path
return html theme path
path abspath path dirnam path dirnam file

